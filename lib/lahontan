#!/usr/bin/python3

################################################################
# General Usage
################################################################

'''Usage:
    lahontan [options] [<command>] [<args>...]

Options:
    -h, --help
        Show this screen and exit
    --version
        Show version and exit
    --noconfirm
        Ignore all user prompts except JSON file creation

Available lahontan commands:
    fcounts     For running featureCounts pipeline
    string      For running Stringtie pipeline
    kall        For running kallisto pipeline
    bowtie2     For running Bowtie2 pipeline
    mj          Provoke questionnaire to make a Metadata file
    mb          Create trimmomatic blacklist
    clean       Clean any project directories
    fo          Finds optimal execution path for batch execution
    prepref     Pre-processes reference data
    gendef      Generate a default input file

See 'lahontan help <command>' for more information on a specific
command'''
VERSION = 'v0.1.1'

################################################################
# Importations
################################################################

from docopt import docopt
from timeit import default_timer as timer
from collections import OrderedDict as OD
import time
import pipeClasses
import os
import glob
import subprocess
import configparser

################################################################
# Utilities
################################################################

def testFile(filePath):
    """ Arguments:
            filePath : str; path to a file
        Returns:
            None
        Tests existence of file
    """
    if not os.path.exists(filePath):
        raise SystemExit('Error: {} does not exist\n\n{}'.format(filePath,__doc__))
    elif os.path.isdir(filePath):
        raise SystemExit('Error: {} is a directory\n\n{}'.format(filePath,__doc__))

def testDir(dirPath):
    """ Arguments:
            dirPath : str; path to a directory
        Returns:
            None
        Tests existence of directory
    """
    if not os.path.isdir(dirPath):
        raise SystemExit('Error: {} does not exist\n\n{}'.format(dirPath,__doc__))

def expandPath(path):
    """ Arguments:
            path : str; any path
        Returns:
            expandedPath : str; path with expanded variables and path
    """
    return os.path.abspath(os.path.expandvars(path))

def checkMan(default, manifest):
    """ Arguments:
         default :
        manifest :
        Returns:
            None
    """
    return default if manifest == None else manifest

def checkManBool(default, manifest):
    """ Arguments:
         default :
        manifest :
        Returns:
            None
    """
    return default if manifest == None else ""

def makeGlobalVars(arguments):
    ''' Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        Creates global variables NOCONFIRM, JSFI, and IS_REFERENCE_PREPARED
        for lahontan and pipeClasses.py
    '''
    # Global Variables to be used in scripts
    global NOCONFIRM
    NOCONFIRM = arguments['--noconfirm']
    global JSFI # Metadata JSON file
    if arguments['--jsonfile']:
        JSFI = expandPath(arguments['--jsonfile'])
        if JSFI:
            testFile(JSFI)
    else:
        JSFI = None
    global IS_REFERENCE_PREPARED
    IS_REFERENCE_PREPARED = arguments['--use-reference']
    pipeClasses.JSFI = JSFI
    pipeClasses.NOCONFIRM = NOCONFIRM
    pipeClasses.IS_REFERENCE_PREPARED = IS_REFERENCE_PREPARED

def qcRef(referenceDir, genome):
    """ Arguments:
            referenceDir : location of a reference directory
            genome : location of genome file with '.dna.' in name
        Returns:
            None
    """
    print(("[ {} ] Running Quality Control"+
        " Check on Reference Data...").format(pipeClasses.now()))
    command = r'''QCofRef.sh {} {}'''.format(referenceDir, genome)
    subprocess.run(command,
        shell=True,
        check=True,
        executable="/bin/bash")
    with open(os.path.join(referenceDir, 'Reference_Report.txt'),
            'r') as Report:
        print(Report.read())
    print('\nSee Reference_Report.txt to view initial Diagnostics')

def ppRef(referenceDir, cdna, basename, gtf, genome, cpulimit, args):
    ''' Arguments:
            referenceDir : location of a reference directory
            cdna : location of a CDNA file with a '.cdna.' in the name
            basename : basename of files; typically species name
            gtf : location of gtf file with '.gtf' ending in name
            genome : location of genome file with '.dna.' in name
            *cpulimit : multiprocessing cpu limit, default is to use
                        all available CPUs
        Returns:
            None

        Handles preprocessing without a class structure
    '''
    if cpulimit == None:
        cpulimit = os.cpu_count()
    ppLog = os.path.join(referenceDir, 'Preprocessing.log')
    #makeBlastdb = """time -p makeblastdb -in {cdna} -dbtype nucl 
    # -out {basename}.cdna.all""".format(**Context)
    makeBlastdb = ("""time -p {makeblastdb} -in {-in} -dbtype {-dbtype}"""+
        """ {other} -out {-out}""").format(
            **{
            "makeblastdb": checkMan("makeblastdb",
                args["prepref/makeBlastdb"]['makeblastdb']),
            "-in": checkMan(cdna, args["prepref/makeBlastdb"]['-in']),
            "-dbtype": checkMan('nucl',
                args["prepref/makeBlastdb"]['-dbtype']),
            "other": checkMan('', args["prepref/makeBlastdb"]['other']),
            "-out": checkMan("{}.cdna.all".format(basename),
                args["prepref/makeBlastdb"]['-out'])
            })
    #extractSpliceSites = """time -p extract_splice_sites.py {gtf} > 
    # splice_sites.txt""".format(**Context)
    extractSpliceSites = ("""time -p {extract_splice_sites} {other}"""+
        """ {gtf} > {out}""").format(
            **{
            "extract_splice_sites": checkMan("extract_splice_sites.py",
                args["prepref/extractSpliceSites"]['extract_splice_sites.py']),
            "other": checkMan('', args["prepref/extractSpliceSites"]['other']),
            "gtf": checkMan(gtf, args["prepref/extractSpliceSites"]['gtf']),
            "out": checkMan("splice_sites.txt", args["prepref/extractSpliceSites"]['out'])
            })
    #extractExons = """time -p extract_exons.py {gtf} > 
    # known_exons.txt""".format(**Context)
    extractExons = ("""time -p {extract_exons} {other} {gtf} >"""+
        """ {out}""").format(
            **{
            "extract_exons": checkMan("extract_exons.py",
                args["prepref/extractExons"]['extract_exons.py']),
            "other": checkMan('', args["prepref/extractExons"]['other']),
            "gtf": checkMan(gtf, args["prepref/extractExons"]['gtf']),
            "out": checkMan("known_exons.txt",
                args["prepref/extractExons"]['out'])
            })
    #hisatBuild = """time -p hisat2-build -p {cpu} --ss splice_sites.txt 
    # --exon known_exons.txt {genome} {basename}""".format(**Context)
    hisatBuild = ("""time -p {hisat2-build} -p {-p} --ss {--ss}"""+
        """ --exon {--exon} {other} {genome} {basename}""").format(
            **{
            "hisat2-build": checkMan("hisat2-build",
                args["prepref/hisatBuild"]['hisat2-build']),
            "-p": checkMan(cpulimit, args["prepref/hisatBuild"]['-p']),
            "--ss": checkMan("splice_sites.txt",
                args["prepref/hisatBuild"]['--ss']),
            "--exon": checkMan("known_exons.txt",
                args["prepref/hisatBuild"]['--exon']),
            "other": checkMan('', args["prepref/hisatBuild"]['other']),
            "genome": checkMan(genome, args["prepref/hisatBuild"]['genome']),
            "basename": checkMan(basename,
                args["prepref/hisatBuild"]['basename']),
            })
    #samtoolsFaidx = """time -p samtools faidx {genome}""".format(**Context)
    samtoolsFaidx = ("""time -p {samtools} faidx {other} {genome}""").format(
            **{
            "samtools": checkMan("samtools",
                args["prepref/samtoolsFaidx"]['samtools']),
            "other": checkMan('', args["prepref/samtoolsFaidx"]['other']),
            "genome": checkMan(genome,
                args["prepref/samtoolsFaidx"]['genome']),
            })
    os.chdir(referenceDir)
    print("[ {} ] Preprocessing Data...".format(pipeClasses.now()))
    with open(ppLog, 'w') as PPlog:
        if args['prepref/main']['makeBlastdb']:
            PPlog.write('\n{}\n{}'.format(makeBlastdb,'='*50))
            subprocess.run(makeBlastdb,
                shell=True,
                check=True,
                executable="/bin/bash",
                stdout=PPlog,
                stderr=subprocess.STDOUT)
        else:
            print('makeBlastdb skipped due to manifest\n')
            PPlog.write('makeBlastdb skipped due to manifest\n')
        if args['prepref/main']['extractSpliceSites']:
            PPlog.write('\n{}\n{}'.format(extractSpliceSites,'='*50))
            subprocess.run(extractSpliceSites,
                shell=True,
                check=True,
                executable="/bin/bash",
                stdout=PPlog,
                stderr=subprocess.STDOUT)
        else:
            print('extractSpliceSites skipped due to manifest\n')
            PPlog.write('extractSpliceSites skipped due to manifest\n')
        if args['prepref/main']['extractExons']:
            PPlog.write('\n{}\n{}'.format(extractExons,'='*50))
            subprocess.run(extractExons,
                shell=True,
                check=True,
                executable="/bin/bash",
                stdout=PPlog,
                stderr=subprocess.STDOUT)
        else:
            print('extractExons skipped due to manifest\n')
            PPlog.write('extractExons skipped due to manifest\n')
        if args['prepref/main']['hisatBuild']:
            PPlog.write('\n{}\n{}'.format(hisatBuild,'='*50))
            subprocess.run(hisatBuild,
                shell=True,
                check=True,
                executable="/bin/bash",
                stdout=PPlog,
                stderr=subprocess.STDOUT)
        else:
            print('hisatBuild skipped due to manifest\n')
            PPlog.write('hisatBuild skipped due to manifest\n')
        if args['prepref/main']['samtoolsFaidx']:
            PPlog.write('\n{}\n{}'.format(samtoolsFaidx,'='*50))
            subprocess.run(samtoolsFaidx,
                shell=True,
                check=True,
                executable="/bin/bash",
                stdout=PPlog,
                stderr=subprocess.STDOUT)
        else:
            print('samtoolsFaidx skipped due to manifest\n')
            PPlog.write('samtoolsFaidx skipped due to manifest\n')

def createKallistoIndex(referenceDir, cdna, basename, arguments):
    """ Arguments:
            referenceDir : location of a reference directory
            cdna : location of a CDNA file with a '.cdna.' in the name
            basename : basename of files; typically species name
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        Handles creating a kallisto index without a class structure
    """
    indexCheck = os.path.join(referenceDir, 'KaliIndexBuilt')
    if not os.path.exists(indexCheck):
        localArgs = arguments['prepref/createKallistoIndex']
        logFile = os.path.join(referenceDir, 'KallistoRuntime.log')
        # Making Command
        #{{ time -p kallisto index -i {basename}.kali.cdna.fa.idx
        # {cdna}; }} >> {log} 2>&1"
        command = ("""{{ time -p {kallisto} index -i {-i} {other} {cdna};"""+
            """ }} >> {log} 2>&1""")
        Context = {
            "kallisto": checkMan("kallisto", localArgs['kallisto']),
            "-i": checkMan("{}.kali.cdna.fa.idx".format(basename),
                localArgs['-i']),
            "other": checkMan('', localArgs['other']),
            "cdna": checkMan(cdna, localArgs['cdna']),
            "log": logFile,
            }
        goodCommand = command.format(**Context)
        # Executing
        print('[ {} ] Building kallisto index...'.format(pipeClasses.now()))
        os.chdir(referenceDir)
        subprocess.run(goodCommand,
            shell=True,
            check=True,
            executable="/bin/bash")
        with open(indexCheck,'w') as F:
                F.write('True')
    else:
        print('Error: Cannot build Kallisto index; already exists')

def createBowtie2Index(referenceDir, genome, basename, arguments):
    """ Arguments:
            referenceDir : location of a reference directory
            genome : location of a DNA file with a '.dna.' in the name
            basename : basename of files; typically species name
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        Handles creating a bowtie2 index without a class structure
    """
    indexCheck = os.path.join(referenceDir, 'B2IndexBuilt')
    if not os.path.exists(indexCheck):
        if arguments['-r']:
            genome = os.path.join(expandPath(arguments['-r']),genome)
            basename = os.path.join(expandPath(arguments['-r']),basename)
        localArgs = arguments['prepref/createBowtie2Index']
        logFile = os.path.join(referenceDir, 'Bowtie2Runtime.log')
        # Making Command
        command = ("""{{ time -p {bowtie2-build} --threads {--threads}"""+
            """ {other} {genome} {basename}; }} >> {log} 2>&1""")
        Context = {
            "bowtie2-build": checkMan("bowtie2-build", localArgs['bowtie2-build']),
            "--threads": checkMan(str(os.cpu_count()), localArgs['--threads']),
            "other": checkMan('', localArgs['other']),
            "genome": checkMan(genome, localArgs['genome']),
            "basename": checkMan(basename, localArgs['basename']),
            "log": logFile,
            }
        goodCommand = command.format(**Context)
        # Executing
        print('[ {} ] Building Bowtie2 index...'.format(pipeClasses.now()))
        os.chdir(referenceDir)
        subprocess.run(goodCommand,
            shell=True,
            check=True,
            executable="/bin/bash")
        with open(indexCheck,'w') as F:
                F.write('True')
    else:
        print('Error: Cannot build Bowtie2 index; already exists')

def clean(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        Handles lahontan clean command
    """
    # Handling Cleaning Arguments
    possibleCleanArguments = ['All','Reference','Data','Postprocessing']
    if arguments['--clean']:
        assert arguments['--clean'] in possibleCleanArguments, 'Invalid Cleaning Argument: Run lahontan -h for available arguments'
        PROJ = pipeClasses.Experiment(expandPath(arguments['<input>']))
        if arguments['--clean'] != 'All':
            if arguments['--clean'] == 'Data':
                if not os.path.isdir(PROJ.Data):
                    raise SystemExit('{} does not exist'.format(PROJ.Data))
            if arguments['--clean'] == 'Reference':
                if not os.path.isdir(PROJ.Reference):
                    raise SystemExit('{} does not exist'.format(PROJ.Reference))
            if arguments['--clean'] == 'Postprocessing':
                if not os.path.isdir(PROJ.Postprocessing):
                    raise SystemExit('{} does not exist'.format(PROJ.Postprocessing))
        if NOCONFIRM:
            PROJ.clean(arguments['--clean'])
            raise SystemExit
        else:
            while True:
                answer = input('Are you sure you wish to clean {}?(y/n) '.format(arguments['--clean']))
                if answer == 'y':
                    PROJ.clean(arguments['--clean'])
                    raise SystemExit
                elif answer == 'n':
                    raise SystemExit
                else:
                    print('Please answer y or n')
    elif arguments['--sampleclean']:
        PROJ = pipeClasses.Experiment(expandPath(arguments['<input>']))
        if not os.path.isdir(str(PROJ.Data + '/' + arguments['--sampleclean'])):
            raise SystemExit('{} does not exist'.format(str(PROJ.Data + '/' +
                                                        arguments['--sampleclean'])))
        if NOCONFIRM:
            PROJ.clean('Sample',arguments['--sampleclean'])
            raise SystemExit
        else:
            while True:
                answer = input('Are you sure you wish to clean {}?(y/n) '.format(arguments['--sampleclean']))
                if answer == 'y':
                    PROJ.clean('Sample',arguments['--sampleclean'])
                    raise SystemExit
                elif answer == 'n':
                    raise SystemExit
                else:
                    print('Please answer y or n')
        raise SystemExit
    else:
        if NOCONFIRM:
            PROJ.clean('All')
            raise SystemExit
        else:
            while True:
                answer = input('Are you sure you wish to clean All?(y/n) ')
                if answer == 'y':
                    PROJ.clean('All')
                    raise SystemExit
                elif answer == 'n':
                    raise SystemExit
                else:
                    print('Please answer y or n')

def makeBatch(ExperimentClass, arguments):
    ''' Arguments:
            ExperimentClass = class; experiment to run analysis on
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        If --makebatch argument given, then make batch script to be
        used with slurm, and then exit
    '''
    # Making slurm batch files if necessary
    if arguments['--batchjson']:
        testFile(expandPath(arguments['--batchjson']))
        pipeClasses.checkJSON(expandPath(arguments['--batchjson']))
    if arguments['--makebatch']:
        preNodes,Nodes = arguments['--makebatch'].split(','),[]
        for node in preNodes:
            if not node.isdigit() or int(node) <= 0:
                raise SystemExit('Not a valid argument to --makebatch: {}'.format(
                                        arguments['--makebatch']))
            Nodes.append(int(node))
        if arguments['<command>'] == 'string':
            ExperimentClass.makeStringtieBatch(cluster=Nodes,
                    jsonFile=expandPath(arguments['--batchjson']))
        elif arguments['<command>'] == 'kall':
            ExperimentClass.makeKallistoBatch(cluster=Nodes,
                    jsonFile=expandPath(arguments['--batchjson']))
        else:
            ExperimentClass.makeBatch(cluster=Nodes,
                    jsonFile=expandPath(arguments['--batchjson']))
        raise SystemExit('Batch file successfully created:\n\t{}/pipeBatch'.format(os.getcwd()))

def checkMaxCPU(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            int or None; the max number of CPU to use, if None
                         then there is no limit
        Checks --maxcpu option from CLI, if option not given
        then default is to use all available CPU
    """
    # Returning a maximum CPU value if given
    if arguments['--maxcpu']:
        if arguments['--maxcpu'].isdigit():
            Max = int(arguments['--maxcpu'])
            if Max <= os.cpu_count() and Max > 0:
                return Max
            else:
                raise SystemExit('--maxcpu greater than available CPUs')
        else:
            raise SystemExit('Invalid value to --maxcpu: {}'.format(
                        arguments['--maxcpu']))
    else:
        return None

def setGlobalLog(ExperimentClass):
    """ Arguments:
            ExperimentClass : Experiment; instance of a class
        Returns:
            None

        Creates a global variable, RUNTIMELOG, that specifies
        location of execution log
    """
    # Inititiating a Runtime Log global location
    global RUNTIMELOG
    RUNTIMELOG = str(os.path.join(ExperimentClass.Project,'Runtime.log'))
    pipeClasses.RUNTIMELOG = RUNTIMELOG

def checkdashr(ExperimentClass, arguments):
    """ Arguments:
            ExperimentClass : Experiment; instance of a class
            arguments : dictionary; CLI arguments from docopt
        Returns:
            samples : list; list of samples to execute

        Checks --runsample argument from CLI
    """
    # Running a specific sample
    if arguments['--runsample']:
        samples = arguments['--runsample'].split(',')
        possibleSamples = [str(a+1) for a in range(ExperimentClass.Numsamples)]
        runsampleUsage = ('Invalid argument to --runsample: {}'.format(arguments['--runsample']) +
                            'Possible arguments: {}'.format(str(possibleSamples)))
        if len(set(samples)) != len(samples):
            raise SystemExit(runsampleUsage)
        for sample in samples:
            if sample not in possibleSamples:
                raise SystemExit(runsampleUsage)
        return samples

def checkdashe(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            executionStages : list; list of stages to execute

        Checks --execute argument from CLI
    """
    # Determining what stages to run of Pipeline
    if arguments['--execute'] == 'A':
        executionStages = ["1","2","3","4","5"]
    else:
        executionStages = arguments['--execute'].split(',')
    possibleStages = ["1","2","3","4","5","A"]
    executeUsage = ('Invalid argument to --execute: {}'.format(
        arguments['--execute']) + 'Possible arguments: {}'.format(str(possibleStages)))
    if len(set(executionStages)) != len(executionStages):
        raise SystemExit(executeUsage)
    for stage in executionStages:
        if stage not in possibleStages:
            raise SystemExit(executeUsage)
    return executionStages

def checkdashp(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            executionPhases : list; list of phases to execute for
                              Stringtie

        Checks --phase argument from CLI for lahontan string command
    """
    # Handling string --phase
    possiblePhases = ['a','b','c','ab','bc','abc']
    stringtieUsage = ('Invalid argument to --phase: {}'.format(arguments['--phase']) +
                        'Possible arguments: {}'.format(str(possiblePhases)))
    if arguments['--phase'] not in possiblePhases:
        raise SystemExit(stringtieUsage)
    executionPhases = arguments['--phase']
    return executionPhases

def stage1ReadyToExecute(ExperimentClass):
    """ Arguments:
            ExperimentClass : Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    testFile(ExperimentClass.inputPath)
    return True

def stage2ReadyToExecute(ExperimentClass):
    """ Arguments:
            ExperimentClass : Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    projectPath = ExperimentClass.Project
    dataPath = ExperimentClass.Data
    refPath = ExperimentClass.Reference
    origPath = ExperimentClass.Original
    ppPath = ExperimentClass.Postprocessing
    for directory in [projectPath, dataPath, refPath, origPath, ppPath]:
        testDir(directory)
    for sample in glob.glob(os.path.join(dataPath,'sample_*')):
        if len(glob.glob(os.path.join(sample,'*'))) < 2:
            raise SystemExit('Symbolic links to Original data missing')
    for ref in [os.path.join(ExperimentClass.Reference, f) for f
            in [ExperimentClass.Gtf, ExperimentClass.Cdna, ExperimentClass.Genome]]:
        testFile(ref)
    return True

def stage3FCReadyToExecute(FCountsClass):
    """ Arguments:
            FCountsClass : featureCounts Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    if FCountsClass.isReferencePrepared():
        return True
    return False

def stage3STReadyToExecute(STClass):
    """ Arguments:
            STClass : Stringtie Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
            None
    """
    if STClass.isReferencePrepared():
        return True
    return False

def stage3KAReadyToExecute(KAClass):
    """ Arguments:
            KAClass : Kallisto Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    if KAClass.isReferencePrepared() and not KAClass.needToBuildKaliIndex():
        return True
    return False

def stage3BTReadyToExecute(BTClass):
    """ Arguments:
            BTClass : Bowtie Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    if BTClass.isReferencePrepared() and not BTClass.needToBuildB2Index():
        return True
    return False

def stage4ReadyToExecute(ExperimentClass):
    """ Arguments:
            ExperimentClass : Experiment; instance of a class
        Returns:
            None
    """
    return ExperimentClass.is3Finished()

def stage5FCReadyToExecute(FCountsClass):
    """ Arguments:
            FCountsClass : featureCounts Experiment; instance of a class
        Returns:
            None
    """
    if (not os.path.exists(os.path.join(FCountsClass.Postprocessing, 'makeEdge.r')) or
        not os.path.exists(os.path.join(FCountsClass.Postprocessing, 'makeReport.r'))):
        return False
    return True

def stage5STReadyToExecute(STClass):
    """ Arguments:
            STClass : Stringtie Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    if not os.path.exists(os.path.join(STClass.Postprocessing, 'runBallgown.r')):
        return False
    return True

def stage5KAReadyToExecute(KAClass):
    """ Arguments:
            KAClass : Kallisto Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    if not os.path.exists(os.path.join(KAClass.Postprocessing, 'runSleuth.r')):
        return False
    return True

def readInputFile(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            config : dict; arguments from input manifest

        Reads input manifest and stores into a dictionary
    """
    try:
        inputFile = expandPath(arguments['<input>'])
    except KeyError:
        try:
            # Mode is prepref -i
            inputFile = expandPath(arguments['-i'])
        except TypeError:
            # Mode is prepref -r
            inputFile = expandPath(arguments['tmpDefaults'])
    testFile(inputFile)
    config = configparser.ConfigParser(interpolation=configparser.ExtendedInterpolation(),
            dict_type=OD)
    config.optionxform = str
    config.BOOLEAN_STATES = {'True': True,
            'False': False,
            'true': True,
            'false': False,
            'None': False,
            'none': False}
    config.read(inputFile)
    return config

def updateArgs(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            updatedArgs : dict; containing necessary adjustments from manifest

        Combines command line arguments and manifest arguments
        Note: command line arguments take precedence i.e. if command line argument
        specified, use command line argument, else default to manifest
    """
    # Generate a fallback defaults file
    while True:
        counter=0
        try:
            tmpDefaults = '.tmplahontanDefaults{}.ini'.format(counter)
            generateDefaultInputFile({'--filename': tmpDefaults,'--mode': arguments['<command>']})
            FALLBACK = readInputFile({'<input>': tmpDefaults})
            break
        except:
            counter += 1
    mode = arguments['<command>']
    updatedArgs = {}
    arguments.update({'tmpDefaults': tmpDefaults})
    Manifest = readInputFile(arguments)
    try:
        manifestArgs = Manifest[mode]
    except KeyError:
        manifestArgs = FALLBACK[mode]
    # Add mode options i.e. options that can be specified on command line
    for option in arguments:
        if arguments[option] == False:
            updatedArgs[option] = manifestArgs.getboolean(option, fallback=FALLBACK[mode].getboolean(option))
        elif arguments[option] == None:
            if manifestArgs.get(option, fallback=FALLBACK[mode].get(option)) == 'None':
                updatedArgs[option] = None
            else:
                updatedArgs[option] = manifestArgs.get(option, fallback=FALLBACK[mode].get(option))
        else:
            updatedArgs[option] = arguments[option]
    # Add all other manifest options
    for section in FALLBACK.sections():
        if section != mode:
            updatedArgs[section] = {}
            for option in FALLBACK[section]:
                try:
                    if Manifest[section].get(option, fallback=FALLBACK[section].get(option)) == 'None':
                        updatedArgs[section][option] = None
                    elif Manifest[section].get(option, fallback=FALLBACK[section].get(option)) == 'False':
                        updatedArgs[section][option] = False
                    elif Manifest[section].get(option, fallback=FALLBACK[section].get(option)) == 'True':
                        updatedArgs[section][option] = True
                    else:
                        updatedArgs[section][option] = Manifest[section].get(option, fallback=FALLBACK[section].get(option))
                except:
                    if FALLBACK[section].get(option) == 'None':
                        updatedArgs[section][option] = None
                    elif FALLBACK[section].get(option) == 'False':
                        updatedArgs[section][option] = False
                    elif FALLBACK[section].get(option) == 'True':
                        updatedArgs[section][option] = True
                    else:
                        updatedArgs[section][option] = FALLBACK[section].get(option)
    # Remove tmp fallback defaults file
    try:
        os.remove(tmpDefaults)
    except FileNotFoundError:
        pass
    return updatedArgs

def generatePreprefInput(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None
    """
    ############################################################
    # Setup
    ############################################################
    RNASEQDIR = os.path.expandvars('$RNASEQDIR')
    config = configparser.ConfigParser(
            interpolation=configparser.ExtendedInterpolation(),
            dict_type=OD)
    config.optionxform = str
    config.BOOLEAN_STATES = {
        'True': True,
        'False': False,
        'true': True,
        'false': False,
        'None': False,
        'none': False}
    pwd = os.path.abspath(os.curdir)
    ############################################################
    # Locations
    ############################################################
    config['locations'] = OD((
            ('Reference', pwd),
            ))
    ############################################################
    # Mode
    ############################################################
    config['mode'] = OD((
        ('prepref', 'True'),
        ))
    ############################################################
    # Main
    ############################################################
    config['prepref'] = OD((
        ('--qualitycheck', 'False'),
        ('--preprocess', 'False'),
        ('--kallisto', 'False'),
        ('--onlykallisto', 'False'),
        ('--bowtie2', 'False'),
        ('--onlybowtie2', 'False'),
        ('--maxcpu', 'None'),
        ))
    ############################################################
    # Executables
    ############################################################
    config['EXECUTABLES'] = OD((
            ('rnaseqdir', RNASEQDIR),
            ('kallisto', '${rnaseqdir}/kallisto'),
            ('makeblastdb', '${rnaseqdir}/makeblastdb'),
            ('extract_splice_sites.py', '${rnaseqdir}/extract_splice_sites.py'),
            ('extract_exons.py', '${rnaseqdir}/extract_exons.py'),
            ('hisat2-build', '${rnaseqdir}/hisat2-build'),
            ('samtools', '${rnaseqdir}/samtools'),
            ('bowtie2-build', '${rnaseqdir}/bowtie2-build'),
            ))
    ############################################################
    # PREPREF
    ############################################################
    config['prepref/main'] = OD((
            ('qcRef', 'True'),
            ('createKallistoIndex', 'True'),
            ('createBowtie2Index', 'True'),
            ('makeBlastdb', 'True'),
            ('extractSpliceSites', 'True'),
            ('extractExons', 'True'),
            ('hisatBuild', 'True'),
            ('samtoolsFaidx', 'True'),
            ))
    # prepref/main/createKallistoIndex
    # kallisto index -i {basename}.kali.cdna.fa.idx {other} {cdna}
    config['prepref/createKallistoIndex'] = OD((
        ('kallisto', '${EXECUTABLES:kallisto}'),
        ('-i', 'None'),
        ('other', 'None'),
        ('cdna', 'None'),
        ))
    # prepref/main/createBowtie2Index
    # bowtie2-build {other} {genome} {basename}
    config['prepref/createBowtie2Index'] = OD((
        ('bowtie2-build', '${EXECUTABLES:bowtie2-build}'),
        ('--threads', 'None'),
        ('other', 'None'),
        ('genome', 'None'),
        ('basename', 'None'),
        ))
    # prepref/main/makeBlastdb
    # makeblastdb -in {cdna} -dbtype nucl {other} -out {basename}.cdna.all
    config['prepref/makeBlastdb'] = OD((
        ('makeblastdb', '${EXECUTABLES:makeblastdb}'),
        ('-in', 'None'),
        ('-dbtype', 'None'),
        ('other', 'None'),
        ('-out', 'None'),
        ))
    # prepref/main/extractSpliceSites
    # extract_splice_sites.py {other} {gtf} > splice_sites.txt
    config['prepref/extractSpliceSites'] = OD((
        ('extract_splice_sites.py', '${EXECUTABLES:extract_splice_sites.py}'),
        ('other', 'None'),
        ('gtf', 'None'),
        ('out', 'None'),
        ))
    # prepref/main/extractExons
    # extract_exons.py {other} {gtf} > known_exons.txt
    config['prepref/extractExons'] = OD((
        ('extract_exons.py', '${EXECUTABLES:extract_exons.py}'),
        ('other', 'None'),
        ('gtf', 'None'),
        ('out', 'None'),
        ))
    # prepref/main/hisatBuild
    # hisat2-build -p {cpu} --ss splice_sites.txt
    # --exon known_exons.txt {other} {genome} {basename}
    config['prepref/hisatBuild'] = OD((
        ('hisat2-build', '${EXECUTABLES:hisat2-build}'),
        ('-p', 'None'),
        ('--ss', 'None'),
        ('--exon', 'None'),
        ('other', 'None'),
        ('genome', 'None'),
        ('basename', 'None'),
        ))
    # prepref/main/samtoolsFaidx
    # samtools faidx {genome} {other}
    config['prepref/samtoolsFaidx'] = OD((
        ('samtools', '${EXECUTABLES:samtools}'),
        ('genome', 'None'),
        ('other', 'None'),
        ))
    ############################################################
    with open(arguments['--filename'], 'w') as configfile:
        config.write(configfile)
    ############################################################

################################################################
# Usage Functions
################################################################

def featureCounts(arguments):
    '''Usage:
    lahontan fcounts [options] <input>

Options:
    -h, --help
        Show this screen and exit
    -e <stage>, --execute <stage>
        Comma-separated list of stages to be executed.
        Possible stages include:
            1: Creating Project Structure
            2: Preparing Reference Data
            3: Running actual Pipeline
            4: Preparing for R analysis
            5: Running R analysis
            A: (1,2,3,4,5); A=all i.e. runs entire pipeline
    -r <integer>, --runsample <integer>
        Runs Stage 3 of the pipeline on the sample specified
        by the integer
    -j <jsonFile>, --jsonfile <jsonFile>
        Ignores JSON Metadata file creation and uses specified
        path to JSON Metadata
    --maxcpu <CPUs>
        Limits number of CPUs used by Pipeline. Default is to
        use all available CPUs
    --makebatch <cluster>
        Makes batch file to be used with slurm. The argument
        it takes is a comma-separated list of CPUs on each
        node in your cluster
    --batchjson <pathtoJSON>
        Uses json file already created to make batch file
    --edger
        Runs edgeR analysis only. Default is to run both
    --deseq
        Runs DESeq2 analysis only. Default is to run both
    --noconfirm
        Ignore all user prompts except JSON file creation
    --use-blacklist <blacklist>
        Trimmomatic blacklist used for quality control
    --use-reference
        Use Reference data that has already been prepared.
        Put path to already prepared reference data in
        INPUT file
        Note: Need to run Stage 1 with this argument or add to
        "--makebatch" argument'''
    makeGlobalVars(arguments)
    cpuLimit = checkMaxCPU(arguments)
    testFile(expandPath(arguments['<input>']))
    testFile(expandPath(arguments['--use-blacklist']))
    FCClass = pipeClasses.FCountsExperiment(arguments)
    # Make batch file if necessary
    makeBatch(FCClass, arguments)
    setGlobalLog(FCClass)
    samplesToExecute = checkdashr(FCClass, arguments)
    stagesToExecute = checkdashe(arguments)
    # Run Stage 1 if necessary
    if '1' in stagesToExecute and stage1ReadyToExecute(FCClass):
        FCClass.runStage1()
    # Run Stage 2 if necessary
    if '2' in stagesToExecute and stage2ReadyToExecute(FCClass):
        FCClass.runStage2()
    # Run Stage 3 if necessary
    if '3' in stagesToExecute and stage3FCReadyToExecute(FCClass):
        if samplesToExecute == None:
            FCClass.runStage3()
        else:
            for sample in samplesToExecute:
                FCClass.executeSample(sample)
    # Run Stage 4 if necessary
    if '4' in stagesToExecute and stage4ReadyToExecute(FCClass):
        FCClass.runStage4()
    # Run Stage 5 if necessary
    if '5' in stagesToExecute and stage5FCReadyToExecute(FCClass):
        if arguments['--edger'] or arguments['--deseq']:
            if arguments['--edger']:
                FCClass.runEdgeR()
            if arguments['--deseq']:
                FCClass.runDESeq()
        else:
            FCClass.runStage5()

def stringtie(arguments):
    '''Usage:
    lahontan string [options] <input>

Options:
    -h, --help
        Show this screen and exit
    -e <stage>, --execute <stage>
        Comma-separated list of stages to be executed.
        Possible stages include:
            1: Creating Project Structure
            2: Preparing Reference Data
            3: Running actual Pipeline
            4: Preparing for R analysis
            5: Running R analysis
            A: (1,2,3,4,5); A=all i.e. runs entire pipeline
    -r <integer>, --runsample <integer>
        Runs Stage 3 of the pipeline on the sample specified
        by the integer
    -p <phase>, --phase <phase>
        Use stringtie tools to replace featureCounts. phase can
        be any of: "a","b","c","ab","bc","abc"
        Option also used to specify stringtie postprocessing
        options in which case use: "--execute 4 --stringtie abc"
        Note: If you will be running phase b, you cannot specify
        a sample to run with --runsample
    -j <jsonFile>, --jsonfile <jsonFile>
        Ignores JSON Metadata file creation and uses specified
        path to JSON Metadata
    --maxcpu <CPUs>
        Limits number of CPUs used by Pipeline. Default is to
        use all available CPUs
    --noconfirm
        Ignore all user prompts except JSON file creation
    --use-blacklist <blacklist>
        Trimmomatic blacklist used for quality control
    --use-reference
        Use Reference data that has already been prepared.
        Put path to already prepared reference data in
        INPUT file
        Note: Need to run Stage 1 with this argument or add to
        "--makebatch" argument
    --makebatch <cluster>
        Makes batch file to be used with slurm. The argument
        it takes is a comma-separated list of CPUs on each
        node in your cluster
    --batchjson <pathtoJSON>
        Uses json file already created to make batch file'''
    makeGlobalVars(arguments)
    cpuLimit = checkMaxCPU(arguments)
    testFile(expandPath(arguments['<input>']))
    testFile(expandPath(arguments['--use-blacklist']))
    StringtieClass = pipeClasses.StringtieExperiment(arguments)
    # Make batch file if necessary
    makeBatch(StringtieClass, arguments)
    setGlobalLog(StringtieClass)
    samplesToExecute = checkdashr(StringtieClass, arguments)
    stagesToExecute = checkdashe(arguments)
    phasesToExecute = checkdashp(arguments)
    # Run Stage 1 if necessary
    if '1' in stagesToExecute and stage1ReadyToExecute(StringtieClass):
        StringtieClass.runStage1()
    # Run Stage 2 if necessary
    if '2' in stagesToExecute and stage2ReadyToExecute(StringtieClass):
        StringtieClass.runStage2()
    # Run Stage 3 if necessary
    if '3' in stagesToExecute and stage3STReadyToExecute(StringtieClass):
        if samplesToExecute == None:
            StringtieClass.runStage3(phasesToExecute)
        else:
            for sample in samplesToExecute:
                StringtieClass.executeSample(sample, phasesToExecute)
    # Run Stage 4 if necessary
    if '4' in stagesToExecute and stage4ReadyToExecute(StringtieClass):
        StringtieClass.runStage4()
    # Run Stage 5 if necessary
    if '5' in stagesToExecute and stage5STReadyToExecute(StringtieClass):
        StringtieClass.runStage5()

def kallisto(arguments):
    '''Usage:
    lahontan kall [options] <input>

Options:
    -h, --help
        Show this screen and exit
    -e <stage>, --execute <stage>
        Comma-separated list of stages to be executed.
        Possible stages include:
            1: Creating Project Structure
            2: Preparing Reference Data
            3: Running actual Pipeline
            4: Preparing for R analysis
            5: Running R analysis
            A: (1,2,3,4,5); A=all i.e. runs entire pipeline
    -r <integer>, --runsample <integer>
        Runs Stage 3 of the pipeline on the sample specified
        by the integer
    -j <jsonFile>, --jsonfile <jsonFile>
        Ignores JSON Metadata file creation and uses specified
        path to JSON Metadata
    --maxcpu <CPUs>
        Limits number of CPUs used by Pipeline. Default is to
        use all available CPUs
    --noconfirm
        Ignore all user prompts except JSON file creation
    --use-blacklist <blacklist>
        Trimmomatic blacklist used for quality control
    --use-reference
        Use Reference data that has already been prepared.
        Put path to already prepared reference data in
        INPUT file
        Note: Need to run Stage 1 with this argument or add to
        "--makebatch" argument
    --makebatch <cluster>
        Makes batch file to be used with slurm. The argument
        it takes is a comma-separated list of CPUs on each
        node in your cluster
    --batchjson <pathtoJSON>
        Uses json file already created to make batch file'''
    makeGlobalVars(arguments)
    cpuLimit = checkMaxCPU(arguments)
    testFile(expandPath(arguments['<input>']))
    testFile(expandPath(arguments['--use-blacklist']))
    KallistoClass = pipeClasses.KallistoExperiment(arguments)
    # Make batch file if necessary
    makeBatch(KallistoClass, arguments)
    setGlobalLog(KallistoClass)
    samplesToExecute = checkdashr(KallistoClass, arguments)
    stagesToExecute = checkdashe(arguments)
    # Run Stage 1 if necessary
    if '1' in stagesToExecute and stage1ReadyToExecute(KallistoClass):
        KallistoClass.runStage1()
    # Run Stage 2 if necessary
    if '2' in stagesToExecute and stage2ReadyToExecute(KallistoClass):
        KallistoClass.runStage2()
    # Run Stage 3 if necessary
    if '3' in stagesToExecute and stage3KAReadyToExecute(KallistoClass):
        if samplesToExecute == None:
            KallistoClass.runStage3()
        else:
            for sample in samplesToExecute:
                KallistoClass.executeSample(sample)
    # Run Stage 4 if necessary
    if '4' in stagesToExecute and stage4ReadyToExecute(KallistoClass):
        KallistoClass.runStage4()
    # Run Stage 5 if necessary
    if '5' in stagesToExecute and stage5KAReadyToExecute(KallistoClass):
        KallistoClass.runStage5()

def bowtie2(arguments):
    '''Usage:
    lahontan bowtie2 [options] <input>

Options:
    -h, --help
        Show this screen and exit
    -e <stage>, --execute <stage>
        Comma-separated list of stages to be executed.
        Possible stages include:
            1: Creating Project Structure
            2: Preparing Reference Data
            3: Running actual Pipeline
            4: Post-processing
            A: (1,2,3,4); A=all i.e. runs entire pipeline
    -r <integer>, --runsample <integer>
        Runs Stage 3 of the pipeline on the sample specified
        by the integer
    -j <jsonFile>, --jsonfile <jsonFile>
        Ignores JSON Metadata file creation and uses specified
        path to JSON Metadata
    --maxcpu <CPUs>
        Limits number of CPUs used by Pipeline. Default is to
        use all available CPUs
    --noconfirm
        Ignore all user prompts except JSON file creation
    --use-blacklist <blacklist>
        Trimmomatic blacklist used for quality control
    --use-reference
        Use Reference data that has already been prepared.
        Put path to already prepared reference data in
        INPUT file
        Note: Need to run Stage 1 with this argument or add to
        "--makebatch" argument
    --makebatch <cluster>
        Makes batch file to be used with slurm. The argument
        it takes is a comma-separated list of CPUs on each
        node in your cluster
    --batchjson <pathtoJSON>
        Uses json file already created to make batch file'''
    makeGlobalVars(arguments)
    cpuLimit = checkMaxCPU(arguments)
    testFile(expandPath(arguments['<input>']))
    testFile(expandPath(arguments['--use-blacklist']))
    Bowtie2Class = pipeClasses.Bowtie2Experiment(arguments)
    makeBatch(Bowtie2Class, arguments)
    setGlobalLog(Bowtie2Class)
    samplesToExecute = checkdashr(Bowtie2Class, arguments)
    stagesToExecute = checkdashe(arguments)
    # Run Stage 1 if necessary
    if '1' in stagesToExecute and stage1ReadyToExecute(Bowtie2Class):
        Bowtie2Class.runStage1()
    # Run Stage 2 if necessary
    if '2' in stagesToExecute and stage2ReadyToExecute(Bowtie2Class):
        Bowtie2Class.runStage2()
    # Run Stage 3 if necessary
    if '3' in stagesToExecute and stage3BTReadyToExecute(Bowtie2Class):
        if samplesToExecute == None:
            Bowtie2Class.runStage3()
        else:
            for sample in samplesToExecute:
                Bowtie2Class.executeSample(sample)
    # Run Stage 4 if necessary
    if '4' in stagesToExecute and stage4ReadyToExecute(Bowtie2Class):
        Bowtie2Class.runStage4()

def cleanup(arguments):
    '''Usage:
    lahontan clean [options] <input>

Options:
    -h, --help
        Show this screen and exit
    -c <placeToClean>, --clean <placeToClean>
        Cleans <placeToClean>; Possible places include:
            Reference
            Data
            Postprocessing
            All
    --sampleclean <sampleName>
        Similar to --clean; but instead just cleans a
        single sample directory, <sampleName>'''
    makeGlobalVars(arguments)
    testFile(expandPath(arguments['<input>']))
    clean(arguments)

def referenceProcessing(arguments):
    '''Usage:
    lahontan prepref [options] (-r <referenceDir> | -i <input>)

Options:
    -h, --help
        Show this screen and exit
    -r <referenceDir>
        One of the mandatory arguments i.e. must specify either
        r OR i options.
        Option value is a path to directory that contains a GTF,
        cDNA, and reference genome
    -i <input>
        One of the mandatory arguments i.e. must specify either
        r OR i options
        Option value is a path to input file that must contain
        at least a path to reference directory
        Note: a default input file can be generated with:
            lahontan gendef --mode prepref
    -q, --qualitycheck
        Only run quality check on references. Default behavior
        is to run both quality control and preprocessing
    -p, --preprocess
        Only run preprocessing on references. Default behavior
        is to run both quality control and preprocessing
    -k, --kallisto
        Additionally build kallisto index
        Note: index required if kallisto pipeline to be used
    --onlykallisto
        Build only the kallisto index
    -b, --bowtie2
        Additionally build Bowtie2 index
        Note: index required if Bowtie2 pipeline to be used
    --onlybowtie2
        Build only the Bowtie2 index
    --maxcpu <CPUs>
        Limit the number of CPU that get used to preprocess
        reference data.
        Note: default is to use all available'''
    cpuLimit = checkMaxCPU(arguments)
    if arguments['-r']:
        referencePath = expandPath(arguments['-r'])
    else:
        referencePath = expandPath(arguments['locations']['Reference'])
    if not os.path.isdir(referencePath):
        raise SystemExit('Reference directory does not exist: {}'.format(referencePath))
    Init = os.path.join(referencePath,'.init')
    if not os.path.exists(Init):
        Gtf,Cdna,Genome = pipeClasses.getReferenceVariables(referencePath)
        with open(Init,'w') as f:
            f.write('\n'.join([Gtf,Cdna,Genome]))
    else:
        with open(Init,'r') as f:
            Stuff = f.readlines()
        Gtf = Stuff[0].rstrip('\n')
        Cdna = Stuff[1].rstrip('\n')
        Genome = Stuff[2].rstrip('\n')
    Basename = str(Genome.split(".")[0])
    if arguments['--onlykallisto']:
        createKallistoIndex(referencePath, Cdna, Basename, arguments)
        print('[ {} ] Completed Kallisto index; exiting...'.format(pipeClasses.now()))
        return None
    if arguments['--onlybowtie2']:
        createBowtie2Index(referencePath, Genome, Basename, arguments)
        print('[ {} ] Completed Bowtie2 index; exiting...'.format(pipeClasses.now()))
        return None
    if arguments['--qualitycheck'] and not arguments['--preprocess']: # only q
        if arguments['prepref/main']['qcRef']:
            qcRef(referencePath,Genome)
        else:
            print('qcRef skipped due to manifest\n')
    elif not arguments['--qualitycheck'] and arguments['--preprocess']: # only p
        ppRef(referencePath, Cdna, Basename, Gtf, Genome, cpuLimit, arguments)
    else: #both
        if arguments['prepref/main']['qcRef']:
            qcRef(referencePath,Genome)
        else:
            print('qcRef skipped due to manifest\n')
        ppRef(referencePath, Cdna, Basename, Gtf, Genome, cpuLimit, arguments)
    if arguments['--kallisto']:
        createKallistoIndex(referencePath, Cdna, Basename, arguments)
    if arguments['--bowtie2']:
        createBowtie2Index(referencePath, Genome, Basename, arguments)

def generateDefaultInputFile(arguments):
    '''Usage:
    lahontan gendef [options]

Options:
    -h, --help
        Show this screen and exit
    -f <filename>, --filename <filename>
        Name of input file to create
        [default: default_input.ini]
    -m <mode>, --mode <mode>
        Type of execution mode, can be:
            fcounts
            string
            kall
            bowtie2
            prepref
        [default: fcounts]

Note: Any options given on command-line will override those in
input file'''
    ############################################################
    # If mode is gendef; create different config file
    ############################################################
    if arguments['--mode'] == 'prepref':
        generatePreprefInput(arguments)
        return None
    ############################################################
    # Set-Up Config
    ############################################################
    config = configparser.ConfigParser(
            interpolation=configparser.ExtendedInterpolation(),
            dict_type=OD)
    config.optionxform = str
    config.BOOLEAN_STATES = {'True': True,
            'False': False,
            'true': True,
            'false': False,
            'None': False,
            'none': False}
    # LOCATIONS
    pwd = os.path.abspath(os.curdir)
    config['locations'] = OD((
            ('Project', pwd),
            ('Reference', pwd),
            ('Original', pwd),
            ))
    # MODE
    if arguments['--mode'] not in ['fcounts', 'string', 'kall', 'bowtie2']:
        raise SystemExit('--mode argument is not valid: {}'.format(arguments['--mode']))
    config['mode'] = OD((
            ('fcounts', 'True' if arguments['--mode'] == 'fcounts' else 'False'),
            ('kall', 'True' if arguments['--mode'] == 'kall' else 'False'),
            ('string', 'True' if arguments['--mode'] == 'string' else 'False'),
            ('bowtie2', 'True' if arguments['--mode'] == 'bowtie2' else 'False'),
            ))
    RNASEQDIR = os.path.expandvars('$RNASEQDIR')

    ############################################################
    # CLI-mutable args
    ############################################################
    if arguments['--mode'] == 'fcounts':
        config['fcounts'] = OD((
                ('--execute', 'A'),
                ('--runsample', 'None'),
                ('--jsonfile', 'None'),
                ('--maxcpu', 'None'),
                ('--noconfirm', 'False'),
                ('--makebatch', 'None'),
                ('--batchjson', 'None'),
                ('--edger', 'False'),
                ('--deseq', 'False'),
                ('--use-blacklist', os.path.join(RNASEQDIR,'../src/trimmomatic/adapters/TruSeq3-PE.fa')),
                ('--use-reference', 'False'),
                ))
    elif arguments['--mode'] == 'string':
        config['string'] = OD((
                ('--execute', 'A'),
                ('--runsample', 'None'),
                ('--phase', 'abc'),
                ('--jsonfile', 'None'),
                ('--maxcpu', 'None'),
                ('--noconfirm', 'False'),
                ('--use-blacklist', os.path.join(RNASEQDIR,'../src/trimmomatic/adapters/TruSeq3-PE.fa')),
                ('--use-reference', 'False'),
                ('--makebatch', 'None'),
                ('--batchjson', 'None'),
                ))
    elif arguments['--mode'] == 'kall':
        config['kall'] = OD((
                ('--execute', 'A'),
                ('--runsample', 'None'),
                ('--jsonfile', 'None'),
                ('--maxcpu', 'None'),
                ('--noconfirm', 'False'),
                ('--use-blacklist', os.path.join(RNASEQDIR,'../src/trimmomatic/adapters/TruSeq3-PE.fa')),
                ('--use-reference', 'False'),
                ('--makebatch', 'None'),
                ('--batchjson', 'None'),
                ))
    elif arguments['--mode'] == 'bowtie2':
        config['bowtie2'] = OD((
                ('--execute', 'A'),
                ('--runsample', 'None'),
                ('--jsonfile', 'None'),
                ('--maxcpu', 'None'),
                ('--noconfirm', 'False'),
                ('--makebatch', 'None'),
                ('--batchjson', 'None'),
                ('--use-blacklist', os.path.join(RNASEQDIR,'../src/trimmomatic/adapters/TruSeq3-PE.fa')),
                ('--use-reference', 'False'),
                ))

    ############################################################
    # Executables
    ############################################################
    config['EXECUTABLES'] = OD((
            ('Rscript', '${rnaseqdir}/Rscript'),
            ('java', '/usr/bin/java'),
            ('rnaseqdir', RNASEQDIR),
            ('fastqc', '${rnaseqdir}/fastqc'),
            ('extract_exons.py', '${rnaseqdir}/extract_exons.py'),
            ('extract_splice_sites.py', '${rnaseqdir}/extract_splice_sites.py'),
            ('hisat2', '${rnaseqdir}/hisat2'),
            ('hisat2-build', '${rnaseqdir}/hisat2-build'),
            ('samtools', '${rnaseqdir}/samtools'),
            ('makeblastdb', '${rnaseqdir}/makeblastdb'),
            ('blastn', '${rnaseqdir}/blastn'),
            ('seqtk', '${rnaseqdir}/seqtk'),
            ('gffcompare', '${rnaseqdir}/gffcompare'),
            ('stranded_classifier.py', '${rnaseqdir}/stranded_classifier.py'),
            ('featureCounts', '${rnaseqdir}/featureCounts'),
            ('stringtie', '${rnaseqdir}/stringtie'),
            ('kallisto', '${rnaseqdir}/kallisto'),
            ('bowtie2', '${rnaseqdir}/bowtie2'),
            ('bowtie2-build', '${rnaseqdir}/bowtie2-build'),
            ))

    ############################################################
    # FCOUNTS
    ############################################################
    if arguments['--mode'] == 'fcounts':
        config['fcounts/main'] = OD((
                ('runQCheck', 'True'),
                ('runTrimmomatic', 'True'),
                ('runSeqtk', 'True'),
                ('runBlastn', 'True'),
                ('runHisat', 'True'),
                ('runCompression', 'True'),
                ('runFeatureCounts', 'True'),
                ('getNiceColumns', 'True'),
                ('getAlignedColumn', 'True'),
                ))
        # fcounts/main/runHisat
        # hisat2 -k 5 -p {numProcs}{FRoRF} --dta --phred{phred} {other}\
        #       --known-splicesite-infile {ref}/splice_sites.txt -x {ref}/{basename} \
        #       -1 read1.P.trim.{fastq}.gz -2 read2.P.trim.{fastq}.gz -S aligned.{sample}.sam
        config['fcounts/runHisat'] = OD((
                ('hisat2', '${EXECUTABLES:hisat2}'),
                ('-k', 'None'),
                ('-p', 'None'),
                ('--rna-strandedness', 'None'),
                ('--dta', 'None'),
                ('--phred', 'None'),
                ('--known-splicesite-infile', 'None'),
                ('-x', 'None'),
                ('-1', 'None'),
                ('-2', 'None'),
                ('-S', 'None'),
                ('other', 'None'),
                ))
        # fcounts/main/runCompression
        # samtools view -bT {ref}/{genome} -@{procs} {other} aligned.{sample}.sam -o aligned.{sample}.bam
        config['fcounts/runCompression'] = OD((
                ('samtools', '${EXECUTABLES:samtools}'),
                ('-b', 'None'),
                ('-T', 'None'),
                ('-@', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))
        # fcounts/main/runFeatureCounts
        # featureCounts -T {procs} -s {stranded} -p -C --primary --ignoreDup --largestOverlap -t exon -g gene_id \
        #       -a {ref}/{gtf} -o aligned.{sample}.counts {other} aligned.{sample}.bam
        config['fcounts/runFeatureCounts'] = OD((
                ('featureCounts', '${EXECUTABLES:featureCounts}'),
                ('-T', 'None'),
                ('-s', 'None'),
                ('-p', 'None'),
                ('-C', 'None'),
                ('--primary', 'None'),
                ('--ignoreDup', 'None'),
                ('--largestOverlap', 'None'),
                ('-t', 'None'),
                ('-g', 'None'),
                ('-a', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))

    ############################################################
    # STRING
    ############################################################
    elif arguments['--mode'] == 'string':
        config['string/main'] = OD((
                ('runQCheck', 'True'),
                ('runTrimmomatic', 'True'),
                ('runSeqtk', 'True'),
                ('runBlastn', 'True'),
                ('runHisat', 'True'),
                ('runAltCompression', 'True'),
                ('assembleTranscripts', 'True'),
                ('stringtieMerge', 'True'),
                ('compareTranscripts', 'True'),
                ('estimateTranscriptAbundances', 'True'),
                ))
        # string/main/runHisat
        # hisat2 -k 5 -p {numProcs}{FRoRF} --dta --phred{phred} {other}\
        #       --known-splicesite-infile {ref}/splice_sites.txt -x {ref}/{basename} \
        #       -1 read1.P.trim.{fastq}.gz -2 read2.P.trim.{fastq}.gz -S aligned.{sample}.sam
        config['string/runHisat'] = OD((
                ('hisat2', '${EXECUTABLES:hisat2}'),
                ('-k', 'None'),
                ('-p', 'None'),
                ('--rna-strandedness', 'None'),
                ('--dta', 'None'),
                ('--phred', 'None'),
                ('--known-splicesite-infile', 'None'),
                ('-x', 'None'),
                ('-1', 'None'),
                ('-2', 'None'),
                ('-S', 'None'),
                ('other', 'None'),
                ))
        # string/main/runAltCompression
        # samtools sort -@ {procs} -o aligned.{sample}.bam {other} aligned.{sample}.sam
        config['string/runAltCompression'] = OD((
                ('samtools', '${EXECUTABLES:samtools}'),
                ('-@', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))
        # string/main/assembleTranscripts
        # stringtie -p {procs} -o {sample}.st.gtf -l {sample} {other} aligned.{sample}.bam
        config['string/assembleTranscripts'] = OD((
                ('stringtie', '${EXECUTABLES:stringtie}'),
                ('-p', 'None'),
                ('-o', 'None'),
                ('-l', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))
        # string/main/stringtieMerge
        # stringtie --merge -p {procs} -o {mergedir}/{projectname}.stmerged.gtf {other} {mergelist}
        config['string/stringtieMerge'] = OD((
                ('stringtie', '${EXECUTABLES:stringtie}'),
                ('-p', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))
        # string/main/compareTranscripts
        # gffcompare -r {ref}/{gtf} -G -o {projectname}.merged {other} {stmerged}
        config['string/compareTranscripts'] = OD((
                ('gffcompare', '${EXECUTABLES:gffcompare}'),
                ('-r', 'None'),
                ('-G', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))
        # string/main/estimateTranscriptAbundances
        # stringtie -e -B -p {procs} -G {stmerged} -o {sample}.good.st.gtf {other} aligned.{sample}.bam
        config['string/estimateTranscriptAbundances'] = OD((
                ('stringtie', '${EXECUTABLES:stringtie}'),
                ('-e', 'None'),
                ('-B', 'None'),
                ('-p', 'None'),
                ('-G', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))

    ############################################################
    # KALL
    ############################################################
    elif arguments['--mode'] == 'kall':
        config['kall/main'] = OD((
                ('buildKallistoIndex', 'True'),
                ('runQCheck', 'True'),
                ('runTrimmomatic', 'True'),
                ('runSeqtk', 'True'),
                ('runBlastn', 'True'),
                ('runKallisto', 'True'),
                ))
        # kall/main/buildKallistoIndex
        config['kall/buildKallistoIndex'] = OD((
                ('kallisto', '${EXECUTABLES:kallisto}'),
                ('other', 'None'),
                ('-i', 'None'),
                ('cdna', 'None'),
                ))
        # kall/main/runKallisto
        # kallisto quant -i {transcriptindex} -o {outputdir} --threads {procs}{FRoRF} -b 100 \
        #       <( zcat read1.P.trim.{fastq}.gz ) <( zcat read2.P.trim.{fastq}.gz )
        config['kall/runKallisto'] = OD((
                ('kallisto', '${EXECUTABLES:kallisto}'),
                ('-i', 'None'),
                ('-o', 'None'),
                ('--threads', 'None'),
                ('stranded', 'None'),
                ('-b', 'None'),
                ('read1', 'None'),
                ('read2', 'None'),
                ('other', 'None'),
                ))

    ############################################################
    # Bowtie2
    ############################################################
    elif arguments['--mode'] == 'bowtie2':
        config['bowtie2/main'] = OD((
                ('buildB2Index', 'True'),
                ('runQCheck', 'True'),
                ('runTrimmomatic', 'True'),
                ('runSeqtk', 'True'),
                ('runBlastn', 'True'),
                ('runBowtie2', 'True'),
                ('runCompression', 'True'),
                ))
        # bowtie2/main/buildB2Index
        # bowtie2 [options]
        config['bowtie2/buildB2Index'] = OD((
                ('bowtie2-build', '${EXECUTABLES:bowtie2-build}'),
                ('--threads', 'None'),
                ("other", 'None'),
                ('genome', 'None'),
                ('basename', 'None'),
                ))
        # bowtie2/main/runBowtie2
        # bowtie2 [options]
        config['bowtie2/runBowtie2'] = OD((
                ('bowtie2', '${EXECUTABLES:bowtie2}'),
                ("--very-sensitive-local", 'None'),
                ("-k", '5'),
                ("-p", 'None'),
                ("--rna-strandedness", 'None'),
                ("--phred", 'None'),
                ("other", 'None'),
                ("-x", 'None'),
                ("-1", 'None'),
                ("-2", 'None'), 
                ("-S", 'None'), 
                ))
        # bowtie2/main/runCompression
        # samtools view -bT {ref}/{genome} -@{procs} {other} aligned.{sample}.sam -o aligned.{sample}.bam
        config['bowtie2/runCompression'] = OD((
                ('samtools', '${EXECUTABLES:samtools}'),
                ('-b', 'None'),
                ('-T', 'None'),
                ('-@', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))

    ############################################################
    # General Utilities
    ############################################################
    # runQCheck
    # fastqc -t {procs} -o {fastqfolder} {other} {read1} {read2}
    config['runQCheck'] = OD((
            ('fastqc', '${EXECUTABLES:fastqc}'),
            ('-t', 'None'),
            ('-o', 'None'),
            ('read1', 'None'),
            ('read2', 'None'),
            ('other', 'None'),
            ))
    # runTrimmomatic
    # java -jar $RNASEQDIR/Trimmomatic/trimmomatic-0.36.jar PE -threads {procs} -phred{phred} {other}\
    #       {Read1} {Read2} \
    #       read1.P.trim.{fastq}.gz read1.U.trim.{fastq}.gz \
    #       read2.P.trim.{fastq}.gz read2.U.trim.{fastq}.gz \
    #       ILLUMINACLIP:{blacklist}:2:30:10 LEADING:5 TRAILING:5 SLIDINGWINDOW:4:5 MINLEN:35
    config['runTrimmomatic'] = OD((
            ('java', '${EXECUTABLES:java}'),
            ('-jar', 'None'),
            ('-threads', 'None'),
            ('-phred', 'None'),
            ('read1', 'None'),
            ('read2', 'None'),
            ('read1pout', 'None'),
            ('read2pout', 'None'),
            ('read1uout', 'None'),
            ('read2uout', 'None'),
            ('blacklist', 'None'),
            ('ILLUMINACLIP', 'None'),
            ('LEADING', 'None'),
            ('TRAILING', 'None'),
            ('SLIDINGWINDOW', 'None'),
            ('MINLEN', 'None'),
            ('other', 'None'),
            ))
    # runSeqtk
    # seqtk sample -s100 read1.P.trim.{0}.gz 10000 | seqtk seq -A {other} - > sampled.read1.fa
    # seqtk sample -s100 read2.P.trim.{0}.gz 10000 | seqtk seq -A {other} - > sampled.read2.fa
    config['runSeqtk'] = OD((
            ('seqtk', '${EXECUTABLES:seqtk}'),
            ('-s', 'None'),
            ('read1', 'None'),
            ('read2', 'None'),
            ('read1out', 'None'),
            ('read2out', 'None'),
            ('samples', 'None'),
            ('-A', 'None'),
            ('other', 'None'),
            ))
    # runBlastn
    # blastn -query sampled.read1.fa -db {0} -out sampled.read1_vscdna.out -task blastn-short \
    #       -outfmt "6 std sstrand" -max_target_seqs 1 -num_threads {1} {other}
    # blastn -query sampled.read2.fa -db {0} -out sampled.read2_vscdna.out -task blastn-short \
    #       -outfmt "6 std sstrand" -max_target_seqs 1 -num_threads {1} {other}
    config['runBlastn'] = OD((
            ('blastn', '${EXECUTABLES:blastn}'),
            ('read1', 'None'),
            ('read2', 'None'),
            ('out1', 'None'),
            ('out2', 'None'),
            ('-db', 'None'),
            ('-task', 'None'),
            ('-outfmt', 'None'),
            ('-max_target_seqs', 'None'),
            ('-num_threads', 'None'),
            ('other', 'None'),
            ))

    ############################################################
    with open(arguments['--filename'], 'w') as configfile:
        config.write(configfile)
    ############################################################

def otherStuff(arguments):
    ''' Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        Handles what happens when a sub-command is given that
        isn't real
    '''
    if any(arguments.values()):
        raise SystemExit(__doc__)
    else:
        raise SystemExit(__doc__)

def moreHelp(arguments):
    ''' Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        Handles the help subcommand
    '''
    try:
        helpCommand = arguments['<args>'][0]
    except IndexError:
        raise SystemExit(__doc__)
    if helpCommand == 'fcounts':
        print(featureCounts.__doc__)
        print(
"""\n################################################################
                    fcounts Information
################################################################

The fcounts API consists of the FCountsExperiment and
FCountsSample classes located in pipeClasses.py. There are also
methods and attributes that are inherited from the Experiment
and Sample Class. Execution of an experiment consists of
executing the 5 runStage methods of an FCountsExperiment. These
stages are:
            1: Creating Project Structure
            2: Preparing Reference Data
            3: Running actual Pipeline
            4: Preparing for R analysis
            5: Running R analysis

Within the runStage1() method, there are two functions:
            1: makeStructure()
            2: makeSyms()

Function 1: Experiment.makeStructure():
    Action: Calls the makeStructure.sh shell script which takes
    as its arguments the path to the project and the number of
    samples
    Result: After execution, all the main directories of the
    project should be included -> Project, Data, Original,
    Postprocessing, Reference, and each of the sample
    directories

Function 2: Experiment.makeSyms():
    Action: Calls the makeSyms.sh shell script which takes as
    its arguments the path to the project, the path to the
    original data, and the path to the reference data
    Result: The original data files will have symbolic links in
    their respective sample directories; if there is a metadata
    file specified by the '--jsonfile' option, it will be linked
    in the Postprocessing directory; if the reference data has
    been prepared and specified by the '--use-reference' option,
    the entire reference directory will be linked in the
    Reference directoy, otherwise, just the 3 necessary
    reference files will be linked -> Gtf, Cdna, and Genome

Within the runStage2() method, there are two functions:
            1: qcRef()
            2: ppRef()

Function 1: Experiment.qcRef()
    Action: Calls the QCofRef.sh shell script which takes as its
    arguments the path to the reference data and the name of the
    genome.
    Result: Certain characteristics of the reference data will
    be checked such as: the names of the chromosomes in the gtf
    and genome file, the number of chromosomes in the gtf and
    genome file, the names of the genes in the cdna and gtf
    file, the total number of unique genes in the cdna and gtf,
    and the number of unique gene names in the cdna AND not in
    the gtf

Function 2: Experiment.ppRef()
    Action: Prepares the reference data by using various tools
    such as blast, extract_spice_sites.py, extract_exons.py,
    hisat2, and samtools
    Result: A blast database, a file with exon and splice site
    locations, a hisat2 database, and a genome index will be
    created in reference directory

Within the runStage3() method, there is one function:
            1: GO()

Function 1: FCountsExperiment.GO()
    Action: Creates sample classes and executes their runParts
    method
    Result: Experiment infrastructures acts as a wrapper around
    the samples, and executes them individually such that they
    are independent

Further Stage 3 information:

In Stage 3, the GO() method will create execution spaces for
each sample specified on the command line, or all possible by
default. After creating each sample, each sample's runSample()
method will be executed.

For the FCountsSample types, the runSample() method executes the
following commands:
        Part 1:
            1: runQCheck()
            2: runTrimmomatic()
            3: runQCheck()
        Part 2:
            1: runSeqtk()
            2: runBlastn()
            3: runHisat()
            4: runCompression()
            5: runFeatureCounts()
            6: getNiceColumns()
            7: getAlignedColumn()

Part 1: Consists of quality control with fastQC and trimmomatic

Function 1: Sample.runQCheck()
    Action: Runs fastQC on reads and then scrapes the
    overrepresented sequences from fastQC logs
    Result: There will be a fastQC folder in each sample
    directory that contains quality control information
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting runQCheck to
    False. Can also control the execution options under the
    [runQCheck] header:
        {fastqc} -t {-t} -o {-o} {other} {read1} {read2}
        fastqc: fastQC executable (by default will use
        executable defined under [EXECUTABLES] header)
        -t: processors to use (by default will use allocated
        sample space)
        -o: output directory (by default will use folder named
        fastqc{run-number}.{sample-name}) (CAUTION: highly
        discouraged from changing)
        other: used to specify any other options not already
        defined
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)

Function 2: Sample.runTrimmomatic()
    Action: Executes trimmomatic on reads
    Result: Reads will be trimmed
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting runTrimmomatic to
    False. Can also control the execution options under the
    [runTrimmomatic] header:
        {java} -jar {-jar} PE -threads {-threads} -phred{-phred}
        {other} {read1} {read2} {read1pout} {read1uout}
        {read2pout} {read2uout}
        ILLUMINACLIP:{blacklist}:{ILLUMINACLIP}
        LEADING:{LEADING} TRAILING:{TRAILING}
        SLIDINGWINDOW:{SLIDINGWINDOW} MINLEN:{MINLEN}
        java: java executable (by default will use executable
        defined under [EXECUTABLES] header)
        -jar: trimmomatic jar file (by default will use
        $RNASEQDIR/trimmomatic-0.36.jar)
        -threads: processors to use (by default will use
        allocated sample space)
        -phred: phred version (by default will scrape version
        from fastQC logs). Can set to 33, 64, or None (for
        default)
        other: used to specify any other options not already
        defined
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        read1pout: output read 1 (CAUTION: highly discouraged
        from changing)
        read2pout: output read 2 (CAUTION: highly discouraged
        from changing)
        read1uout: output read 1 (CAUTION: highly discouraged
        from changing)
        read2uout: output read 2 (CAUTION: highly discouraged
        from changing)
        blacklist: blacklist file (Can also specify on
        command-line with --use-blacklist)
        ILLUMINACLIP: trim options (by default: "2:30:10")
        LEADING: trim options (by default: "5")
        TRAILING: trim options (by default: "5")
        SLIDINGWINDOW: trim options (by default: "4:5")
        MINLEN: trim options (by default: "35")

Function 3: Sample.runQCheck()
    Action: Runs fastQC on reads and then scrapes the
    overrepresented sequences from fastQC logs
    Result: Does the same thing as the previous runQCheck except
    this run is post-trimmomatic to get a perspective on the
    changes that trimmomatic made
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting runQCheck to
    False or runTrimmomatic to False. Control execution options
    exactly the same as in Function 1.

Part 2: Consists of execution of feature counts method

Function 1: Sample.runSeqtk()
    Action: Execute seqtk on reads to get a representative
    sample of reads
    Result: Obtains a representative sample of reads in order to
    more quickly check strandedness of reads
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting runSeqtk to
    False. Can also control the execution options under the
    [runSeqtk] header:
        {seqtk} sample -s{-s} {read1} {samples} | seqtk seq {-A}
            {other} - > {read1out}
        {seqtk} sample -s{-s} {read2} {samples} | seqtk seq {-A}
            {other} - > {read2out}
        seqtk: seqtk executable (by default will use executable
        defined under [EXECUTABLES] header)
        -s: random seed (by default: "100")
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        read1out: output read 1 (CAUTION: highly discouraged from
        changing)
        read2out: output read 2 (CAUTION: highly discouraged from
        changing)
        samples: number of samples to take (by default: "10000")
        -A: boolean option to force FASTA output (by default is
        on). Can turn off by setting to False
        other: used to specify any other options not already
        defined

Function 2: Sample.runBlastn()
    Action: Execute blastn on seqtk output
    Result: Used to gather strandedness information of reads
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting runBlastn to
    False. Can also control the execution options under the
    [runBlastn] header:
        {blastn} -query {read1} -db {-db} -out {out1} -task
            {-task} -outfmt {-outfmt} -max_target_seqs
            {-max_target_seqs} -num_threads {-num_threads}
            {other}
        {blastn} -query {read2} -db {-db} -out {out2} -task
            {-task} -outfmt {-outfmt} -max_target_seqs
            {-max_target_seqs} -num_threads {-num_threads}
            {other}
        blastn: blastn executable (by default will use
        executable defined under [EXECUTABLES] header)
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        out1: output read 1 (CAUTION: highly discouraged from
        changing)
        out2: output read 2 (CAUTION: highly discouraged from
        changing)
        -db: path to blast database (by default:
        Reference/{basename}.cdna.all)
        -task: task to executed (by default "blastn-short")
        -outfmt: output format (by default '"6 std sstrand"';
        notice the double quotes necessary to contain the
        spaces)
        -max_target_seqs: max target sequences (by default "1")
        -num_threads: processors to use (by default will use
        allocated sample space)
        other: used to specify any other options not already
        defined

Function 3: FCountsSample.runHisat()
    Action: Executes hisat2 for alignment of reads to reference
    genome
    Result: A SAM file with identified reads
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting runHisat to
    False. Can also control the execution options under the
    [fcounts/runHisat] header:
        {hisat2} -k {-k} -p {-p} {--rna-strandedness} {--dta}
        --phred{phred} {other} --known-slicesite-infile
        {--known-splicesite-infile} -x {-x} -1 {-1} -2 {-2}
        -S {-S}
        hisat2: hisat2 executable (by default will use
        executable defined under [EXECUTABLES] header)
        -k: alternates per read (by default "5")
        -p: processors to use (by default will use allocated
        sample space)
        --rna-strandedness: strandedness of reads (by default
        will determine from blastn and seqtk) Can set to FR, RF,
        False, or None. False specifies unstrandedness while
        None defaults to pipeline findStranded()
        --dta: boolean option to report alignments tailored for
        transcript assemblers (by default on). Can turn off by
        setting to False
        --phred: phred version (by default will determine from
        fastQC logs). Can set to 33 or 64
        --known-splicesite-infile: path to splice sites (by
        default will use Reference/splice_sites.txt)
        -x: path to hisat2 index (by default will use
        Reference/{basename})
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        -S: outpus SAM file (CAUTION: highly discouraged from
        changing)
        other: used to specify any other options not already
        defined

Function 4: FCountsSample.runCompression()
    Action: Use samtools to compress hisat2 output
    Result: A compressed BAM files with aligned read information
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting runCompression to
    False. Can also control the execution options under the
    [fcounts/runCompression] header:
        {samtools} view {-b} -T {-T} -@{-@} {other} {in} -o {-o}
        samtools: samtools executable (by default will use
        executable defined under [EXECUTABLES] header)
        -b: boolean option to output BAM file (by default on).
        Can turn off by setting to False
        -T: path to reference sequence FASTA file (by default
        will use Reference/{genome_file})
        -@: processors to use (by default will use allocated
        sample space)
        -o: output file name (CAUTION: highly discouraged from
        changing)
        in: input SAM file (CAUTION: highly discouraged from
        changing)
        other: used to specify any other options not already
        defined

Function 5: FCountsSample.runFeatureCounts()
    Action: Use featureCounts to count aligned reads
    Result: A file with count data
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting runFeatureCounts
    to False. Can also control the execution options under the
    [fcounts/runFeatureCounts] header:
        {featureCounts} -T {-T} -s
        {-s}{-p}{-C}{--primary}{--ignoreDup}{--largestOverlap}
        -t {-t} -g {-g} -a {-a} {other} -o {-o} {in}
        featureCounts: featureCounts executable (by default will
        use executable defined under [EXECUTABLES] header)
        -T: processors to use (by default will use allocated
        sample space)
        -s:  strandedness of reads (by default will determine
        from blastn and seqtk). Can set to 0 (unstranded), 1
        (stranded), 2 (reversely stranded), or None (default)
        -p: boolean option that allows for fragments to be
        counted instead of reads, normally for paired-end reads
        (by default on). Can turn off by setting to False.
        -C: boolean option that sets: "Do not count read pairs
        that have their two ends mapping to different
        chromosomes or mapping to same chromosome but on
        different strands." (By default on). Can turn off by
        setting to False.
        --primary: boolean option to count primary alignments
        only (by default on). Can turn off by setting to False.
        --ignoreDup: boolean option to ignore duplicate reads
        when read counting. (By default on). Can turn off by
        setting to False.
        --largestOverlap: boolean option to count gene with
        largest overlap on read (By default on). Can turn off
        by setting to False.
        -t: feature type in GTF annotation (by default "exon")
        -g: attribute type in GTF annotation (by default
        "gene_id")
        -a: path to annotation file (gtf) (by default
        Reference/{Gtf})
        -o: ouput counts file (CAUTION: highly discouraged from
        changing)
        in: input BAM file (CAUTION: highly discouraged from
        changing)
        other: used to specify any other options not already
        defined

Function 6: FCountsSample.getNiceColumns()
    Action: Scrapes featureCounts output for gene id, length of
    gene, and counts
    Result: A table with only gene name, length, and count
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting getNiceColumns
    to False.

Function 7: FCountsSample.getAlignedColumn()
    Action: Scrapes featureCounts to get only count column
    Result: A file with one column that contains count
    information
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting getAlignedColumn
    to False.
""")
    elif helpCommand == 'string':
        print(stringtie.__doc__)
        print(
"""\n################################################################
                    Stringtie information
################################################################

The string API consists of the StringtieExperiment and
StringtieSample classes located in pipeClasses.py. There are
also methods and attributes that are inherited from the
Experiment and Sample class. Execution of an experiment consists
of executing the 5 runStage methods of a StringtieExperiment.
in general, the StringtieExperiment is very similar to the
FcountsExperiment experiment except for Stage 3. the
StringtieExperiment stages are:

    1: Creating project structure
    2: Preparing reference data 
    3: Running actual pipeline 
    4: Preparing for R analysis
    5: Running R analysis

Within the runStage1() method, there are two functions:
            1: makeStructure()
            2: makeSyms()

Function 1: Experiment.makeStructure():
    Action: Calls the makeStructure.sh shell script which takes
    as its arguments the path to the project and the number of
    samples
    Result: After execution, all the main directories of the
    project should be included -> Project, Data, Original,
    Postprocessing, Reference, and each of the Sample
    directories

Function 2: Experiment.makeSyms():
    Action: Calls the makeSyms.sh shell script which takes as
    its arguments the path to the project, the path to the
    original data, and the path to the reference data
    Result: The original data files will have symbolic links in
    their respective sample directories; if there is a metadata
    file specified by the '--jsonfile' option, it will be linked
    in the Postprocessing directory; if the reference data has
    been prepared and specified by the '--use-reference' option,
    the entire Reference directory will be linked in the
    Reference directoy, otherwise, just the 3 necessary
    reference files will be linked -> GTF, cdna, and genome

within the runstage2() method, there are two functions:
            1: qcRef()
            2: ppRef()

Function 1: Experiment.qcRef()
    Action: Calls the QCofRef.sh shell script which takes as its
    arguments the path to the reference data and the name of the
    genome.
    Result: Certain characteristics of the reference data will
    be checked such as: the names of the chromosomes in the gtf
    and genome file, the number of chromosomes in the gtf and
    genome file, the names of the genes in the cdna and gtf
    file, the total number of unique genes in the cdna and gtf,
    and the number of unique gene names in the cdna and not in
    the gtf

Function 2: experiment.ppRef()
    Action: Prepares the reference data by using various tools
    such as BLAST, extract_spice_sites.py, extract_exons.py,
    hisat2, and SAMtools
    Result: A BLAST database, a file with exon and splice site
    locations, a hisat2 database, and a genome index will be
    created in reference directory

within the runStage3() method, there is one function:
            1: GO()

Function 1: StringtieExperiment.GO()
    Action: Creates sample classes and executes their runParts
    method
    Result: Experiment infrastructures acts as a wrapper around
    the samples, and executes them individually such that they
    are independent

Further Stage 3 information:

In Stage 3, the GO() method will create execution spaces for
each sample specified on the command line, or all possible by
default. After creating each sample, each sample's runSample()
method will be executed.

For the StringtieSample types, the runSample() method executes
the following commands:
        Part 1:
            1: runQCheck()
            2: runTrimmomatic()
            3: runQCheck()
        Part 2:
            Sub-Part A:
                1: runSeqtk()
                2: runBlastn()
                3: runHisat()
                4: runAltCompression()
                5: assembleTranscripts()
            Sub-Part C:
                8: estimateTranscriptAbundances()

The reason for Sub-Part A and Sub-Part C is that in order to
better estimate the transcript abundances for each sample, a
uniform set of reference transcripts is used to process the read
alignments. The uniform set of transcripts is assembled from
each sample's aligned and quantified transcripts, using a set of
reference transcripts. The merging of each sample's initial
transcripts occurs in Sub-Part B. Sub-Part B is executed by the
StringtieExperiment.stringtiePart2b() function which further
executes the following commands:
        Part 2:
            Sub-Part B:
                6: stringtieMerge()
                7: compareTranscripts()

Each function is further documented below.

Part 1: Consists of quality control with fastQC and trimmomatic

Function 1: Sample.runQCheck()
    Action: Runs fastQC on reads and then scrapes the
    overrepresented sequences from fastQC logs
    Result: There will be a fastQC folder in each sample
    directory that contains quality control information
    Manifest Information: Able to be controlled from manifest
    under the [string/main] header by setting runQCheck to
    False. Can also control the execution options under the
    [runQCheck] header:
        {fastqc} -t {-t} -o {-o} {other} {read1} {read2}
        fastqc: fastQC executable (by default will use
        executable defined under [EXECUTABLES] header)
        -t: processors to use (by default will use allocated
        sample space)
        -o: output directory (by default will use folder named
        fastqc{run-number}.{sample-name}) (CAUTION: highly
        discouraged from changing)
        other: used to specify any other options not already
        defined
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)

Function 2: Sample.runTrimmomatic()
    Action: Executes trimmomatic on reads
    Result: Reads will be trimmed
    Manifest Information: Able to be controlled from manifest
    under the [string/main] header by setting runTrimmomatic to
    False. Can also control the execution options under the
    [runTrimmomatic] header:
        {java} -jar {-jar} PE -threads {-threads} -phred{-phred}
        {other} {read1} {read2} {read1pout} {read1uout}
        {read2pout} {read2uout}
        ILLUMINACLIP:{blacklist}:{ILLUMINACLIP}
        LEADING:{LEADING} TRAILING:{TRAILING}
        SLIDINGWINDOW:{SLIDINGWINDOW} MINLEN:{MINLEN}
        java: java executable (by default will use executable
        defined under [EXECUTABLES] header)
        -jar: trimmomatic jar file (by default will use
        $RNASEQDIR/trimmomatic-0.36.jar)
        -threads: processors to use (by default will use
        allocated sample space)
        -phred: phred version (by default will scrape version
        from fastQC logs). Can set to 33, 64, or None (for
        default)
        other: used to specify any other options not already
        defined
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        read1pout: output read 1 (CAUTION: highly discouraged
        from changing)
        read2pout: output read 2 (CAUTION: highly discouraged
        from changing)
        read1uout: output read 1 (CAUTION: highly discouraged 
        from changing)
        read2uout: output read 2 (CAUTION: highly discouraged
        from changing)
        blacklist: blacklist file (Can also specify on
        command-line with --use-blacklist)
        ILLUMINACLIP: trim options (by default: "2:30:10")
        LEADING: trim options (by default: "5")
        TRAILING: trim options (by default: "5")
        SLIDINGWINDOW: trim options (by default: "4:5")
        MINLEN: trim options (by default: "35")

Function 3: Sample.runQCheck()
    Action: Runs fastQC on reads and then scrapes the
    overrepresented sequences from fastQC logs
    Result: Does the same thing as the previous runQCheck except
    this run is post-trimmomatic to get a perspective on the
    changes that trimmomatic made
    Manifest Information: Able to be controlled from manifest
    under the [string/main] header by setting runQCheck to
    False or runTrimmomatic to False. Control execution options
    exactly the same as in Function 1.

Part 2: 

Sub-Part A: Consists of assembly of each transcript's
transcripts

Function 1: Sample.runSeqtk()
    Action: Execute seqtk on reads to get a representative
    sample of reads
    Result: Obtains a representative sample of reads in order to
    more quickly check strandedness of reads
    Manifest Information: Able to be controlled from manifest
    under the [string/main] header by setting runSeqtk to
    False. Can also control the execution options under the
    [runSeqtk] header:
        {seqtk} sample -s{-s} {read1} {samples} | seqtk seq {-A}
            {other} - > {read1out}
        {seqtk} sample -s{-s} {read2} {samples} | seqtk seq {-A}
            {other} - > {read2out}
        seqtk: seqtk executable (by default will use executable
        defined under [EXECUTABLES] header)
        -s: random seed (by default: "100")
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        read1out: output read 1 (CAUTION: highly discouraged
        from changing)
        read2out: output read 2 (CAUTION: highly discouraged
        from changing)
        samples: number of samples to take (by default: "10000")
        -A: boolean option to force FASTA output (by default is
        on). Can turn off by setting to False
        other: used to specify any other options not already
        defined

Function 2: Sample.runBlastn()
    Action: Execute blastn on seqtk output
    Result: Used to gather strandedness information of reads
    Manifest Information: Able to be controlled from manifest
    under the [string/main] header by setting runBlastn to
    False. Can also control the execution options under the
    [runBlastn] header:
        {blastn} -query {read1} -db {-db} -out {out1} -task
            {-task} -outfmt {-outfmt} -max_target_seqs
            {-max_target_seqs} -num_threads {-num_threads}
            {other}
        {blastn} -query {read2} -db {-db} -out {out2} -task
            {-task} -outfmt {-outfmt} -max_target_seqs
            {-max_target_seqs} -num_threads {-num_threads}
            {other}
        blastn: blastn executable (by default will use
        executable defined under [EXECUTABLES] header)
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        out1: output read 1 (CAUTION: highly discouraged from
        changing)
        out2: output read 2 (CAUTION: highly discouraged from
        changing)
        -db: path to blast database (by default:
        Reference/{basename}.cdna.all)
        -task: task to executed (by default "blastn-short")
        -outfmt: output format (by default '"6 std sstrand"';
        notice the double quotes necessary to contain the
        spaces)
        -max_target_seqs: max target sequences (by default "1")
        -num_threads: processors to use (by default will use
        allocated sample space)
        other: used to specify any other options not already
        defined

Function 3: StringtieSample.runHisat()
    Action: Executes hisat2 for alignment of reads to reference
    genome
    Result: A SAM file with identified reads
    Manifest Information: Able to be controlled from manifest
    under the [string/main] header by setting runHisat to
    False. Can also control the execution options under the
    [string/runHisat] header:
        {hisat2} -k {-k} -p {-p} {--rna-strandedness} {--dta}
        --phred{phred} {other} --known-slicesite-infile
        {--known-splicesite-infile} -x {-x} -1 {-1} -2 {-2}
        -S {-S}
        hisat2: hisat2 executable (by default will use
        executable defined under [EXECUTABLES] header)
        -k: alternates per read (by default "5")
        -p: processors to use (by default will use allocated
        sample space)
        --rna-strandedness: strandedness of reads (by default
        will determine from blastn and seqtk) Can set to FR, RF,
        False, or None. False specifies unstrandedness while
        None defaults to pipeline findStranded()
        --dta: boolean option to report alignments tailored for
        transcript assemblers (by default on). Can turn off by
        setting to False
        --phred: phred version (by default will determine from
        fastQC logs). Can set to 33 or 64
        --known-splicesite-infile: path to splice sites (by
        default will use Reference/splice_sites.txt)
        -x: path to hisat2 index (by default will use
        Reference/{basename})
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        -S: outpus SAM file (CAUTION: highly discouraged from
        changing)
        other: used to specify any other options not already
        defined

Function 4: StringtieSample.runAltCompression()
    Action: Use samtools to compress hisat2 output
    Result: A compressed BAM files with aligned read information
    Manifest Information: Able to be controlled from manifest
    under the [string/main] header by setting runAltCompression
    to False. Can also control the execution options under the
    [string/runAltCompression] header:
        {samtools} sort -@ {-@} -o {-o} {other} {in}
        samtools: samtools executable (by default will use
        executable defined under [EXECUTABLES] header)
        -@: processors to use (by default will use allocated
        sample space)
        -o: output file name (CAUTION: highly discouraged from
        changing)
        in: input SAM file (CAUTION: highly discouraged from
        changing)
        other: used to specify any other options not already
        defined

Function 5: StringtieSample.assembleTranscripts()
    Action: Use stringtie to assemble initial transcripts using
    a reference GTF. 
    Result: A file with an updated gtf based on aligned hisat2
    reads
    Manifest Information: Able to be controlled from manifest
    under the [string/main] header by setting
    assembleTranscripts to False. Can also control the execution
    options under the [string/assembleTranscripts] header:
        {stringtie} -p {-p} -o {-o} -l {-l} {other} {in}
        stringtie: stringtie executable (by default will
        use executable defined under [EXECUTABLES] header)
        -p: processors to use (by default will use allocated
        sample space)
        -o: output gtf file (CAUTION: highly discouraged from
        changing)
        -l: label for output files (CAUTION: highly discouraged
        from changing)
        in: input BAM file (CAUTION: highly discouraged from
        changing)
        other: used to specify any other options not already
        defined

Sub-Part B: Merging sample GTFs

Function 6: StringtieExperiment.stringtieMerge()
    Action: Use Stringtie to merge each sample's initial
    transcripts
    Result: A single GTF that will be used in subsequent
    quantification steps
    Manifest Information: Able to be controlled from manifest
    under the [string/main] header by setting
    stringtieMerge to False. Can also control the execution
    options under the [string/stringtieMerge] header:
        {stringtie} --merge -p {-p} -o {-o} {other} {in}
        stringtie: stringtie executable (by default will
        use executable defined under [EXECUTABLES] header)
        -p: processors to use (by default will use allocated
        sample space)
        -o: output gtf file (CAUTION: highly discouraged from
        changing)
        in: input mergelist file that contains paths to each
        sample's initial gtf (CAUTION: highly discouraged from
        changing)
        other: used to specify any other options not already
        defined

Function 7: StringtieExperiment.compareTranscipts()
    Action: Compares old GTF to new GTF
    Result: A file with comparison statistics
    Manifest Information: Able to be controlled from manifest
    under the [string/main] header by setting
    compareTranscripts to False. Can also control the execution
    options under the [string/compareTranscripts] header:
        {gffcompare} -r {-r} {-G} -o {-o} {other} {in}
        gffcompare: gffcompare executable (by default will
        use executable defined under [EXECUTABLES] header)
        -r: Old GTF file (CAUTION: highly discouraged from
        changing)
        -G: True/False setting
        -o: output prefix
        in: New GTF file (CAUTION: highly discouraged from
        changing)
        other: used to specify any other options not already
        defined

Sub-Part C: Re-estimating abundances

Function 7: StringtieSample.estimateTranscriptAbundances()
    Action: Use Stringtie with the new GTF to quantify the gene
    expression
    Result: Tables of quantified genes for each sample
    Manifest Information: Able to be controlled from manifest
    under the [string/main] header by setting
    estimateTranscriptAbundances to False. Can also control the
    execution options under the
    [string/estimateTranscriptAbundances] header:
        {stringtie} {-e} {-B} -p {-p} -G {-G} -o {-o} {other} {in}
        stringtie: stringtie executable (by default will
        use executable defined under [EXECUTABLES] header)
        -e: only estimate the abundance with given reference
        transcripts
        -B: create ballgown tables
        -p: processors to use (by default will use allocated
        sample space)
        -G: reference annotation file (CAUTION: highly
        discouraged from changing)
        -o: output file name for assembled transcripts (CAUTION:
        highly discouraged from changing)
        in: input BAM file (CAUTION: highly discouraged from
        changing)
        other: used to specify any other options not already
        defined
""")
    elif helpCommand == 'kall':
        print(kallisto.__doc__)
        print(
"""\n################################################################
                    kallisto Information
################################################################

The kall API consists of the KallistoExperiment and
KallistoSample classes located in pipeClasses.py. There are also
methods and attributes that are inherited from the Experiment
and Sample Class. Execution of an experiment consists of
executing the 5 runStage methods of a KallistoExperiment. These
stages are:
            1: Creating Project Structure
            2: Preparing Reference Data
            3: Running actual Pipeline
            4: Preparing for R analysis
            5: Running R analysis

Within the runStage1() method, there are two functions:
            1: makeStructure()
            2: makeSyms()

Function 1: Experiment.makeStructure():
    Action: Calls the makeStructure.sh shell script which takes
    as its arguments the path to the project and the number of
    samples
    Result: After execution, all the main directories of the
    project should be included -> Project, Data, Original,
    Postprocessing, Reference, and each of the sample
    directories

Function 2: Experiment.makeSyms():
    Action: Calls the makeSyms.sh shell script which takes as
    its arguments the path to the project, the path to the
    original data, and the path to the reference data
    Result: The original data files will have symbolic links in
    their respective sample directories; if there is a metadata
    file specified by the '--jsonfile' option, it will be linked
    in the Postprocessing directory; if the reference data has
    been prepared and specified by the '--use-reference' option,
    the entire reference directory will be linked in the
    Reference directoy, otherwise, just the 3 necessary
    reference files will be linked -> Gtf, Cdna, and Genome

Within the runStage2() method, there are two functions:
            1: qcRef()
            2: ppRef()
            3: buildKallistoIndex()

Function 1: Experiment.qcRef()
    Action: Calls the QCofRef.sh shell script which takes as its
    arguments the path to the reference data and the name of the
    genome.
    Result: Certain characteristics of the reference data will
    be checked such as: the names of the chromosomes in the gtf
    and genome file, the number of chromosomes in the gtf and
    genome file, the names of the genes in the cdna and gtf
    file, the total number of unique genes in the cdna and gtf,
    and the number of unique gene names in the cdna AND not in
    the gtf

Function 2: Experiment.ppRef()
    Action: Prepares the reference data by using various tools
    such as blast, extract_spice_sites.py, extract_exons.py,
    hisat2, and samtools
    Result: A blast database, a file with exon and splice site
    locations, a hisat2 database, and a genome index will be
    created in reference directory

Function 3: KallistoExperiment.buildKallistoIndex()
    Action: If needed, kallisto will build the indexes needed
    for its analysis in Stage 3
    Results: A kallisto index

Within the runStage3() method, there is one function:
            1: GO()

Function 1: KallistoExperiment.GO()
    Action: Creates sample classes and executes their runParts
    method
    Result: Experiment infrastructure acts as a wrapper around
    the samples, and executes them individually such that they
    are independent

Further Stage 3 information:

In Stage 3, the GO() method will create execution spaces for
each sample specified on the command line, or all possible by
default. After creating each sample, each sample's runSample()
method will be executed.

For the KallistoSample types, the runSample() method executes
the following commands:
        Part 1:
            1: runQCheck()
            2: runTrimmomatic()
            3: runQCheck()
        Part 2:
            1: runSeqtk()
            2: runBlastn()
            3: runKallisto()

Part 1: Consists of quality control with fastQC and trimmomatic

Function 1: Sample.runQCheck()
    Action: Runs fastQC on reads and then scrapes the
    overrepresented sequences from fastQC logs
    Result: There will be a fastQC folder in each sample
    directory that contains quality control information
    Manifest Information: Able to be controlled from manifest
    under the [kall/main] header by setting runQCheck to
    False. Can also control the execution options under the
    [runQCheck] header:
        {fastqc} -t {-t} -o {-o} {other} {read1} {read2}
        fastqc: fastQC executable (by default will use
        executable defined under [EXECUTABLES] header)
        -t: processors to use (by default will use allocated
        sample space)
        -o: output directory (by default will use folder named
        fastqc{run-number}.{sample-name}) (CAUTION: highly
        discouraged from changing)
        other: used to specify any other options not already
        defined
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)

Function 2: Sample.runTrimmomatic()
    Action: Executes trimmomatic on reads
    Result: Reads will be trimmed
    Manifest Information: Able to be controlled from manifest
    under the [kall/main] header by setting runTrimmomatic to
    False. Can also control the execution options under the
    [runTrimmomatic] header:
        {java} -jar {-jar} PE -threads {-threads} -phred{-phred}
        {other} {read1} {read2} {read1pout} {read1uout}
        {read2pout} {read2uout}
        ILLUMINACLIP:{blacklist}:{ILLUMINACLIP}
        LEADING:{LEADING} TRAILING:{TRAILING}
        SLIDINGWINDOW:{SLIDINGWINDOW} MINLEN:{MINLEN}
        java: java executable (by default will use executable
        defined under [EXECUTABLES] header)
        -jar: trimmomatic jar file (by default will use
        $RNASEQDIR/trimmomatic-0.36.jar)
        -threads: processors to use (by default will use
        allocated sample space)
        -phred: phred version (by default will scrape version
        from fastQC logs). Can set to 33, 64, or None (for
        default)
        other: used to specify any other options not already
        defined
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        read1pout: output read 1 (CAUTION: highly discouraged
        from changing)
        read2pout: output read 2 (CAUTION: highly discouraged
        from changing)
        read1uout: output read 1 (CAUTION: highly discouraged
        from changing)
        read2uout: output read 2 (CAUTION: highly discouraged
        from changing)
        blacklist: blacklist file (Can also specify on
        command-line with --use-blacklist)
        ILLUMINACLIP: trim options (by default: "2:30:10")
        LEADING: trim options (by default: "5")
        TRAILING: trim options (by default: "5")
        SLIDINGWINDOW: trim options (by default: "4:5")
        MINLEN: trim options (by default: "35")

Function 3: Sample.runQCheck()
    Action: Runs fastQC on reads and then scrapes the
    overrepresented sequences from fastQC logs
    Result: Does the same thing as the previous runQCheck except
    this run is post-trimmomatic to get a perspective on the
    changes that trimmomatic made
    Manifest Information: Able to be controlled from manifest
    under the [kall/main] header by setting runQCheck to
    False or runTrimmomatic to False. Control execution options
    exactly the same as in Function 1.

Part 2: Consists of execution of strandedness check and kallisto

Function 1: Sample.runSeqtk()
    Action: Execute seqtk on reads to get a representative
    sample of reads
    Result: Obtains a representative sample of reads in order to
    more quickly check strandedness of reads
    Manifest Information: Able to be controlled from manifest
    under the [kall/main] header by setting runSeqtk to
    False. Can also control the execution options under the
    [runSeqtk] header:
        {seqtk} sample -s{-s} {read1} {samples} | seqtk seq {-A}
            {other} - > {read1out}
        {seqtk} sample -s{-s} {read2} {samples} | seqtk seq {-A}
            {other} - > {read2out}
        seqtk: seqtk executable (by default will use executable
        defined under [EXECUTABLES] header)
        -s: random seed (by default: "100")
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        read1out: output read 1 (CAUTION: highly discouraged from
        changing)
        read2out: output read 2 (CAUTION: highly discouraged from
        changing)
        samples: number of samples to take (by default: "10000")
        -A: boolean option to force FASTA output (by default is
        on). Can turn off by setting to False
        other: used to specify any other options not already
        defined

Function 2: Sample.runBlastn()
    Action: Execute blastn on seqtk output
    Result: Used to gather strandedness information of reads
    Manifest Information: Able to be controlled from manifest
    under the [kall/main] header by setting runBlastn to
    False. Can also control the execution options under the
    [runBlastn] header:
        {blastn} -query {read1} -db {-db} -out {out1} -task
            {-task} -outfmt {-outfmt} -max_target_seqs
            {-max_target_seqs} -num_threads {-num_threads}
            {other}
        {blastn} -query {read2} -db {-db} -out {out2} -task
            {-task} -outfmt {-outfmt} -max_target_seqs
            {-max_target_seqs} -num_threads {-num_threads}
            {other}
        blastn: blastn executable (by default will use
        executable defined under [EXECUTABLES] header)
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        out1: output read 1 (CAUTION: highly discouraged from
        changing)
        out2: output read 2 (CAUTION: highly discouraged from
        changing)
        -db: path to blast database (by default:
        Reference/{basename}.cdna.all)
        -task: task to executed (by default "blastn-short")
        -outfmt: output format (by default '"6 std sstrand"';
        notice the double quotes necessary to contain the
        spaces)
        -max_target_seqs: max target sequences (by default "1")
        -num_threads: processors to use (by default will use
        allocated sample space)
        other: used to specify any other options not already
        defined

Function 3: KallistoSample.runKallisto()
    Action: Uses kallisto to compute equivalence classes for
    reads and quantifies abundances
    Result: A directory that contains qunatification tables
    Manifest Information: Able to be controlled from manifest
    under the [kall/main] header by setting runKallisto to
    False. Can also control the execution options under the
    [kall/runKallisto] header:
        {kallisto} quant -i {-i} -o {-o}
        --threads {--threads}{stranded} -b {-b} {other}
        <( zcat {read1} ) <( zcat {read2} )
        kallisto: kallisto executable (by default will use
        executable defined under [EXECUTABLES] header)
        -i: path to kallisto index build in stage 2 (CAUTION:
        highly discouraged from changing)
        -o: Name of output directory (CAUTION: highly
        discouraged from changing)
        --threads: processors to use (by default will use
        allocated sample space)
        stranded: strandedness of reads (by default will
        determine from blastn and seqtk) Can set to fr, rf,
        False, or None. False specifies unstrandedness while
        None defaults to pipeline findStranded()
        -b: Number of bootstrap samples (by default will use
        100)
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        other: used to specify any other options not already
        defined
""")
    elif helpCommand == 'bowtie2':
        print(bowtie2.__doc__)
        print(
"""\n################################################################
                    bowtie2 Information
################################################################

The bowtie2 API consists of the Bowtie2Experiment and
Bowtie2Sample classes located in pipeClasses.py. There are also
methods and attributes that are inherited from the Experiment
and Sample Class. Execution of an experiment consists of
executing the 4 runStage methods of a Bowtie2Experiment. These
stages are:
            1: Creating Project Structure
            2: Preparing Reference Data
            3: Running actual Pipeline
            4: Organizing results

Within the runStage1() method, there are two functions:
            1: makeStructure()
            2: makeSyms()

Function 1: Experiment.makeStructure():
    Action: Calls the makeStructure.sh shell script which takes
    as its arguments the path to the project and the number of
    samples
    Result: After execution, all the main directories of the
    project should be included -> Project, Data, Original,
    Postprocessing, Reference, and each of the sample
    directories

Function 2: Experiment.makeSyms():
    Action: Calls the makeSyms.sh shell script which takes as
    its arguments the path to the project, the path to the
    original data, and the path to the reference data
    Result: The original data files will have symbolic links in
    their respective sample directories; if there is a metadata
    file specified by the '--jsonfile' option, it will be linked
    in the Postprocessing directory; if the reference data has
    been prepared and specified by the '--use-reference' option,
    the entire reference directory will be linked in the
    Reference directoy, otherwise, just the 3 necessary
    reference files will be linked -> Gtf, Cdna, and Genome

Within the runStage2() method, there are two functions:
            1: qcRef()
            2: ppRef()
            3: buildB2Index()

Function 1: Experiment.qcRef()
    Action: Calls the QCofRef.sh shell script which takes as its
    arguments the path to the reference data and the name of the
    genome.
    Result: Certain characteristics of the reference data will
    be checked such as: the names of the chromosomes in the gtf
    and genome file, the number of chromosomes in the gtf and
    genome file, the names of the genes in the cdna and gtf
    file, the total number of unique genes in the cdna and gtf,
    and the number of unique gene names in the cdna AND not in
    the gtf

Function 2: Experiment.ppRef()
    Action: Prepares the reference data by using various tools
    such as blast, extract_spice_sites.py, extract_exons.py,
    hisat2, and samtools
    Result: A blast database, a file with exon and splice site
    locations, a hisat2 database, and a genome index will be
    created in reference directory

Function 3: Bowtie2Experiment.buildB2Index()
    Action: If needed, bowtie2 will build the indexes needed
    for its analysis in Stage 3
    Results: A bowtie2 index (similar to hisat2 indexes, except
    will have .bt2 suffix)

Within the runStage3() method, there is one function:
            1: GO()

Function 1: Bowtie2Experiment.GO()
    Action: Creates sample classes and executes their runParts
    method
    Result: Experiment infrastructure acts as a wrapper around
    the samples, and executes them individually such that they
    are independent

Further Stage 3 information:

In Stage 3, the GO() method will create execution spaces for
each sample specified on the command line, or all possible by
default. After creating each sample, each sample's runSample()
method will be executed.

For the FCountsSample types, the runSample() method executes the
following commands:
        Part 1:
            1: runQCheck()
            2: runTrimmomatic()
            3: runQCheck()
        Part 2:
            1: runSeqtk()
            2: runBlastn()
            3: runBowtie2()
            4: runCompression()

Part 1: Consists of quality control with fastQC and trimmomatic

Function 1: Sample.runQCheck()
    Action: Runs fastQC on reads and then scrapes the
    overrepresented sequences from fastQC logs
    Result: There will be a fastQC folder in each sample
    directory that contains quality control information
    Manifest Information: Able to be controlled from manifest
    under the [bowtie2/main] header by setting runQCheck to
    False. Can also control the execution options under the
    [runQCheck] header:
        {fastqc} -t {-t} -o {-o} {other} {read1} {read2}
        fastqc: fastQC executable (by default will use
        executable defined under [EXECUTABLES] header)
        -t: processors to use (by default will use allocated
        sample space)
        -o: output directory (by default will use folder named
        fastqc{run-number}.{sample-name}) (CAUTION: highly
        discouraged from changing)
        other: used to specify any other options not already
        defined
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)

Function 2: Sample.runTrimmomatic()
    Action: Executes trimmomatic on reads
    Result: Reads will be trimmed
    Manifest Information: Able to be controlled from manifest
    under the [bowtie2/main] header by setting runTrimmomatic to
    False. Can also control the execution options under the
    [runTrimmomatic] header:
        {java} -jar {-jar} PE -threads {-threads} -phred{-phred}
        {other} {read1} {read2} {read1pout} {read1uout}
        {read2pout} {read2uout}
        ILLUMINACLIP:{blacklist}:{ILLUMINACLIP}
        LEADING:{LEADING} TRAILING:{TRAILING}
        SLIDINGWINDOW:{SLIDINGWINDOW} MINLEN:{MINLEN}
        java: java executable (by default will use executable
        defined under [EXECUTABLES] header)
        -jar: trimmomatic jar file (by default will use
        $RNASEQDIR/trimmomatic-0.36.jar)
        -threads: processors to use (by default will use
        allocated sample space)
        -phred: phred version (by default will scrape version
        from fastQC logs). Can set to 33, 64, or None (for
        default)
        other: used to specify any other options not already
        defined
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        read1pout: output read 1 (CAUTION: highly discouraged
        from changing)
        read2pout: output read 2 (CAUTION: highly discouraged
        from changing)
        read1uout: output read 1 (CAUTION: highly discouraged
        from changing)
        read2uout: output read 2 (CAUTION: highly discouraged
        from changing)
        blacklist: blacklist file (Can also specify on
        command-line with --use-blacklist)
        ILLUMINACLIP: trim options (by default: "2:30:10")
        LEADING: trim options (by default: "5")
        TRAILING: trim options (by default: "5")
        SLIDINGWINDOW: trim options (by default: "4:5")
        MINLEN: trim options (by default: "35")

Function 3: Sample.runQCheck()
    Action: Runs fastQC on reads and then scrapes the
    overrepresented sequences from fastQC logs
    Result: Does the same thing as the previous runQCheck except
    this run is post-trimmomatic to get a perspective on the
    changes that trimmomatic made
    Manifest Information: Able to be controlled from manifest
    under the [bowtie2/main] header by setting runQCheck to
    False or runTrimmomatic to False. Control execution options
    exactly the same as in Function 1.

Part 2: Consists of execution of bowtie2

Function 1: Sample.runSeqtk()
    Action: Execute seqtk on reads to get a representative
    sample of reads
    Result: Obtains a representative sample of reads in order to
    more quickly check strandedness of reads
    Manifest Information: Able to be controlled from manifest
    under the [bowtie2/main] header by setting runSeqtk to
    False. Can also control the execution options under the
    [runSeqtk] header:
        {seqtk} sample -s{-s} {read1} {samples} | seqtk seq {-A}
            {other} - > {read1out}
        {seqtk} sample -s{-s} {read2} {samples} | seqtk seq {-A}
            {other} - > {read2out}
        seqtk: seqtk executable (by default will use executable
        defined under [EXECUTABLES] header)
        -s: random seed (by default: "100")
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        read1out: output read 1 (CAUTION: highly discouraged from
        changing)
        read2out: output read 2 (CAUTION: highly discouraged from
        changing)
        samples: number of samples to take (by default: "10000")
        -A: boolean option to force FASTA output (by default is
        on). Can turn off by setting to False
        other: used to specify any other options not already
        defined

Function 2: Sample.runBlastn()
    Action: Execute blastn on seqtk output
    Result: Used to gather strandedness information of reads
    Manifest Information: Able to be controlled from manifest
    under the [bowtie2/main] header by setting runBlastn to
    False. Can also control the execution options under the
    [runBlastn] header:
        {blastn} -query {read1} -db {-db} -out {out1} -task
            {-task} -outfmt {-outfmt} -max_target_seqs
            {-max_target_seqs} -num_threads {-num_threads}
            {other}
        {blastn} -query {read2} -db {-db} -out {out2} -task
            {-task} -outfmt {-outfmt} -max_target_seqs
            {-max_target_seqs} -num_threads {-num_threads}
            {other}
        blastn: blastn executable (by default will use
        executable defined under [EXECUTABLES] header)
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        out1: output read 1 (CAUTION: highly discouraged from
        changing)
        out2: output read 2 (CAUTION: highly discouraged from
        changing)
        -db: path to blast database (by default:
        Reference/{basename}.cdna.all)
        -task: task to executed (by default "blastn-short")
        -outfmt: output format (by default '"6 std sstrand"';
        notice the double quotes necessary to contain the
        spaces)
        -max_target_seqs: max target sequences (by default "1")
        -num_threads: processors to use (by default will use
        allocated sample space)
        other: used to specify any other options not already
        defined

Function 3: Bowtie2Sample.runBowtie2()
    Action: Executes bowtie2 for alignment of reads to reference
    genome
    Result: A SAM file with identified reads
    Manifest Information: Able to be controlled from manifest
    under the [bowtie2/main] header by setting runBowtie2 to
    False. Can also control the execution options under the
    [bowtie2/runBowtie2] header:
        {bowtie2} {--very-sensitive-local} -k {-k} -p {-p}
        {--rna-strandedness} --phred{--phred} {other} -x {-x}
        -1 {-1} -2 {-2} -S {-S}
        bowtie2: bowtie2 executable (by default will use
        executable defined under [EXECUTABLES] header)
        --very-sensitive-local: true/false setting
        -k: alternates per read (by default "5")
        -p: processors to use (by default will use allocated
        sample space)
        --rna-strandedness: strandedness of reads (by default
        will determine from blastn and seqtk) Can set to fr, rf,
        ff, False, or None. False specifies unstrandedness while
        None defaults to pipeline findStranded()
        --phred: phred version (by default will determine from
        fastQC logs). Can set to 33 or 64
        -x: path to bowtie2 index (by default will use
        Reference/{basename})
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        -S: output SAM file (CAUTION: highly discouraged from
        changing)
        other: used to specify any other options not already
        defined

Function 4: Bowtie2Sample.runCompression()
    Action: Use samtools to compress bowtie2 output
    Result: A compressed BAM files with aligned read information
    Manifest Information: Able to be controlled from manifest
    under the [bowtie2/main] header by setting runCompression to
    False. Can also control the execution options under the
    [bowtie2/runCompression] header:
        {samtools} view {-b} -T {-T} -@{-@} {other} {in} -o {-o}
        samtools: samtools executable (by default will use
        executable defined under [EXECUTABLES] header)
        -b: boolean option to output BAM file (by default on).
        Can turn off by setting to False
        -T: path to reference sequence FASTA file (by default
        will use Reference/{genome_file})
        -@: processors to use (by default will use allocated
        sample space)
        -o: output file name (CAUTION: highly discouraged from
        changing)
        in: input SAM file (CAUTION: highly discouraged from
        changing)
        other: used to specify any other options not already
        defined
""")
    elif helpCommand == 'mj':
        import makeJSON
        print(makeJSON.__doc__)
        print(
"""\n################################################################
                    makeJSON Information
################################################################

Used to create a metadata file for experiment. The JSON metadata
should contain information about the experiment such as the
number of samples and the features that each sample holds. The
metadata file is used in creating comparison groups within the
R analysis. Without this information, lahontan would have no
information with which to automate the creation of the respective
R scripts.

Provided with lahontan is a command to automate the creation of
a minimal metadata file. The command involves user responses to
a series of questions about the experiment. Simply answer each
question and at the conclusion of the survey, the program will
create a syntactically correct JSON file.

For more information on correct JSON syntax, see http://json.org
""")
    elif helpCommand == 'mb':
        import makeTrimBlacklist
        print(makeTrimBlacklist.__doc__)
        print(
"""\n################################################################
                makeTrimBlacklist Information
################################################################

Used to create a read blacklist file for trimmomatic. The FASTA
file generated by the program is used by trimmomatic to remove
any reads it encounters that match a read in the blacklist.

As of trimmomatic v0.36, the default paired-end blacklist file
is:

>PrefixPE/1
TACACTCTTTCCCTACACGACGCTCTTCCGATCT
>PrefixPE/2
GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT

As of lahontan v1.0, the blacklist created by this command is:

>PrefixPE/1
TACACTCTTTCCCTACACGACGCTCTTCCGATCT
>PrefixPE/2
GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT
>PE1
TACACTCTTTCCCTACACGACGCTCTTCCGATCT
>PE1_rc
AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTA
>PE2
GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT
>PE2_rc
AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC
>ABISolid3AdapterB
CCTATCCCCTGTGTGCCTTGGCAGTCTCAGCCTCTCTATGGGCAGTCGGT
>PCR_Primer1
AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT
>PCR_Primer1_rc
AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTAGATCTCGGTGGTCGCCGTATCATT
>PCR_Primer2
CAAGCAGAAGACGGCATACGAGATCGGTCTCGGCATTCCTGCTGAACCGCTCTTCCGATCT
>PCR_Primer2_rc
AGATCGGAAGAGCGGTTCAGCAGGAATGCCGAGACCGATCTCGTATGCCGTCTTCTGCTTG
>FlowCell1
TTTTTTTTTTAATGATACGGCGACCACCGAGATCTACAC
>FlowCell2
TTTTTTTTTTCAAGCAGAAGACGGCATACGA
>ConsecutiveA
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
>ConsecutiveT
TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT
TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT
TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT
TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT
TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT
TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT
TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT
>ConsecutiveC
CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
>ConsecutiveG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG

To modify this file, simply follow FASTA format. For more
information on FASTA format, see
https://en.wikipedia.org/wiki/FASTA_format
""")
    elif helpCommand == 'clean':
        print(cleanup.__doc__)
        print(
"""\n################################################################
                    clean Information
################################################################

This is a utility used to reset the project to a previous state
by removing created files in locations:
    Reference
    Data
    Postprocessing
    All

If you choose to reset the Reference directory, then the program
will remove all files except the genome, cdna, and gtf in the
directory.

If you choose to reset the Data directory, then the program will
reset every sample to the point where only the two raw reads
exist

If you choose to reset the Postprocessing directory, then the
program will remove every file except the Metadata file

If you choose to reset the All directory, then the program will
reset each of the Reference, Data, and Postprocessing
directories
""")
    elif helpCommand == 'fo':
        import optPath
        print(optPath.__doc__)
        print(
"""\n################################################################
                    findOptimal Information
################################################################

This program is used to find the optimal way to create a batch
file. Meaning, findOptimal will create a JSON file that contains
information on how many CPU to spend on each sample per step.

For example, if you wanted to run 12 samples on a cluster that
contained 3 nodes with 48, 48, and 32 CPUs respectively, then
the program will produce the following JSON file:

$ lahontan fo 12 48,48,32
{
    "Step 1": {
        "Procs": 9,
        "Samps": 12
    }
}

This file tells lahontan to create a batch file that executes all
12 samples in parallel with 9 CPUs each.

However, if you wanted to run 12 samples on a single computer with
32 CPUs, the the program will produce the following JSON file:

$ lahontan fo 12 32
{
    "Step 1": {
        "Procs": 4,
        "Samps": 8
    },
    "Step 2": {
        "Procs": 8,
        "Samps": 4
    }
}

This file tells lahontan to create a batch file that executes 8
of the 12 samples in parallel for one step, then after those 8
samples have completed, to run 4 of the 12 samples in parallel
with 8 CPUs each.

However, there are some points of instability within the
optimization algorithm that cause the program to hang. In that
case you can use the -c option to bring up a survey that
will ask you how to define the number of samples per step and
the number of CPUs per sample.

For example,

$ lahontan fo --customize 12 32
Type 0 to exit
Total available CPU: 32

Step 1:
Remaining Samples: 12

Please specify a number of samples to run for Step 1: 8
Please specify the number of CPU each sample should use for Step 1: 4

Step 2:
Remaining Samples: 4

Please specify a number of samples to run for Step 2: 4
Please specify the number of CPU each sample should use for Step 2: 8

Customized Path:
{'Step 1': {'Procs': 4, 'Samps': 8}, 'Step 2': {'Procs': 8, 'Samps': 4}}
Saving to ./OptimalPath.dat
Optimal path saved

In this case, I chose to run 8 samples for step 1 with 4 CPUs
each and 4 samples in step 2 with 8 CPUs each. In general, the
solution to this optimization problem is to run the maximum 
number of samples possible per step while taking advantage of
multiprocessing i.e. always use >1 CPU per sample.

Note that findOptimal is only necessary if you will be executing
with SLURM or another batch job scheduler.
""")
    elif helpCommand == 'prepref':
        print(referenceProcessing.__doc__)
        print(
"""\n################################################################
                    prepref Information
################################################################

This utility is used to prepare the reference data outside of a
project context. It is useful to prepare the reference
information before running the pipeline as there are typically
unforeseen difficulties with the reference information that
cannot be caught by the pipeline. For that reason, it is
recommended that the prepref utility be used prior to running 
the pipeline.

When using prepref, there are two modes of execution: by feeding
a reference directory that contains a GTF, cDNA, and genome file
with the -r option OR by feeding an input file that contains at
least the path to the reference directory with the -i option.

For example, if you have a reference directory located at:

/home/alberton/References/Human

then the appropriate execution syntax is:

lahontan prepref -r /home/alberton/References/Human

OR, if you have a manifest file called prepref.ini that contains
at least:

[locations]
Reference = /home/alberton/References/Human

then the appropriate execution syntax is:

lahontan prepref -i prepref.ini

Additionally, if you are running the pipeline in fcounts or
string mode, then no additional flags are needed. If you are
running the pipeline in kall or bowtie2 mode, then you need to
add the --kallisto or --bowtie2 flag, respectively. These flags
will tell the pipeline to build the additional required indexes.

For example, to additionally build the kallisto index:

lahontan prepref --kallisto -i prepref.ini

The advantages of using the manifest file (-i) over the -r
option is that you are able to control the execution of the
preparation. This ability is similar to the control possible
over the 4 main pipeline.

The prepref utility consists of 8 functions:
        1: qcRef()
        2: createKallistoIndex()
        3: createBowtie2Index()
        4: makeBlastdb()
        5: extractSpliceSites()
        6: extractExons()
        7: hisatBuild()
        8: samtoolsFaidx()

These can all be controlled in the manifest file:

Function 1: qcRef
    Action: Perform quality control check on the reference data.
    Will catch errors in the data such as mismatching names or
    extra chromosomes in genome file.
    Result: A file that contains various quality control
    measures
    Manifest Information: Able to be controlled from manifest
    under the [prepref/main] header by setting qcRef to False.

Function 2: createKallistoIndex
    Action: Use kallisto to build reference index needed for
    kallisto's read alignment
    Result: A kallisto index in the Reference directory
    Manifest Information: Able to be controlled from manifest
    under the [prepref/main] header by setting
    createKallistoIndex to False. Can also control the execution
    options under the [prepref/createKallistoIndex] header:
        {kallisto} index -i {-i} {other} {cdna}
        kallisto: kallisto executable (by default will use
        executable defined under [EXECUTABLES] header)
        -i: Name of output kallisto index (CAUTION: highly
        discouraged from changing)
        cdna: Name of input cDNA file (CAUTION: highly
        discouraged from changing)
        other: used to specify any other options not already
        defined


Function 3: createBowtie2Index
    Action: Use bowtie2 to build reference index needed for
    bowtie2's read alignment
    Result: A bowtie2 index in the Reference directory
    Manifest Information: Able to be controlled from manifest
    under the [prepref/main] header by setting
    createBowtie2Index to False. Can also control the execution
    options under the [prepref/createBowtie2Index] header:
        {bowtie2-build} --threads {--threads} {other}
        {genome} {basename}
        bowtie2-build: bowtie2-build executable (by default
        will use executable defined under [EXECUTABLES] header)
        --threads: processors to use (by default will use
        allocated sample space)
        genome: Name of input genome file (CAUTION: highly
        discouraged from changing)
        basename: Output prefix (CAUTION: highly discouraged
        from changing)
        other: used to specify any other options not already
        defined

Function 4: makeBlastdb
    Action: Use BLAST tools to make a database that will be used
    to qualify the read's strandedness
    Result: A BLAST database in the Reference directory
    Manifest Information: Able to be controlled from manifest
    under the [prepref/main] header by setting makeBlastdb to
    False. Can also control the execution options under the
    [prepref/makeBlastdb] header:
        {makeblastdb} -in {-in} -dbtype {-dbtype} {other}
        -out {-out}
        makeblastdb: makeblastdb executable (by default
        will use executable defined under [EXECUTABLES] header)
        -in: Input cDNA file (CAUTION: highly
        discouraged from changing)
        -dbtype: type of database (by default 'nucl')
        -out: Name of output database file (CAUTION: highly
        discouraged from changing)
        other: used to specify any other options not already
        defined

Function 5: extractSpliceSites
    Action: Mark the splice sites in the transcript annotation
    Result: A file that contains splice site locations
    Manifest Information: Able to be controlled from manifest
    under the [prepref/main] header by setting
    extractSpliceSites to False. Can also control the
    execution options under the
    [prepref/extractSpliceSites] header:
        {extract_splice_sites} {other} {gtf} > {out}
        extract_splice_sites: extract_splice_sites.py
        executable (by default will use executable defined under
        [EXECUTABLES] header)
        gtf: Input GTF file (CAUTION: highly
        discouraged from changing)
        out: Output splice site file (CAUTION: highly
        discouraged from changing)
        other: used to specify any other options not already
        defined

Function 6: extractExons
    Action: Mark the exons in the transcript annotation
    Result: A file that contains exon locations
    Manifest Information: Able to be controlled from manifest
    under the [prepref/main] header by setting extractExons to
    False. Can also control the execution options under the
    [prepref/extractExons] header:
        {extract_exons} {other} {gtf} > {out}
        extract_exons: extract_exons.py executable (by default
        will use executable defined under [EXECUTABLES] header)
        gtf: Input GTF file (CAUTION: highly
        discouraged from changing)
        out: Output splice site file (CAUTION: highly
        discouraged from changing)
        other: used to specify any other options not already
        defined

Function 7: hisatBuild
    Action: Build a hisat2 index that is used for hisat2 read
    alignment steps
    Result: A hisat2 database in the Reference directory
    Manifest Information: Able to be controlled from manifest
    under the [prepref/main] header by setting hisatBuild to
    False. Can also control the execution options under the
    [prepref/hisatBuild] header:
        {hisat2-build} -p {-p} --ss {--ss} --exon {--exon}
        {other} {genome} {basename}
        hisat2-build: hisat2-build executable (by default will
        use executable defined under [EXECUTABLES] header)
        -p: processors to use (by default will use allocated
        sample space)
        -ss: Input splice site file (CAUTION: highly
        discouraged from changing)
        --exon: Input exon file (CAUTION: highly
        discouraged from changing)
        genome: Input genome file (CAUTION: highly
        discouraged from changing)
        basename: Output prefix (CAUTION: highly
        discouraged from changing)
        other: used to specify any other options not already
        defined

Function 8: samtoolsFaidx
    Action: Use samtools to build an index of genome
    Result: A genome index in the Reference directory
    Manifest Information: Able to be controlled from manifest
    under the [prepref/main] header by setting samtoolsFaidx to
    False. Can also control the execution options under the
    [prepref/samtoolsFaidx] header:
        time -p {samtools} faidx {other} {genome}
        samtools: samtools executable (by default will
        use executable defined under [EXECUTABLES] header)
        genome: Input genome file (CAUTION: highly
        discouraged from changing)
        other: used to specify any other options not already
        defined
""")
    elif helpCommand == 'gendef':
        print(generateDefaultInputFile.__doc__)
        print(
"""\n################################################################
            generateDefaultInputFile Information
################################################################

This utility is used to generate a default manifest input file
for the fcounts, string, kall, bowtie2, and prepref modes. The
input file follows standard INI file syntax. For more
information on the INI format followed, see
https://docs.python.org/3/library/configparser.html#supported-ini-file-structure

To summarize, files consist of sections that contain a [section]
header in brackets and a body with key/value entries separated
by and = or : symbol.

For example:

[locations]
Project = /home/alberton/Projects/MouseProject
Reference = /home/alberton/References/MouseReference
Original = /home/alberton/Data/MouseData

The only required section for each mode is the [locations]
section that should at minimum contain definitions for the
Project, Reference, and Original directories. Every other
section contains optional customization options that change the
behavior of the pipeline at runtime.

It's important to note that any options listed on the command
line override any options defined in the manifest file and any
options defined in the manifest file overrides the default
behavior of the pipeline. With the gendef utility, a default
manifest is produced that contains default values for the
pipeline.

In general, specifying a value of None for an option lets the
pipeline perform it's default behavior. Specifying a value of
True/False will turn on/off a behavior. Specifying any other
value will be interpreted by the corresponding function as if
the user is infallible, meaning that inputs are not sanitized
and it is up to the user to make sure that any changes to the
default behavior produces the desired behavior!

It is up to the user to make sure any changes to the default
behavior produces the desired behavior!
""")
    elif helpCommand == 'help':
        print('''Usage: lahontan help <command>\n''')
        print(__doc__[231:-72])
    else:
        print(__doc__)
    raise SystemExit

################################################################
# Reading Command-Line Arguments
################################################################

if __name__ == '__main__':
    beginTime = timer()

    args = docopt(__doc__, version=VERSION, options_first=True)
    argv = [args['<command>']] + args['<args>']
    if args['<command>'] == 'fcounts':
        args.update(docopt(featureCounts.__doc__, argv=argv))
        updatedArgs = updateArgs(args)
        featureCounts(updatedArgs)
    elif args['<command>'] == 'string':
        args.update(docopt(stringtie.__doc__, argv=argv))
        updatedArgs = updateArgs(args)
        stringtie(updatedArgs)
    elif args['<command>'] == 'kall':
        args.update(docopt(kallisto.__doc__, argv=argv))
        updatedArgs = updateArgs(args)
        kallisto(updatedArgs)
    elif args['<command>'] == 'bowtie2':
        args.update(docopt(bowtie2.__doc__, argv=argv))
        updatedArgs = updateArgs(args)
        bowtie2(updatedArgs)
    elif args['<command>'] == 'mj':
        import makeJSON
        args.update(docopt(makeJSON.__doc__, argv=argv))
        makeJSON.writeJSON(args['--jsonfile'])
    elif args['<command>'] == 'mb':
        import makeTrimBlacklist
        args.update(docopt(makeTrimBlacklist.__doc__, argv=argv))
        makeTrimBlacklist.blacklist(args['--tofile'])
    elif args['<command>'] == 'clean':
        args.update(docopt(cleanup.__doc__, argv=argv))
        cleanup(args)
    elif args['<command>'] == 'fo':
        import optPath
        args.update(docopt(optPath.__doc__, argv=argv))
        optPath.main(args)
    elif args['<command>'] == 'prepref':
        args.update(docopt(referenceProcessing.__doc__, argv=argv))
        updatedArgs = updateArgs(args)
        referenceProcessing(updatedArgs)
    elif args['<command>'] == 'gendef':
        args.update(docopt(generateDefaultInputFile.__doc__, argv=argv))
        generateDefaultInputFile(args)
    elif args['<command>'] == 'help':
        moreHelp(args)
    elif args['<command>'] == None:
        otherStuff(args)
    else:
        raise SystemExit("{} is not a lahontan command. See lahontan help".format(args['<command>']))

    timeused = str(time.strftime('%H:%M:%S', time.gmtime(timer() - beginTime)))
    print('[ {} ] Total time elapsed: {}'.format(pipeClasses.now(), timeused))
