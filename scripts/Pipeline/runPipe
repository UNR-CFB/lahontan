#!/usr/bin/python3

'''Usage:
    runPipe [options] <pathtoInputFile>

Options:
    -h, --help
        Show this screen and exit
    -e <stage>, --execute <stage>
        Comma-separated list of stages to be executed.
        Possible stages include:
            1: Creating Project Structure
            2: Preparing Reference Data
            3: Running actual Pipeline
            4: Preparing for R analysis
            5: Running R analysis
            A: (1,2,3,4,5); A=all i.e. runs entire pipeline
        [default: A]
    -r <integer>, --runsample <integer>
        Runs Stage 3 of the pipeline on the sample specified
        by the integer
    -j <jsonFile>, --jsonfile <jsonFile>
        Ignores JSON Metadata file creation and uses specified
        path to JSON Metadata
    -s <phase>, --stringtie <phase>
        Use stringtie tools to replace featureCounts. phase can
        be any of: "a","b","c","ab","bc","abc"
        Option also used to specify stringtie postprocessing
        options in which case use: "--execute 4 --stringtie abc"
        Note: If you will be running phase b, you cannot specify
        a sample to run with --runsample
    -k, --kallisto
        Use kallisto tools to replace featureCounts and hisat2.
    -c <placeToClean>, --clean <placeToClean>
        Cleans <placeToClean>; Possible places include:
            Reference
            Data
            Postprocessing
            All
    --sampleclean <sampleName>
        Similar to --clean; but instead just cleans a
        single sample directory, <sampleName>
    --maxcpu <CPUs>
        Limits number of CPUs used by Pipeline. Without
        argument, default is to use all available CPUs
    --reference-qc <pathtoReferences>
        Runs Quality Control check on Reference files
    --reference-pp <pathtoReferences>
        Pre processes Reference data
    --use-reference
        Use Reference data that has already been prepared.
        Put path to already prepared reference data in 
        INPUT file
        Note: Need to run Stage 1 with this argument
    --makebatch <cluster>
        Makes batch file to be used with slurm. The argument
        it takes is a comma-separated list of CPUs on each
        node in your cluster
    --makebatchbiox
        Modifies behavior of --makebatch. Makes batch file
        with best behavior for our cluster(compute-1,compute-2)
    --batchjson <pathtoJSON>
        Uses json file already created to make batch file
        [default: False]
    --noconfirm
        Ignore all user prompts except JSON file creation
    --NUKE
        Removes entire project Directory
    --edger
        Runs edgeR analysis only. Default is to run both 
    --deseq
        Runs DESeq2 analysis only. Default is to run both
'''

#Examples:
#    runPipe.py /path/to/INPUT
#        This will run the pipeline using the input variables
#        from /path/to/INPUT with all the default behavior
#
#    runPipe.py --execute 1,2 /path/to/INPUT
#        This will run the first and second stage of the
#        pipeline using the input variables from /path/to/INPUT
#
#    runPipe.py --runsample 1,2 /path/to/INPUT
#        This will run third stage on the first and second
#        sample. Note that it will also run first and second
#        stage if needed
#
#    runPipe.py --jsonfile /path/to/Metadata /path/to/INPUT
#        This will run the pipeline using the input variables
#        from /path/to/INPUTfile and will use the JSON located
#        at /path/to/Metadata for DESeq2 and edgeR analysis
#
#    runPipe.py --clean Data /path/to/INPUT
#        This will wipe all of the pipeline's actions on all
#        samples within the respective Project Directory
#        leaving only the symlinks that were created
#
#    runPipe.py --NUKE /path/to/INPUT
#        This will remove entire Project directory denoted by
#        the INPUT variable "Project".
#        Note: Will leave original Reference and Data folders
#        as they were originally made
#'''

################################################################
# Importations
################################################################

from docopt import docopt
from timeit import default_timer as timer
import time
import pipeClasses
import os

################################################################
# Handling Command line arguments
################################################################

def main(arguments):
    ''' Arguments:                   
            None                     
        Returns:                     
            None                     
                                     
        Handles arguments from docopt
        Creates Experiment Class     
        Runs Experiment methods      
        Tip: search for @@@          
    '''                              
    t1 = timer()

    # Global Variables to be used in scripts
    global NOCONFIRM
    NOCONFIRM = arguments['--noconfirm']
    global JSFI # Metadata JSON file
    JSFI = arguments['--jsonfile']
    global IS_REFERENCE_PREPARED
    IS_REFERENCE_PREPARED = arguments['--use-reference']

    pipeClasses.JSFI = JSFI
    pipeClasses.NOCONFIRM = NOCONFIRM
    pipeClasses.IS_REFERENCE_PREPARED = IS_REFERENCE_PREPARED
    pipeClasses.pipeUtils.JSFI = JSFI
    pipeClasses.pipeUtils.NOCONFIRM = NOCONFIRM
    pipeClasses.pipeUtils.IS_REFERENCE_PREPARED = IS_REFERENCE_PREPARED

    # Handling --stringtie
    def makeSTGlobal():
        '''
            If --stringtie option given, same behavior as
            without except Stage 3 is different.
        '''
        tmpStringtie = arguments['--stringtie']
        if tmpStringtie != None:
            possiblePhases = ['a','b','c','ab','bc','abc']
            if tmpStringtie in possiblePhases:
                global STRINGTIE
                STRINGTIE = arguments['--stringtie']
                pipeClasses.STRINGTIE = STRINGTIE
            else:
                raise SystemExit('Invalid argument to --stringtie: {}'.format(
                                                    tmpStringtie))
    makeSTGlobal()

    # Handling --kallisto
    def makeKallistoGlobal():
        '''
            If --kallisto option given, same behavior as
            without except Stage 3 is different.
        '''
        tmpKallisto = arguments['--kallisto']
        if tmpKallisto:
            global KALLISTO
            KALLISTO = arguments['--kallisto']
            pipeClasses.KALLISTO = KALLISTO
    makeKallistoGlobal()

    # Handling --NUKE argument
    def deleteAll():
        if arguments['--NUKE']:
            if NOCONFIRM:
                PROJ = pipeClasses.Experiment(arguments['<pathtoInputFile>'])
                PROJ.nukeProject()
                raise SystemExit
            else:
                PROJ = pipeClasses.Experiment(arguments['<pathtoInputFile>'])
                while True:
                    answer = input('Are you sure you wish to remove {}?(y/n) '.format(PROJ.Project))
                    if answer == 'y':
                        PROJ.nukeProject()
                        raise SystemExit
                    elif answer == 'n':
                        raise SystemExit
                    else:
                        print('Please answer y or n')
    deleteAll()

    # Handling Cleaning Arguments
    def Clean():
        possibleCleanArguments = ['All','Reference','Data','Postprocessing']
        if arguments['--clean'] != None:
            assert arguments['--clean'] in possibleCleanArguments, 'Invalid Cleaning Argument: Run runPipe.py -h for available arguments'
            PROJ = pipeClasses.Experiment(arguments['<pathtoInputFile>'])
            if arguments['--clean'] != 'All':
                if arguments['--clean'] == 'Data':
                    if not os.path.isdir(PROJ.Data):
                        raise SystemExit('{} does not exist'.format(PROJ.Data))
                if arguments['--clean'] == 'Reference':
                    if not os.path.isdir(PROJ.Reference):
                        raise SystemExit('{} does not exist'.format(PROJ.Reference))
                if arguments['--clean'] == 'Postprocessing':
                    if not os.path.isdir(PROJ.Postprocessing):
                        raise SystemExit('{} does not exist'.format(PROJ.Postprocessing))
            PROJ.clean(arguments['--clean'])
            raise SystemExit
        elif arguments['--sampleclean'] != None:
            PROJ = pipeClasses.Experiment(arguments['<pathtoInputFile>'])
            if not os.path.isdir(str(PROJ.Data + '/' + arguments['--sampleclean'])):
                raise SystemExit('{} does not exist'.format(str(PROJ.Data + '/' +
                                                            arguments['--sampleclean'])))
            PROJ.clean('Sample',arguments['--sampleclean'])
            raise SystemExit
    Clean()

    # Checking JSON file for syntax errors
    def checkJSON():
        if JSFI != None:
            pipeClasses.checkJSON(JSFI)
    checkJSON()

    # Making slurm batch files if necessary
    def makeBatch(ExperimentClass):
        ''' Arguments:
                ExperimentClass = class; experiment to run analysis on
            Returns:
                None

            If --makebatch argument given, then make batch script to be
            used with slurm, and then exit
        '''
        if arguments['--batchjson'] != str(False):
            pipeClasses.checkJSON(arguments['--batchjson'])
        if arguments['--makebatchbiox']:
            ExperimentClass.makeBatchBiox(jsonFile=arguments['--batchjson'])
            raise SystemExit('Batch file successfully created:\n\t{}/pipeBatch'.format(os.getcwd()))
        elif arguments['--makebatch'] != None:
            preNodes,Nodes = arguments['--makebatch'].split(','),[]
            for node in preNodes:
                if not node.isdigit() or int(node) <= 0:
                    raise SystemExit('Not a valid argument to --makebatch: {}'.format(
                                            arguments['--makebatch']))
                Nodes.append(int(node))
            if arguments['--stringtie'] != None:
                ExperimentClass.makeStringtieBatch(cluster=Nodes,jsonFile=arguments['--batchjson'])
            elif arguments['--kallisto']:
                ExperimentClass.makeKallistoBatch(cluster=Nodes,jsonFile=arguments['--batchjson'])
            else:
                ExperimentClass.makeBatch(cluster=Nodes,jsonFile=arguments['--batchjson'])
            raise SystemExit('Batch file successfully created:\n\t{}/pipeBatch'.format(os.getcwd()))

    # Returning a maximum CPU value if given
    def checkMaxCPU():
        if arguments['--maxcpu'] == None:
            return None
        else:
            if arguments['--maxcpu'].isdigit():
                Max = int(arguments['--maxcpu'])
                if Max <= os.cpu_count() and Max > 0:
                    return Max
                else:
                    raise SystemExit('--maxcpu greater than available CPUs')
            else:
                raise SystemExit('Invalid value to --maxcpu: {}'.format(
                            arguments['--maxcpu']))

    # Inititiating a class instance
    PROJ = pipeClasses.Experiment(arguments['<pathtoInputFile>'], maxCPU=checkMaxCPU())

    # Inititiating a Runtime Log global location
    global RUNTIMELOG
    RUNTIMELOG = str(PROJ.Project + '/Runtime.log')

    pipeClasses.RUNTIMELOG = RUNTIMELOG

    # Running R analysis
    def runR(ExperimentClass):
        ''' Arguments:
                ExperimentClass = class; experiment to run analysis on
            Returns:
                None

            Runs R analysis, if:
                --edger  :   Then only edgeR analysis done
                --deseq  :   Then only DESeq2 analysis done
                neither argument is provided then both are done
        '''
        if arguments['--edger'] or arguments['--deseq']:
            if arguments['--edger']:
                ExperimentClass.runEdgeR()
            if arguments['--deseq']:
                ExperimentClass.runDESeq()
        else:
            ExperimentClass.runStage5()

    # Running a specific sample
    def checkdashr():
        if arguments['--runsample'] == None:
            return None
        else:
            samples = arguments['--runsample'].split(',')
            possibleSamples = [str(a+1) for a in range(PROJ.getNumberofSamples())]
            if len(samples) == 0:
                print('Argument not valid: {}'.format(
                        arguments['--runsample']))
                print('Possible arguments for --runsample: {}'.format(
                        ','.join(possibleSamples)))
                raise SystemExit
            if len(set(samples)) != len(samples):
                print('Argument not valid: {}'.format(
                        arguments['--runsample']))
                print('Possible arguments for --runsample: {}'.format(
                        ','.join(possibleSamples)))
                raise SystemExit('No repeats allowed')
            for sample in samples:
                if sample not in possibleSamples:
                    print('Argument not valid: {}'.format(
                            arguments['--runsample']))
                    print('Possible arguments for --runsample: {}'.format(
                            ','.join(possibleSamples)))
                    raise SystemExit('Argument not possible')
            return samples

    # Determining what stages to run of Pipeline
    def checkdashe():
        executionStages = arguments['--execute'].split(',')
        possibleStages = ["1","2","3","4","5","A"]
        if len(executionStages) == 0:
            print('Argument not valid: {}'.format(
                    arguments['--execute']))
            raise SystemExit('Possible arguments for --execute: {}'.format(
                            ','.join(possibleStages)))
        if len(set(executionStages)) != len(executionStages):
            print('Argument not valid: {}'.format(
                    arguments['--execute']))
            print('Possible arguments for --execute: {}'.format(
                    ','.join(possibleStages)))
            raise SystemExit('No repeats allowed')
        for stage in executionStages:
            if stage not in possibleStages:
                print('Argument not valid: {}'.format(
                        arguments['--execute']))
                raise SystemExit('Possible arguments for --execute: {}'.format(
                                ','.join(possibleStages)))
        return executionStages

    # Final Execution
    def executeProject(ExperimentClass):
        ''' Arguments:
                ExperimentClass = class; experiment to run analysis on
            Returns:
                None

            Runs Experiment methods based on --execute,--runsample or
            just entire pipeline if not specified
        '''
        makeBatch(ExperimentClass)
        executionSamples = checkdashr()
        executionStages = checkdashe()

        if executionSamples == None:
            if 'A' in executionStages:
                ExperimentClass.runAll()
            else:
                for stageNumber in executionStages:
                    if str(stageNumber) == '5':
                        runR(ExperimentClass)
                    else:
                        exec('ExperimentClass.runStage{}()'.format(stageNumber))
        else:
            if not os.path.exists(ExperimentClass.Data):
                ExperimentClass.runStage1()
            if "KALLISTO" in globals() and ExperimentClass.needToBuildKaliIndex():
                ExperimentClass.runStage2()
            elif not os.path.exists(os.path.join(ExperimentClass.Reference,'Reference_Report.txt')):
                ExperimentClass.runStage2()
            for sample in executionSamples:
                ExperimentClass.executeSample(int(sample))
            if ExperimentClass.is3Finished():
                if 'A' in executionStages:
                    ExperimentClass.runStage4()
                    runR(ExperimentClass)
                else:
                    if '4' in executionStages:
                        ExperimentClass.runStage4()
                    if '5' in executionStages:
                        runR(ExperimentClass)

    ############################################################
    # Call for actually doing stuff
    ############################################################
    # @@@
    executeProject(PROJ)
    ############################################################

    t2 = timer()

    timeused = str(time.strftime('%H:%M:%S', time.gmtime(t2-t1)))
    print('Total time elapsed: {}'.format(timeused))

# For Checking reference Data without an Experiment Structure
def side(arguments):
    ''' Arguments:                   
            None                     
        Returns:                     
            None                     

        Runs Alternate Analysis
    '''                              
    if arguments['--reference-qc'] != None:
        NOCONFIRM = arguments['--noconfirm']
        pipeClasses.pipeUtils.NOCONFIRM = NOCONFIRM
        Init = arguments['--reference-qc']+'/.init'
        if not os.path.exists(Init):
            Gtf,Cdna,Genome = pipeClasses.pipeUtils.getReferenceVariables(
                                                    arguments['--reference-qc'])
            with open(Init,'w') as f:
                f.write('\n'.join([Gtf,Cdna,Genome]))
        else:
            with open(Init,'r') as f:
                Stuff = f.readlines()
            Gtf = Stuff[0].rstrip('\n')
            Cdna = Stuff[1].rstrip('\n')
            Genome = Stuff[2].rstrip('\n')
        pipeClasses.pipeUtils.qcReference(arguments['--reference-qc'],Genome)
        raise SystemExit
    if arguments['--reference-pp'] != None:
        NOCONFIRM = arguments['--noconfirm']
        pipeClasses.pipeUtils.NOCONFIRM = NOCONFIRM
        Init = arguments['--reference-pp']+'/.init'
        if not os.path.exists(Init):
            Gtf,Cdna,Genome = pipeClasses.pipeUtils.getReferenceVariables(
                                                    arguments['--reference-pp'])
            with open(Init,'w') as f:
                f.write('\n'.join([Gtf,Cdna,Genome]))
        else:
            with open(Init,'r') as f:
                Stuff = f.readlines()
            Gtf = Stuff[0].rstrip('\n')
            Cdna = Stuff[1].rstrip('\n')
            Genome = Stuff[2].rstrip('\n')
        Basename = pipeClasses.pipeUtils.getBasename(Genome)
        pipeClasses.pipeUtils.preProcessingReference(arguments['--reference-pp'],
                                                    Cdna,Gtf,Genome,Basename)
        if arguments['--kallisto'] and pipeClasses.needToBuildKaliIndex():
            pipeClasses.buildKallistoIndex()
        raise SystemExit

# Evaluating which analysis to run
def MainVsSide(arguments):
    if arguments['--reference-pp'] != None:
        return 'side'
    if arguments['--reference-qc'] != None:
        return 'side'
    return 'main'

################################################################
if __name__ == '__main__':
    argument = docopt(__doc__, version='Version 1.00\nAuthor: Alberto')
    if MainVsSide(argument) == 'main':
        main(argument)
    else:
        side(argument)
