#!/usr/bin/python3

################################################################
# General Usage
################################################################

'''Usage:
    runPipe [options] [<command>] [<args>...]

Options:
    -h, --help
        Show this screen and exit
    --version
        Show version and exit
    --noconfirm
        Ignore all user prompts except JSON file creation

Available runPipe commands:
    fcounts     For running featureCounts pipeline
    string      For running Stringtie pipeline
    kall        For running kallisto pipeline
    mj          Provoke questionnaire to make a Metadata file
    mb          Create trimmomatic blacklist
    clean       Clean any project directories
    fo          Finds optimal execution path for batch execution
    prepref     Pre-processes reference data
    gendef      Generate a default input file
    readin      Test

See 'runPipe help <command>' for more information on a specific 
command'''
VERSION = 'runPipe version 1.1\n'

################################################################
# Importations
################################################################

from docopt import docopt
from timeit import default_timer as timer
from collections import OrderedDict as OD
import time
import pipeClasses
import os
import glob
import subprocess
import configparser

################################################################
# Utilities
################################################################

def testFile(filePath):
    """ Arguments:
            filePath : str; path to a file
        Returns:
            None
        Tests existence of file
    """
    if not os.path.exists(filePath):
        raise SystemExit('Error: {} does not exist\n\n{}'.format(filePath,__doc__))
    elif os.path.isdir(filePath):
        raise SystemExit('Error: {} is a directory\n\n{}'.format(filePath,__doc__))

def testDir(dirPath):
    """ Arguments:
            dirPath : str; path to a directory
        Returns:
            None
        Tests existence of directory
    """
    if not os.path.isdir(dirPath):
        raise SystemExit('Error: {} does not exist\n\n{}'.format(dirPath,__doc__))

def expandPath(path):
    """ Arguments:
            path : str; any path
        Returns:
            expandedPath : str; path with expanded variables and path
    """
    return os.path.abspath(os.path.expandvars(path))

def makeGlobalVars(arguments):
    ''' Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        Creates global variables NOCONFIRM, JSFI, and IS_REFERENCE_PREPARED
        for runPipe, pipeClasses.py, and pipeUtils.py
    '''
    # Global Variables to be used in scripts
    global NOCONFIRM
    NOCONFIRM = arguments['--noconfirm']
    global JSFI # Metadata JSON file
    if arguments['--jsonfile']:
        JSFI = expandPath(arguments['--jsonfile'])
        if JSFI:
            testFile(JSFI)
    else:
        JSFI = None
    global IS_REFERENCE_PREPARED
    IS_REFERENCE_PREPARED = arguments['--use-reference']
    pipeClasses.JSFI = JSFI
    pipeClasses.NOCONFIRM = NOCONFIRM
    pipeClasses.IS_REFERENCE_PREPARED = IS_REFERENCE_PREPARED

def ppRef(referenceDir, cdna, basename, gtf, genome, cpulimit=None):
    ''' Arguments:
            referenceDir : location of a reference directory
            cdna : location of a CDNA file with a '.cdna.' in the name
            basename : basename of files; typically species name
            gtf : location of gtf file with '.gtf' ending in name
            genome : location of genome file with '.dna.' in name
            *cpulimit : multiprocessing cpu limit, default is to use
                        all available CPUs
        Returns:
            None

        Handles preprocessing without a class structure
    '''
    if cpulimit == None:
        cpulimit = os.cpu_count()
    ppLog = os.path.join(referenceDir, 'Preprocessing.log')
    Context = {
            "cdna": cdna,
            "basename": basename,
            "gtf": gtf,
            "genome": genome,
            "cpu": cpulimit
            }
    makeBlastdb = """time -p makeblastdb -in {cdna} -dbtype nucl -out {basename}.cdna.all""".format(**Context)
    extractSpliceSites = """time -p extract_splice_sites.py {gtf} > splice_sites.txt""".format(**Context)
    extractExons = """time -p extract_exons.py {gtf} > known_exons.txt""".format(**Context)
    hisatBuild = """time -p hisat2-build -p {cpu} --ss splice_sites.txt --exon known_exons.txt {genome} {basename}""".format(**Context)
    samtoolsFaidx = """time -p samtools faidx {genome}""".format(**Context)
    os.chdir(referenceDir)
    print("Preprocessing Data...")
    with open(ppLog, 'w') as PPlog:
        PPlog.write('\n{}\n{}'.format(makeBlastdb,'='*50))
        subprocess.run(makeBlastdb,
                            shell=True,
                            check=True,
                            executable="/bin/bash",
                            stdout=PPlog,
                            stderr=subprocess.STDOUT)
        PPlog.write('\n{}\n{}'.format(extractSpliceSites,'='*50))
        subprocess.run(extractSpliceSites,
                            shell=True,
                            check=True,
                            executable="/bin/bash",
                            stdout=PPlog,
                            stderr=subprocess.STDOUT)
        PPlog.write('\n{}\n{}'.format(extractExons,'='*50))
        subprocess.run(extractExons,
                            shell=True,
                            check=True,
                            executable="/bin/bash",
                            stdout=PPlog,
                            stderr=subprocess.STDOUT)
        PPlog.write('\n{}\n{}'.format(hisatBuild,'='*50))
        subprocess.run(hisatBuild,
                            shell=True,
                            check=True,
                            executable="/bin/bash",
                            stdout=PPlog,
                            stderr=subprocess.STDOUT)
        PPlog.write('\n{}\n{}'.format(samtoolsFaidx,'='*50))
        subprocess.run(samtoolsFaidx,
                            shell=True,
                            check=True,
                            executable="/bin/bash",
                            stdout=PPlog,
                            stderr=subprocess.STDOUT)

def createKallistoIndex(referenceDir, cdna, basename):
    """ Arguments:
            referenceDir : location of a reference directory
            cdna : location of a CDNA file with a '.cdna.' in the name
            basename : basename of files; typically species name
        Returns:
            None

        Handles creating a kallisto index without a class structure
    """
    indexCheck = os.path.join(referenceDir, 'KaliIndexBuilt')
    if not os.path.exists(indexCheck):
        logFile = os.path.join(referenceDir, 'KallistoRuntime.log')        
        # Making Command                                                     
        command = r"{{ time -p kallisto index -i {basename}.kali.cdna.fa.idx {cdna}; }} >> {log} 2>&1"
        context = {"cdna": cdna,
                   "basename": basename,
                   "log": logFile}
        goodCommand = command.format(**context)
        # Executing                                                          
        print('Building kallisto index...')                                  
        os.chdir(referenceDir)
        subprocess.run(goodCommand,
                       shell=True,                                      
                       check=True,
                       executable="/bin/bash")
        with open(indexCheck,'w') as F:
                F.write('True')
    else:
        print('Error: Cannot build Kallisto index; already exists')

def clean(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        Handles runPipe clean command
    """
    # Handling Cleaning Arguments
    possibleCleanArguments = ['All','Reference','Data','Postprocessing']
    if arguments['--clean']:
        assert arguments['--clean'] in possibleCleanArguments, 'Invalid Cleaning Argument: Run runPipe.py -h for available arguments'
        PROJ = pipeClasses.Experiment(expandPath(arguments['<input>']))
        if arguments['--clean'] != 'All':
            if arguments['--clean'] == 'Data':
                if not os.path.isdir(PROJ.Data):
                    raise SystemExit('{} does not exist'.format(PROJ.Data))
            if arguments['--clean'] == 'Reference':
                if not os.path.isdir(PROJ.Reference):
                    raise SystemExit('{} does not exist'.format(PROJ.Reference))
            if arguments['--clean'] == 'Postprocessing':
                if not os.path.isdir(PROJ.Postprocessing):
                    raise SystemExit('{} does not exist'.format(PROJ.Postprocessing))
        if NOCONFIRM:
            PROJ.clean(arguments['--clean'])
            raise SystemExit
        else:
            while True:
                answer = input('Are you sure you wish to clean {}?(y/n) '.format(arguments['--clean']))
                if answer == 'y':
                    PROJ.clean(arguments['--clean'])
                    raise SystemExit
                elif answer == 'n':
                    raise SystemExit
                else:
                    print('Please answer y or n')
    elif arguments['--sampleclean']:
        PROJ = pipeClasses.Experiment(expandPath(arguments['<input>']))
        if not os.path.isdir(str(PROJ.Data + '/' + arguments['--sampleclean'])):
            raise SystemExit('{} does not exist'.format(str(PROJ.Data + '/' +
                                                        arguments['--sampleclean'])))
        if NOCONFIRM:
            PROJ.clean('Sample',arguments['--sampleclean'])
            raise SystemExit
        else:
            while True:
                answer = input('Are you sure you wish to clean {}?(y/n) '.format(arguments['--sampleclean']))
                if answer == 'y':
                    PROJ.clean('Sample',arguments['--sampleclean'])
                    raise SystemExit
                elif answer == 'n':
                    raise SystemExit
                else:
                    print('Please answer y or n')
        raise SystemExit
    else:
        if NOCONFIRM:
            PROJ.clean('All')
            raise SystemExit
        else:
            while True:
                answer = input('Are you sure you wish to clean All?(y/n) ')
                if answer == 'y':
                    PROJ.clean('All')
                    raise SystemExit
                elif answer == 'n':
                    raise SystemExit
                else:
                    print('Please answer y or n')

def makeBatch(ExperimentClass, arguments):
    ''' Arguments:
            ExperimentClass = class; experiment to run analysis on
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        If --makebatch argument given, then make batch script to be
        used with slurm, and then exit
    '''
    # Making slurm batch files if necessary
    if arguments['--batchjson']:
        testFile(expandPath(arguments['--batchjson']))
        pipeClasses.checkJSON(expandPath(arguments['--batchjson']))
    if arguments['--makebatch']:
        preNodes,Nodes = arguments['--makebatch'].split(','),[]
        for node in preNodes:
            if not node.isdigit() or int(node) <= 0:
                raise SystemExit('Not a valid argument to --makebatch: {}'.format(
                                        arguments['--makebatch']))
            Nodes.append(int(node))
        if arguments['<command>'] == 'string':
            ExperimentClass.makeStringtieBatch(cluster=Nodes,
                    jsonFile=expandPath(arguments['--batchjson']))
        elif arguments['<command>'] == 'kall':
            ExperimentClass.makeKallistoBatch(cluster=Nodes,
                    jsonFile=expandPath(arguments['--batchjson']))
        else:
            ExperimentClass.makeBatch(cluster=Nodes,
                    jsonFile=expandPath(arguments['--batchjson']))
        raise SystemExit('Batch file successfully created:\n\t{}/pipeBatch'.format(os.getcwd()))

def checkMaxCPU(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            int or None; the max number of CPU to use, if None
                         then there is no limit
        Checks --maxcpu option from CLI, if option not given
        then default is to use all available CPU
    """
    # Returning a maximum CPU value if given
    if arguments['--maxcpu']:
        if arguments['--maxcpu'].isdigit():
            Max = int(arguments['--maxcpu'])
            if Max <= os.cpu_count() and Max > 0:
                return Max
            else:
                raise SystemExit('--maxcpu greater than available CPUs')
        else:
            raise SystemExit('Invalid value to --maxcpu: {}'.format(
                        arguments['--maxcpu']))
    else:
        return None

def setGlobalLog(ExperimentClass):
    """ Arguments:
            ExperimentClass : Experiment; instance of a class
        Returns:
            None

        Creates a global variable, RUNTIMELOG, that specifies
        location of execution log
    """
    # Inititiating a Runtime Log global location
    global RUNTIMELOG
    RUNTIMELOG = str(os.path.join(ExperimentClass.Project,'Runtime.log'))
    pipeClasses.RUNTIMELOG = RUNTIMELOG

def checkdashr(ExperimentClass, arguments):
    """ Arguments:
            ExperimentClass : Experiment; instance of a class
            arguments : dictionary; CLI arguments from docopt
        Returns:
            samples : list; list of samples to execute

        Checks --runsample argument from CLI
    """
    # Running a specific sample
    if arguments['--runsample']:
        samples = arguments['--runsample'].split(',')
        possibleSamples = [str(a+1) for a in range(ExperimentClass.Numsamples)]
        runsampleUsage = ('Invalid argument to --runsample: {}'.format(arguments['--runsample']) + 
                            'Possible arguments: {}'.format(str(possibleSamples)))
        if len(set(samples)) != len(samples):
            raise SystemExit(runsampleUsage)
        for sample in samples:
            if sample not in possibleSamples:
                raise SystemExit(runsampleUsage)
        return samples

def checkdashe(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            executionStages : list; list of stages to execute

        Checks --execute argument from CLI
    """
    # Determining what stages to run of Pipeline
    if arguments['--execute'] == 'A':
        executionStages = ["1","2","3","4","5"]
    else:
        executionStages = arguments['--execute'].split(',')
    possibleStages = ["1","2","3","4","5","A"]
    executeUsage = ('Invalid argument to --execute: {}'.format(
        arguments['--execute']) + 'Possible arguments: {}'.format(str(possibleStages)))
    if len(set(executionStages)) != len(executionStages):
        raise SystemExit(executeUsage)
    for stage in executionStages:
        if stage not in possibleStages:
            raise SystemExit(executeUsage)
    return executionStages

def checkdashp(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            executionPhases : list; list of phases to execute for
                              Stringtie

        Checks --phase argument from CLI for runPipe string command
    """
    # Handling string --phase
    possiblePhases = ['a','b','c','ab','bc','abc']
    stringtieUsage = ('Invalid argument to --phase: {}'.format(arguments['--phase']) + 
                        'Possible arguments: {}'.format(str(possiblePhases)))
    if arguments['--phase'] not in possiblePhases:
        raise SystemExit(stringtieUsage)
    executionPhases = arguments['--phase']
    return executionPhases

def stage1ReadyToExecute(ExperimentClass):
    """ Arguments:
            ExperimentClass : Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    testFile(ExperimentClass.inputPath)
    return True

def stage2ReadyToExecute(ExperimentClass):
    """ Arguments:
            ExperimentClass : Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    projectPath = ExperimentClass.Project
    dataPath = ExperimentClass.Data
    refPath = ExperimentClass.Reference
    origPath = ExperimentClass.Original
    ppPath = ExperimentClass.Postprocessing
    for directory in [projectPath, dataPath, refPath, origPath, ppPath]:
        testDir(directory)
    for sample in glob.glob(os.path.join(dataPath,'sample_*')):
        if len(glob.glob(os.path.join(sample,'*'))) < 2:
            raise SystemExit('Symbolic links to Original data missing')
    for ref in [os.path.join(ExperimentClass.Reference, f) for f 
            in [ExperimentClass.Gtf, ExperimentClass.Cdna, ExperimentClass.Genome]]:
        testFile(ref)
    return True

def stage3FCReadyToExecute(FCountsClass):
    """ Arguments:
            FCountsClass : featureCounts Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    if FCountsClass.isReferencePrepared():
        return True
    return False

def stage3STReadyToExecute(STClass):
    """ Arguments:
            STClass : Stringtie Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
            None
    """
    if STClass.isReferencePrepared():
        return True
    return False

def stage3KAReadyToExecute(KAClass):
    """ Arguments:
            KAClass : Kallisto Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    if KAClass.isReferencePrepared() and not KAClass.needToBuildKaliIndex():
        return True
    return False

def stage4ReadyToExecute(ExperimentClass):
    """ Arguments:
            ExperimentClass : Experiment; instance of a class
        Returns:
            None
    """
    return ExperimentClass.is3Finished()

def stage5FCReadyToExecute(FCountsClass):
    """ Arguments:
            FCountsClass : featureCounts Experiment; instance of a class
        Returns:
            None
    """
    if (not os.path.exists(os.path.join(FCountsClass.Postprocessing, 'makeEdge.r')) or 
        not os.path.exists(os.path.join(FCountsClass.Postprocessing, 'makeReport.r'))):
        return False
    return True

def stage5STReadyToExecute(STClass):
    """ Arguments:
            STClass : Stringtie Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    if not os.path.exists(os.path.join(STClass.Postprocessing, 'runBallgown.r')):
        return False
    return True

def stage5KAReadyToExecute(KAClass):
    """ Arguments:
            KAClass : Kallisto Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    if not os.path.exists(os.path.join(KAClass.Postprocessing, 'runSleuth.r')):
        return False
    return True

def readInputFile(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            config : dict; arguments from input manifest
        
        Reads input manifest and stores into a dictionary
    """
    inputFile = expandPath(arguments['<input>'])
    testFile(inputFile)
    config = configparser.ConfigParser(interpolation=configparser.ExtendedInterpolation(),
            dict_type=OD)
    config.optionxform = str
    config.BOOLEAN_STATES = {'True': True, 
            'False': False,
            'true': True,
            'false': False,
            'None': False,
            'none': False}
    config.read(arguments['<input>'])
    return config

def updateArgs(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            updatedArgs : dict; containing necessary adjustments from manifest
        
        Combines command line arguments and manifest arguments
        Note: command line arguments take precedence i.e. if command line argument
        specified, use command line argument, else default to manifest
    """
    # Generate a fallback defaults file
    generateDefaultInputFile({'--filename': '.tmprunPipeDefaults.ini','--mode': arguments['<command>']})
    FALLBACK = readInputFile({'<input>': '.tmprunPipeDefaults.ini'})
    mode = arguments['<command>']
    updatedArgs = {}
    Manifest = readInputFile(arguments)
    try:
        manifestArgs = Manifest[mode]
    except KeyError:
        manifestArgs = FALLBACK[mode]
    # Add mode options i.e. options that can be specified on command line
    for option in arguments:
        if arguments[option] == False:
            updatedArgs[option] = manifestArgs.getboolean(option, fallback=FALLBACK[mode].getboolean(option))
        elif arguments[option] == None:
            if manifestArgs.get(option, fallback=FALLBACK[mode].get(option)) == 'None':
                updatedArgs[option] = None
            else:
                updatedArgs[option] = manifestArgs.get(option, fallback=FALLBACK[mode].get(option))
        else:
            updatedArgs[option] = arguments[option]
    # Add all other manifest options
    for section in FALLBACK.sections():
        if section != mode:
            updatedArgs[section] = {}
            for option in FALLBACK[section]:
                try:
                    if Manifest[section].get(option, fallback=FALLBACK[section].get(option)) == 'None':
                        updatedArgs[section][option] = None
                    elif Manifest[section].get(option, fallback=FALLBACK[section].get(option)) == 'False':
                        updatedArgs[section][option] = False
                    elif Manifest[section].get(option, fallback=FALLBACK[section].get(option)) == 'True':
                        updatedArgs[section][option] = True
                    else:
                        updatedArgs[section][option] = Manifest[section].get(option, fallback=FALLBACK[section].get(option))
                except KeyError:
                    if FALLBACK[section].get(option) == 'None':
                        updatedArgs[section][option] = None
                    elif FALLBACK[section].get(option) == 'False':
                        updatedArgs[section][option] = False
                    elif FALLBACK[section].get(option) == 'True':
                        updatedArgs[section][option] = True
                    else:
                        updatedArgs[section][option] = FALLBACK[section].get(option)

    # Remove tmp fallback defaults file
    os.remove('.tmprunPipeDefaults.ini')
    return updatedArgs

################################################################
# Usage Functions
################################################################

def featureCounts(arguments):
    '''Usage:
    runPipe fcounts [options] <input>

Options:
    -h, --help
        Show this screen and exit
    -e <stage>, --execute <stage>
        Comma-separated list of stages to be executed.
        Possible stages include:
            1: Creating Project Structure
            2: Preparing Reference Data
            3: Running actual Pipeline
            4: Preparing for R analysis
            5: Running R analysis
            A: (1,2,3,4,5); A=all i.e. runs entire pipeline
    -r <integer>, --runsample <integer>
        Runs Stage 3 of the pipeline on the sample specified
        by the integer
    -j <jsonFile>, --jsonfile <jsonFile>
        Ignores JSON Metadata file creation and uses specified
        path to JSON Metadata
    --maxcpu <CPUs>
        Limits number of CPUs used by Pipeline. Default is to
        use all available CPUs
    --makebatch <cluster>
        Makes batch file to be used with slurm. The argument
        it takes is a comma-separated list of CPUs on each
        node in your cluster
    --batchjson <pathtoJSON>
        Uses json file already created to make batch file
    --edger
        Runs edgeR analysis only. Default is to run both 
    --deseq
        Runs DESeq2 analysis only. Default is to run both
    --noconfirm
        Ignore all user prompts except JSON file creation
    --use-blacklist <blacklist>
        Trimmomatic blacklist used for quality control
    --use-reference
        Use Reference data that has already been prepared.
        Put path to already prepared reference data in 
        INPUT file
        Note: Need to run Stage 1 with this argument or add to
        "--makebatch" argument'''
    makeGlobalVars(arguments)
    cpuLimit = checkMaxCPU(arguments)
    testFile(expandPath(arguments['<input>']))
    testFile(expandPath(arguments['--use-blacklist']))
    FCClass = pipeClasses.FCountsExperiment(arguments)
    # Make batch file if necessary
    makeBatch(FCClass, arguments)
    setGlobalLog(FCClass)
    samplesToExecute = checkdashr(FCClass, arguments)
    stagesToExecute = checkdashe(arguments)
    # Run Stage 1 if necessary
    if '1' in stagesToExecute and stage1ReadyToExecute(FCClass):
        FCClass.runStage1()
    # Run Stage 2 if necessary
    if '2' in stagesToExecute and stage2ReadyToExecute(FCClass):
        FCClass.runStage2()
    # Run Stage 3 if necessary
    if '3' in stagesToExecute and stage3FCReadyToExecute(FCClass):
        if samplesToExecute == None:
            FCClass.runStage3()
        else:
            for sample in samplesToExecute:
                FCClass.executeSample(sample)
    #TODO do stage 3 reform
    exit(1)
    # Run Stage 4 if necessary
    if '4' in stagesToExecute and stage4ReadyToExecute(FCClass):
        FCClass.runStage4()
    # Run Stage 5 if necessary
    if '5' in stagesToExecute and stage5FCReadyToExecute(FCClass):
        if arguments['--edger'] or arguments['--deseq']:
            if arguments['--edger']:
                FCClass.runEdgeR()
            if arguments['--deseq']:
                FCClass.runDESeq()
        else:
            FCClass.runStage5()

def stringtie(arguments):
    '''Usage:
    runPipe string [options] <input>

Options:
    -h, --help
        Show this screen and exit
    -e <stage>, --execute <stage>
        Comma-separated list of stages to be executed.
        Possible stages include:
            1: Creating Project Structure
            2: Preparing Reference Data
            3: Running actual Pipeline
            4: Preparing for R analysis
            5: Running R analysis
            A: (1,2,3,4,5); A=all i.e. runs entire pipeline
    -r <integer>, --runsample <integer>
        Runs Stage 3 of the pipeline on the sample specified
        by the integer
    -p <phase>, --phase <phase>
        Use stringtie tools to replace featureCounts. phase can
        be any of: "a","b","c","ab","bc","abc"
        Option also used to specify stringtie postprocessing
        options in which case use: "--execute 4 --stringtie abc"
        Note: If you will be running phase b, you cannot specify
        a sample to run with --runsample
    -j <jsonFile>, --jsonfile <jsonFile>
        Ignores JSON Metadata file creation and uses specified
        path to JSON Metadata
    --maxcpu <CPUs>
        Limits number of CPUs used by Pipeline. Default is to
        use all available CPUs
    --noconfirm
        Ignore all user prompts except JSON file creation
    --use-blacklist <blacklist>
        Trimmomatic blacklist used for quality control
    --use-reference
        Use Reference data that has already been prepared.
        Put path to already prepared reference data in 
        INPUT file
        Note: Need to run Stage 1 with this argument or add to
        "--makebatch" argument
    --makebatch <cluster>
        Makes batch file to be used with slurm. The argument
        it takes is a comma-separated list of CPUs on each
        node in your cluster
    --batchjson <pathtoJSON>
        Uses json file already created to make batch file'''
    makeGlobalVars(arguments)
    cpuLimit = checkMaxCPU(arguments)
    testFile(expandPath(arguments['<input>']))
    testFile(expandPath(arguments['--use-blacklist']))
    StringtieClass = pipeClasses.StringtieExperiment(expandPath(arguments['<input>']),
                                                     maxCPU=cpuLimit, 
                                                     blacklist=expandPath(arguments['--use-blacklist']))
    # Make batch file if necessary
    makeBatch(StringtieClass, arguments)
    setGlobalLog(StringtieClass)
    samplesToExecute = checkdashr(StringtieClass, arguments)
    stagesToExecute = checkdashe(arguments)
    phasesToExecute = checkdashp(arguments)
    # Run Stage 1 if necessary
    if '1' in stagesToExecute and stage1ReadyToExecute(StringtieClass):
        StringtieClass.runStage1()
    # Run Stage 2 if necessary
    if '2' in stagesToExecute and stage2ReadyToExecute(StringtieClass):
        StringtieClass.runStage2()
    # Run Stage 3 if necessary
    if '3' in stagesToExecute and stage3STReadyToExecute(StringtieClass):
        if samplesToExecute == None:
            StringtieClass.runStage3(phasesToExecute)
        else:
            for sample in samplesToExecute:
                StringtieClass.executeSample(sample, phasesToExecute)
    # Run Stage 4 if necessary
    if '4' in stagesToExecute and stage4ReadyToExecute(StringtieClass):
        StringtieClass.runStage4()
    # Run Stage 5 if necessary
    if '5' in stagesToExecute and stage5STReadyToExecute(StringtieClass):
        StringtieClass.runStage5()

def kallisto(arguments):
    '''Usage:
    runPipe kall [options] <input>

Options:
    -h, --help
        Show this screen and exit
    -e <stage>, --execute <stage>
        Comma-separated list of stages to be executed.
        Possible stages include:
            1: Creating Project Structure
            2: Preparing Reference Data
            3: Running actual Pipeline
            4: Preparing for R analysis
            5: Running R analysis
            A: (1,2,3,4,5); A=all i.e. runs entire pipeline
    -r <integer>, --runsample <integer>
        Runs Stage 3 of the pipeline on the sample specified
        by the integer
    -j <jsonFile>, --jsonfile <jsonFile>
        Ignores JSON Metadata file creation and uses specified
        path to JSON Metadata
    --maxcpu <CPUs>
        Limits number of CPUs used by Pipeline. Default is to
        use all available CPUs
    --noconfirm
        Ignore all user prompts except JSON file creation
    --use-blacklist <blacklist>
        Trimmomatic blacklist used for quality control
    --use-reference
        Use Reference data that has already been prepared.
        Put path to already prepared reference data in 
        INPUT file
        Note: Need to run Stage 1 with this argument or add to
        "--makebatch" argument
    --makebatch <cluster>
        Makes batch file to be used with slurm. The argument
        it takes is a comma-separated list of CPUs on each
        node in your cluster
    --batchjson <pathtoJSON>
        Uses json file already created to make batch file'''
    makeGlobalVars(arguments)
    cpuLimit = checkMaxCPU(arguments)
    testFile(expandPath(arguments['<input>']))
    testFile(expandPath(arguments['--use-blacklist']))
    KallistoClass = pipeClasses.KallistoExperiment(expandPath(arguments['<input>']),
                                                   maxCPU=cpuLimit, 
                                                   blacklist=expandPath(arguments['--use-blacklist']))
    # Make batch file if necessary
    makeBatch(KallistoClass, arguments)
    setGlobalLog(KallistoClass)
    samplesToExecute = checkdashr(KallistoClass, arguments)
    stagesToExecute = checkdashe(arguments)
    # Run Stage 1 if necessary
    if '1' in stagesToExecute and stage1ReadyToExecute(KallistoClass):
        KallistoClass.runStage1()
    # Run Stage 2 if necessary
    if '2' in stagesToExecute and stage2ReadyToExecute(KallistoClass):
        KallistoClass.runStage2()
    # Run Stage 3 if necessary
    if '3' in stagesToExecute and stage3KAReadyToExecute(KallistoClass):
        if samplesToExecute == None:
            KallistoClass.runStage3()
        else:
            for sample in samplesToExecute:
                KallistoClass.executeSample(sample)
    # Run Stage 4 if necessary
    if '4' in stagesToExecute and stage4ReadyToExecute(KallistoClass):
        KallistoClass.runStage4()
    # Run Stage 5 if necessary
    if '5' in stagesToExecute and stage5KAReadyToExecute(KallistoClass):
        KallistoClass.runStage5()

def cleanup(arguments):
    '''Usage:
    runPipe clean [options] <input>

Options:
    -h, --help
        Show this screen and exit
    -c <placeToClean>, --clean <placeToClean>
        Cleans <placeToClean>; Possible places include:
            Reference
            Data
            Postprocessing
            All
    --sampleclean <sampleName>
        Similar to --clean; but instead just cleans a
        single sample directory, <sampleName>'''
    makeGlobalVars(arguments)
    testFile(expandPath(arguments['<input>']))
    clean(arguments)

def referenceProcessing(arguments):
    '''Usage:
    runPipe prepref [options] <pathtoReferenceDir>

Options:
    -h, --help
        Show this screen and exit
    -q, --qualitycheck
        Only run quality check on references. Default behavior
        is to run both quality control and preprocessing
    -p, --preprocess
        Only run preprocessing on references. Default behavior
        is to run both quality control and preprocessing
    -k, --kallisto
        Additionally build kallisto index
        Note: index required if kallisto pipeline to be used
    --onlykallisto
        Build only the kallisto index
    --maxcpu <CPUs>
        Limit the number of CPU that get used to preprocess
        reference data.
        Note: default is to use all available
        
Mandatory Arguments:
    <pathtoReferenceDir>
        Path to directory that contains a GTF, cDNA, and
        reference genome'''
    makeGlobalVars(arguments)
    cpuLimit = checkMaxCPU(arguments)
    referencePath = expandPath(arguments['<pathtoReferenceDir>'])
    if not os.path.isdir(referencePath):
        raise SystemExit('Reference directory does not exist: {}'.format(referencePath))
    Init = os.path.join(referencePath,'.init')
    if not os.path.exists(Init):
        Gtf,Cdna,Genome = pipeClasses.pipeUtils.getReferenceVariables(referencePath)
        with open(Init,'w') as f:
            f.write('\n'.join([Gtf,Cdna,Genome]))
    else:
        with open(Init,'r') as f:
            Stuff = f.readlines()
        Gtf = Stuff[0].rstrip('\n')
        Cdna = Stuff[1].rstrip('\n')
        Genome = Stuff[2].rstrip('\n')
    Basename = pipeClasses.pipeUtils.getBasename(Genome)
    if arguments['--onlykallisto']:
        createKallistoIndex(referencePath, Cdna, Basename)
        raise SystemExit('Completed Kallisto index; exiting...')
    if arguments['--qualitycheck'] and not arguments['--preprocess']: # only q
        pipeClasses.pipeUtils.qcReference(referencePath,Genome)
    elif not arguments['--qualitycheck'] and arguments['--preprocess']: # only p
        ppRef(referencePath, Cdna, Basename, Gtf, Genome, cpuLimit)
    else: #both
        pipeClasses.pipeUtils.qcReference(referencePath,Genome)
        ppRef(referencePath, Cdna, Basename, Gtf, Genome, cpuLimit)
    if arguments['--kallisto']:
        createKallistoIndex(referencePath, Cdna, Basename)

def generateDefaultInputFile(arguments):
    '''Usage:
    runPipe gendef [options]

Options:
    -h, --help
        Show this screen and exit
    -f <filename>, --filename <filename>
        Name of input file to create
        [default: default_input.ini]
    -m <mode>, --mode <mode>
        Type of execution mode, can be:
            fcounts
            string
            kall
        [default: fcounts]

Note: Any options given on command-line will override those in
input file'''
    config = configparser.ConfigParser(interpolation=configparser.ExtendedInterpolation(),
            dict_type=OD)
    config.optionxform = str
    config.BOOLEAN_STATES = {'True': True, 
            'False': False,
            'true': True,
            'false': False,
            'None': False,
            'none': False}
    # LOCATIONS
    pwd = os.path.abspath(os.curdir)
    config['locations'] = OD((
            ('Project', pwd),
            ('Reference', pwd),
            ('Original', pwd),
            ))
    # MODE
    if arguments['--mode'] not in ['fcounts', 'string', 'kall']:
        raise SystemExit('--mode argument is not valid: {}'.format(arguments['--mode']))
    config['mode'] = OD((
            ('fcounts', 'True' if arguments['--mode'] == 'fcounts' else 'False'),
            ('kall', 'True' if arguments['--mode'] == 'kall' else 'False'),
            ('string', 'True' if arguments['--mode'] == 'string' else 'False'),
            ))
    RNASEQDIR = os.path.expandvars('$RNASEQDIR')
    # GENERAL
    if arguments['--mode'] == 'fcounts':
        config['fcounts'] = OD((
                ('--execute', 'A'),
                ('--runsample', 'None'),
                ('--jsonfile', 'None'),
                ('--maxcpu', 'None'),
                ('--noconfirm', 'False'),
                ('--makebatch', 'None'),
                ('--batchjson', 'None'),
                ('--edger', 'False'),
                ('--deseq', 'False'),
                ('--use-blacklist', RNASEQDIR+'/Trimmomatic/adapters/TruSeq3-PE.fa'),
                ('--use-reference', 'False'),
                ))
    elif arguments['--mode'] == 'string':
        config['string'] = OD((
                ('--execute', 'A'),
                ('--runsample', 'None'),
                ('--phase', 'abc'),
                ('--jsonfile', 'None'),
                ('--maxcpu', 'None'),
                ('--noconfirm', 'False'),
                ('--use-blacklist', RNASEQDIR+'/Trimmomatic/adapters/TruSeq3-PE.fa'),
                ('--use-reference', 'False'),
                ('--makebatch', 'None'),
                ('--batchjson', 'None'),
                ))
    elif arguments['--mode'] == 'kall':
        config['kall'] = OD((
                ('--execute', 'A'),
                ('--runsample', 'None'),
                ('--jsonfile', 'None'),
                ('--maxcpu', 'None'),
                ('--noconfirm', 'False'),
                ('--use-blacklist', RNASEQDIR+'/Trimmomatic/adapters/TruSeq3-PE.fa'),
                ('--use-reference', 'False'),
                ('--makebatch', 'None'),
                ('--batchjson', 'None'),
                ))
    # EXECUTABLES
    config['EXECUTABLES'] = OD((
            ('Rscript', '/usr/local/bin/Rscript'),
            ('java', '/usr/bin/java'),
            ('rnaseqdir', RNASEQDIR),
            ('fastqc', '${rnaseqdir}/fastqc'),
            ('extract_exons.py', '${rnaseqdir}/hisat2/extract_exons.py'),
            ('extract_splice_sites.py', '${rnaseqdir}/hisat2/extract_splice_sites.py'),
            ('hisat2', '${rnaseqdir}/hisat2/hisat2'),
            ('hisat2-build', '${rnaseqdir}/hisat2/hisat2-build'),
            ('samtools', '${rnaseqdir}/samtools/bin/samtools'),
            ('makeblastdb', '${rnaseqdir}/ncbi-blast/bin/makeblastdb'),
            ('blastn', '${rnaseqdir}/ncbi-blast/bin/blastn'),
            ('seqtk', '${rnaseqdir}/seqtk'),
            ('gffcompare', '${rnaseqdir}/gffcompare'),
            ('stranded_classifier.py', '${rnaseqdir}/stranded_classifier.py'),
            ('featureCounts', '${rnaseqdir}/subread/bin/featureCounts'),
            ('stringtie', '${rnaseqdir}/stringtie'),
            ('kallisto', '${rnaseqdir}/kallisto'),
            ))

    ############################################################
    # FCOUNTS
    ############################################################
    if arguments['--mode'] == 'fcounts':
        config['fcounts/main'] = OD((
                ('fcounts/runQCheck', 'True'),
                ('fcounts/runTrimmomatic', 'True'),
                ('fcounts/runSeqtk', 'True'),
                ('fcounts/runBlastn', 'True'),
                ('fcounts/runHisat', 'True'),
                ('fcounts/runCompression', 'True'),
                ('fcounts/runFeatureCounts', 'True'),
                ('fcounts/getNiceColumns', 'True'),
                ('fcounts/getAlignedColumn', 'True'),
                ))
        # fcounts/runQCheck
        # fastqc -t {procs} -o {fastqfolder} {other} {read1} {read2}
        config['fcounts/runQCheck'] = OD((
                ('fastqc', '${EXECUTABLES:fastqc}'),
                ('-t', 'None'),
                ('-o', 'None'),
                ('read1', 'None'),
                ('read2', 'None'),
                ('other', 'None'),
                ))
        # fcounts/runTrimmomatic
        # java -jar $RNASEQDIR/Trimmomatic/trimmomatic-0.36.jar PE -threads {procs} -phred{phred} {other}\
        #       {Read1} {Read2} \
        #       read1.P.trim.{fastq}.gz read1.U.trim.{fastq}.gz \
        #       read2.P.trim.{fastq}.gz read2.U.trim.{fastq}.gz \
        #       ILLUMINACLIP:{blacklist}:2:30:10 LEADING:5 TRAILING:5 SLIDINGWINDOW:4:5 MINLEN:35
        config['fcounts/runTrimmomatic'] = OD((
                ('java', '${EXECUTABLES:java}'),
                ('-jar', 'None'),
                ('-threads', 'None'),
                ('-phred', 'None'),
                ('read1', 'None'),
                ('read2', 'None'),
                ('read1pout', 'None'),
                ('read2pout', 'None'),
                ('read1uout', 'None'),
                ('read2uout', 'None'),
                ('blacklist', 'None'),
                ('LEADING', 'None'),
                ('TRAILING', 'None'),
                ('SLIDINGWINDOW', 'None'),
                ('MINLEN', 'None'),
                ('other', 'None'),
                ))
        # fcounts/runSeqtk
        # seqtk sample -s100 read1.P.trim.{0}.gz 10000 | seqtk seq -A {other} - > sampled.read1.fa
        # seqtk sample -s100 read2.P.trim.{0}.gz 10000 | seqtk seq -A {other} - > sampled.read2.fa
        config['fcounts/runSeqtk'] = OD((
                ('seqtk', '${EXECUTABLES:seqtk}'),
                ('-s', 'None'),
                ('read1', 'None'),
                ('read2', 'None'),
                ('samples', 'None'),
                ('-A', 'None'),
                ('other', 'None'),
                ))
        # fcounts/runBlastn
        # blastn -query sampled.read1.fa -db {0} -out sampled.read1_vscdna.out -task blastn-short \
        #       -outfmt "6 std sstrand" -max_target_seqs 1 -num_threads {1} {other}
        # blastn -query sampled.read2.fa -db {0} -out sampled.read2_vscdna.out -task blastn-short \
        #       -outfmt "6 std sstrand" -max_target_seqs 1 -num_threads {1} {other}
        config['fcounts/runBlastn'] = OD((
                ('blastn', '${EXECUTABLES:blastn}'),
                ('read1', 'None'),
                ('read2', 'None'),
                ('out1', 'None'),
                ('out2', 'None'),
                ('-db', 'None'),
                ('-task', 'None'),
                ('-outfmt', 'None'),
                ('-max_target_seqs', 'None'),
                ('num_threads', 'None'),
                ('other', 'None'),
                ))
        # fcounts/runHisat
        # hisat2 -k 5 -p {numProcs}{FRoRF} --dta --phred{phred} {other}\
        #       --known-splicesite-infile {ref}/splice_sites.txt -x {ref}/{basename} \
        #       -1 read1.P.trim.{fastq}.gz -2 read2.P.trim.{fastq}.gz -S aligned.{sample}.sam
        config['fcounts/runHisat'] = OD((
                ('hisat2', '${EXECUTABLES:hisat2}'),
                ('-k', 'None'),
                ('-p', 'None'),
                ('--rna-strandedness', 'None'),
                ('--dta', 'None'),
                ('--phred', 'None'),
                ('--known-splicesite-infile', 'None'),
                ('-x', 'None'),
                ('-1', 'None'),
                ('-2', 'None'),
                ('-S', 'None'),
                ('other', 'None'),
                ))
        # fcounts/runCompression
        # samtools view -bT {ref}/{genome} -@{procs} {other} aligned.{sample}.sam -o aligned.{sample}.bam
        config['fcounts/runCompression'] = OD((
                ('samtools', '${EXECUTABLES:samtools}'),
                ('-b', 'None'),
                ('-T', 'None'),
                ('-@', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))
        # fcounts/runFeatureCounts
        # featureCounts -T {procs} -s {stranded} -p -C --primary --ignoreDup -t exon -g gene_id \
        #       -a {ref}/{gtf} -o aligned.{sample}.counts {other} aligned.{sample}.bam
        config['fcounts/runCompression'] = OD((
                ('featureCounts', '${EXECUTABLES:featureCounts}'),
                ('-T', 'None'),
                ('-s', 'None'),
                ('-p', 'None'),
                ('-C', 'None'),
                ('--primary', 'None'),
                ('--ignoreDup', 'None'),
                ('-t', 'None'),
                ('-g', 'None'),
                ('-a', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))

    ############################################################
    # STRING
    ############################################################
    elif arguments['--mode'] == 'string':
        config['string/main'] = OD((
                ('string/runQCheck', 'True'),
                ('string/runTrimmomatic', 'True'),
                ('string/runSeqtk', 'True'),
                ('string/runBlastn', 'True'),
                ('string/runHisat', 'True'),
                ('string/runAltCompression', 'True'),
                ('string/assembleTranscripts', 'True'),
                ('string/stringtieMerge', 'True'),
                ('string/compareTranscripts', 'True'),
                ('string/estimateTranscriptAbundances', 'True'),
                ))
        # string/runQCheck
        # fastqc -t {procs} -o {fastqfolder} {other} {read1} {read2}
        config['string/runQCheck'] = OD((
                ('fastqc', '${EXECUTABLES:fastqc}'),
                ('-t', 'None'),
                ('-o', 'None'),
                ('read1', 'None'),
                ('read2', 'None'),
                ('other', 'None'),
                ))
        # string/runTrimmomatic
        # java -jar $RNASEQDIR/Trimmomatic/trimmomatic-0.36.jar PE -threads {procs} -phred{phred} \
        #       {Read1} {Read2} \
        #       read1.P.trim.{fastq}.gz read1.U.trim.{fastq}.gz \
        #       read2.P.trim.{fastq}.gz read2.U.trim.{fastq}.gz \
        #       ILLUMINACLIP:{blacklist}:2:30:10 LEADING:5 TRAILING:5 SLIDINGWINDOW:4:5 MINLEN:35
        config['string/runTrimmomatic'] = OD((
                ('java', '${EXECUTABLES:java}'),
                ('-jar', 'None'),
                ('-threads', 'None'),
                ('-phred', 'None'),
                ('read1', 'None'),
                ('read2', 'None'),
                ('read1pout', 'None'),
                ('read2pout', 'None'),
                ('read1uout', 'None'),
                ('read2uout', 'None'),
                ('blacklist', 'None'),
                ('LEADING', 'None'),
                ('TRAILING', 'None'),
                ('SLIDINGWINDOW', 'None'),
                ('MINLEN', 'None'),
                ('other', 'None'),
                ))
        # string/runSeqtk
        # seqtk sample -s100 read1.P.trim.{0}.gz 10000 | seqtk seq -A {other} - > sampled.read1.fa
        # seqtk sample -s100 read2.P.trim.{0}.gz 10000 | seqtk seq -A {other} - > sampled.read2.fa
        config['string/runSeqtk'] = OD((
                ('seqtk', '${EXECUTABLES:seqtk}'),
                ('-s', 'None'),
                ('read1', 'None'),
                ('read2', 'None'),
                ('samples', 'None'),
                ('-A', 'None'),
                ('other', 'None'),
                ))
        # string/runBlastn
        # blastn -query sampled.read1.fa -db {0} -out sampled.read1_vscdna.out -task blastn-short \
        #       -outfmt "6 std sstrand" -max_target_seqs 1 -num_threads {1} {other}
        # blastn -query sampled.read2.fa -db {0} -out sampled.read2_vscdna.out -task blastn-short \
        #       -outfmt "6 std sstrand" -max_target_seqs 1 -num_threads {1} {other}
        config['string/runBlastn'] = OD((
                ('blastn', '${EXECUTABLES:blastn}'),
                ('read1', 'None'),
                ('read2', 'None'),
                ('out1', 'None'),
                ('out2', 'None'),
                ('-db', 'None'),
                ('-task', 'None'),
                ('-outfmt', 'None'),
                ('-max_target_seqs', 'None'),
                ('num_threads', 'None'),
                ('other', 'None'),
                ))
        # string/runHisat
        # hisat2 -k 5 -p {numProcs}{FRoRF} --dta --phred{phred} {other}\
        #       --known-splicesite-infile {ref}/splice_sites.txt -x {ref}/{basename} \
        #       -1 read1.P.trim.{fastq}.gz -2 read2.P.trim.{fastq}.gz -S aligned.{sample}.sam
        config['string/runHisat'] = OD((
                ('hisat2', '${EXECUTABLES:hisat2}'),
                ('-k', 'None'),
                ('-p', 'None'),
                ('--rna-strandedness', 'None'),
                ('--dta', 'None'),
                ('--phred', 'None'),
                ('--known-splicesite-infile', 'None'),
                ('-x', 'None'),
                ('-1', 'None'),
                ('-2', 'None'),
                ('-S', 'None'),
                ('other', 'None'),
                ))
        # string/runAltCompression
        # samtools sort -@ {procs} -o aligned.{sample}.bam {other} aligned.{sample}.sam
        config['string/runAltCompression'] = OD((
                ('samtools', '${EXECUTABLES:samtools}'),
                ('-@', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))
        # string/assembleTranscripts
        # stringtie -p {procs} -o {sample}.st.gtf -l {sample} {other} aligned.{sample}.bam
        config['string/assembleTranscripts'] = OD((
                ('stringtie', '${EXECUTABLES:stringtie}'),
                ('-p', 'None'),
                ('-o', 'None'),
                ('-l', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))
        # string/stringtieMerge
        # stringtie --merge -p {procs} -o {mergedir}/{projectname}.stmerged.gtf {other} {mergelist}
        config['string/makeStringtieMergelist'] = OD((
                ('stringtie', '${EXECUTABLES:stringtie}'),
                ('-p', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))
        # string/compareTranscripts
        # gffcompare -r {ref}/{gtf} -G -o {projectname}.merged {other} {stmerged}
        config['string/compareTranscripts'] = OD((
                ('gffcompare', '${EXECUTABLES:gffcompare}'),
                ('-r', 'None'),
                ('-G', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))
        # string/estimateTranscriptAbundances
        # stringtie -e -B -p {procs} -G {stmerged} -o {sample}.good.st.gtf {other} aligned.{sample}.bam
        config['string/estimateTranscriptAbundances'] = OD((
                ('stringtie', '${EXECUTABLES:stringtie}'),
                ('-e', 'None'),
                ('-B', 'None'),
                ('-p', 'None'),
                ('-G', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))

    ############################################################
    # KALL
    ############################################################
    elif arguments['--mode'] == 'kall':
        config['kall/main'] = OD((
                ('kall/runQCheck', 'True'),
                ('kall/runTrimmomatic', 'True'),
                ('kall/runSeqtk', 'True'),
                ('kall/runBlastn', 'True'),
                ('kall/runKallisto', 'True'),
                ))
        # kall/runQCheck
        # fastqc -t {procs} -o {fastqfolder} {other} {read1} {read2}
        config['kall/runQCheck'] = OD((
                ('fastqc', '${EXECUTABLES:fastqc}'),
                ('-t', 'None'),
                ('-o', 'None'),
                ('read1', 'None'),
                ('read2', 'None'),
                ('other', 'None'),
                ))
        # kall/runTrimmomatic
        # java -jar $RNASEQDIR/Trimmomatic/trimmomatic-0.36.jar PE -threads {procs} -phred{phred} \
        #       {Read1} {Read2} \
        #       read1.P.trim.{fastq}.gz read1.U.trim.{fastq}.gz \
        #       read2.P.trim.{fastq}.gz read2.U.trim.{fastq}.gz \
        #       ILLUMINACLIP:{blacklist}:2:30:10 LEADING:5 TRAILING:5 SLIDINGWINDOW:4:5 MINLEN:35
        config['kall/runTrimmomatic'] = OD((
                ('java', '${EXECUTABLES:java}'),
                ('-jar', 'None'),
                ('-threads', 'None'),
                ('-phred', 'None'),
                ('read1', 'None'),
                ('read2', 'None'),
                ('read1pout', 'None'),
                ('read2pout', 'None'),
                ('read1uout', 'None'),
                ('read2uout', 'None'),
                ('blacklist', 'None'),
                ('LEADING', 'None'),
                ('TRAILING', 'None'),
                ('SLIDINGWINDOW', 'None'),
                ('MINLEN', 'None'),
                ('other', 'None'),
                ))
        # kall/runSeqtk
        # seqtk sample -s100 read1.P.trim.{0}.gz 10000 | seqtk seq -A {other} - > sampled.read1.fa
        # seqtk sample -s100 read2.P.trim.{0}.gz 10000 | seqtk seq -A {other} - > sampled.read2.fa
        config['kall/runSeqtk'] = OD((
                ('seqtk', '${EXECUTABLES:seqtk}'),
                ('-s', 'None'),
                ('read1', 'None'),
                ('read2', 'None'),
                ('samples', 'None'),
                ('-A', 'None'),
                ('other', 'None'),
                ))
        # kall/runBlastn
        # blastn -query sampled.read1.fa -db {0} -out sampled.read1_vscdna.out -task blastn-short \
        #       -outfmt "6 std sstrand" -max_target_seqs 1 -num_threads {1} {other}
        # blastn -query sampled.read2.fa -db {0} -out sampled.read2_vscdna.out -task blastn-short \
        #       -outfmt "6 std sstrand" -max_target_seqs 1 -num_threads {1} {other}
        config['kall/runBlastn'] = OD((
                ('blastn', '${EXECUTABLES:blastn}'),
                ('read1', 'None'),
                ('read2', 'None'),
                ('out1', 'None'),
                ('out2', 'None'),
                ('-db', 'None'),
                ('-task', 'None'),
                ('-outfmt', 'None'),
                ('-max_target_seqs', 'None'),
                ('num_threads', 'None'),
                ('other', 'None'),
                ))
        # kall/runKallisto
        # kallisto quant -i {transcriptindex} -o {outputdir} --threads {procs}{FRoRF} -b 100 \
        #       <( zcat read1.P.trim.{fastq}.gz ) <( zcat read2.P.trim.{fastq}.gz )
        config['kall/runKallisto'] = OD((
                ('kallisto', '${EXECUTABLES:kallisto}'),
                ('-i', 'None'),
                ('-o', 'None'),
                ('--threads', 'None'),
                ('stranded', 'None'),
                ('-b', 'None'),
                ('read1', 'None'),
                ('read2', 'None'),
                ('other', 'None'),
                ))

    ############################################################
    with open(arguments['--filename'], 'w') as configfile:
        config.write(configfile)
    ############################################################

def otherStuff(arguments):
    ''' Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        Handles what happens when a sub-command is given that
        isn't real
    '''
    if any(arguments.values()):
        raise SystemExit(__doc__)
    else:
        raise SystemExit(__doc__)

def moreHelp(arguments):
    ''' Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        Handles the help subcommand
    '''
    try:
        helpCommand = arguments['<args>'][0]
    except IndexError:
        raise SystemExit(__doc__)
    if helpCommand == 'fcounts':
        print('''This is featureCounts information #TODO''')
        raise SystemExit(featureCounts.__doc__)
    elif helpCommand == 'string':
        print('''This is stringtie information #TODO''')
        raise SystemExit(stringtie.__doc__)
    elif helpCommand == 'kall':
        print('''This is kallisto information #TODO''')
        raise SystemExit(kallisto.__doc__)
    elif helpCommand == 'mj':
        print('''This is makeJSON information #TODO''')
        import makeJSON
        raise SystemExit(makeJSON.__doc__)
    elif helpCommand == 'mb':
        print('''This is makeTrimBlacklist''')
        import makeTrimBlacklist
        raise SystemExit(makeTrimBlacklist.__doc__)
    elif helpCommand == 'clean':
        print('''This is cleanup information #TODO''')
        raise SystemExit(cleanup.__doc__)
    elif helpCommand == 'fo':
        print('''This is optPath information #TODO''')
        import optPath
        raise SystemExit(optPath.__doc__)
    elif helpCommand == 'prepref':
        print('''This is reference preprocessing information #TODO''')
        raise SystemExit(referenceProcessing.__doc__)
    elif helpCommand == 'help':
        print('''Help command provides help #TODO''')
    else:
        raise SystemExit(__doc__)

################################################################
# Reading Command-Line Arguments
################################################################

if __name__ == '__main__':
    beginTime = timer()
    from pprint import pprint

    args = docopt(__doc__, version=VERSION, options_first=True)
    argv = [args['<command>']] + args['<args>']
    if args['<command>'] == 'fcounts':
        args.update(docopt(featureCounts.__doc__, argv=argv))
        updatedArgs = updateArgs(args)
        pprint(updatedArgs)
        featureCounts(updatedArgs)
    elif args['<command>'] == 'string':
        args.update(docopt(stringtie.__doc__, argv=argv))
        print(args)
        updatedArgs = updateArgs(args)
        exit()
        stringtie(updatedArgs)
    elif args['<command>'] == 'kall':
        args.update(docopt(kallisto.__doc__, argv=argv))
        updatedArgs = updateArgs(args)
        kallisto(updatedArgs)
    elif args['<command>'] == 'mj':
        import makeJSON
        args.update(docopt(makeJSON.__doc__, argv=argv))
        makeJSON.writeJSON(args['--jsonfile'])
    elif args['<command>'] == 'mb':
        import makeTrimBlacklist
        args.update(docopt(makeTrimBlacklist.__doc__, argv=argv))
        makeTrimBlacklist.blacklist(args['--tofile'])
    elif args['<command>'] == 'clean':
        args.update(docopt(cleanup.__doc__, argv=argv))
        cleanup(args)
    elif args['<command>'] == 'fo':
        import optPath
        args.update(docopt(optPath.__doc__, argv=argv))
        optPath.main(args)
    elif args['<command>'] == 'prepref':
        args.update(docopt(referenceProcessing.__doc__, argv=argv))
        referenceProcessing(args)
    elif args['<command>'] == 'gendef':
        args.update(docopt(generateDefaultInputFile.__doc__, argv=argv))
        generateDefaultInputFile(args)
    elif args['<command>'] == 'readin':
        args.update(docopt(readInputFile.__doc__, argv=argv))
        readInputFile(args)
    elif args['<command>'] == 'help':
        moreHelp(args)
    elif args['<command>'] == None:
        otherStuff(args)
    else:
        raise SystemExit("{} is not a runPipe command. See runPipe help".format(args['<command>']))

    timeused = str(time.strftime('%H:%M:%S', time.gmtime(timer() - beginTime)))
    print('Total time elapsed: {}'.format(timeused))
