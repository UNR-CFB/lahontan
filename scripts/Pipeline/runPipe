#!/usr/bin/python3

################################################################
# General Usage
################################################################

'''Usage:
    runPipe [options] [<command>] [<args>...]

Options:
    -h, --help
        Show this screen and exit
    --version
        Show version and exit
    --noconfirm
        Ignore all user prompts except JSON file creation

Available runPipe commands:
    fcounts     For running featureCounts pipeline
    string      For running Stringtie pipeline
    kall        For running kallisto pipeline
    bowtie2     For running Bowtie2 pipeline
    mj          Provoke questionnaire to make a Metadata file
    mb          Create trimmomatic blacklist
    clean       Clean any project directories
    fo          Finds optimal execution path for batch execution
    prepref     Pre-processes reference data
    gendef      Generate a default input file

See 'runPipe help <command>' for more information on a specific
command'''
VERSION = 'runPipe version 1.1\n'

################################################################
# Importations
################################################################

from docopt import docopt
from timeit import default_timer as timer
from collections import OrderedDict as OD
import time
import pipeClasses
import os
import glob
import subprocess
import configparser

################################################################
# Utilities
################################################################

def testFile(filePath):
    """ Arguments:
            filePath : str; path to a file
        Returns:
            None
        Tests existence of file
    """
    if not os.path.exists(filePath):
        raise SystemExit('Error: {} does not exist\n\n{}'.format(filePath,__doc__))
    elif os.path.isdir(filePath):
        raise SystemExit('Error: {} is a directory\n\n{}'.format(filePath,__doc__))

def testDir(dirPath):
    """ Arguments:
            dirPath : str; path to a directory
        Returns:
            None
        Tests existence of directory
    """
    if not os.path.isdir(dirPath):
        raise SystemExit('Error: {} does not exist\n\n{}'.format(dirPath,__doc__))

def expandPath(path):
    """ Arguments:
            path : str; any path
        Returns:
            expandedPath : str; path with expanded variables and path
    """
    return os.path.abspath(os.path.expandvars(path))

def checkMan(default, manifest):
    """ Arguments:
         default :
        manifest :
        Returns:
            None
    """
    return default if manifest == None else manifest

def checkManBool(default, manifest):
    """ Arguments:
         default :
        manifest :
        Returns:
            None
    """
    return default if manifest == None else ""

def makeGlobalVars(arguments):
    ''' Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        Creates global variables NOCONFIRM, JSFI, and IS_REFERENCE_PREPARED
        for runPipe and pipeClasses.py
    '''
    # Global Variables to be used in scripts
    global NOCONFIRM
    NOCONFIRM = arguments['--noconfirm']
    global JSFI # Metadata JSON file
    if arguments['--jsonfile']:
        JSFI = expandPath(arguments['--jsonfile'])
        if JSFI:
            testFile(JSFI)
    else:
        JSFI = None
    global IS_REFERENCE_PREPARED
    IS_REFERENCE_PREPARED = arguments['--use-reference']
    pipeClasses.JSFI = JSFI
    pipeClasses.NOCONFIRM = NOCONFIRM
    pipeClasses.IS_REFERENCE_PREPARED = IS_REFERENCE_PREPARED

def qcRef(referenceDir, genome):
    """ Arguments:
            referenceDir : location of a reference directory
            genome : location of genome file with '.dna.' in name
        Returns:
            None
    """
    print(("[ {} ] Running Quality Control"+
        " Check on Reference Data...").format(pipeClasses.now()))
    command = r'''QCofRef.sh {} {}'''.format(referenceDir, genome)
    subprocess.run(command,
        shell=True,
        check=True,
        executable="/bin/bash")
    with open(os.path.join(referenceDir, 'Reference_Report.txt'),
            'r') as Report:
        print(Report.read())
    print('\nSee Reference_Report.txt to view initial Diagnostics')

def ppRef(referenceDir, cdna, basename, gtf, genome, cpulimit, args):
    ''' Arguments:
            referenceDir : location of a reference directory
            cdna : location of a CDNA file with a '.cdna.' in the name
            basename : basename of files; typically species name
            gtf : location of gtf file with '.gtf' ending in name
            genome : location of genome file with '.dna.' in name
            *cpulimit : multiprocessing cpu limit, default is to use
                        all available CPUs
        Returns:
            None

        Handles preprocessing without a class structure
    '''
    if cpulimit == None:
        cpulimit = os.cpu_count()
    ppLog = os.path.join(referenceDir, 'Preprocessing.log')
    #makeBlastdb = """time -p makeblastdb -in {cdna} -dbtype nucl 
    # -out {basename}.cdna.all""".format(**Context)
    makeBlastdb = ("""time -p {makeblastdb} -in {-in} -dbtype {-dbtype}"""+
        """ {other} -out {-out}""").format(
            **{
            "makeblastdb": checkMan("makeblastdb",
                args["prepref/makeBlastdb"]['makeblastdb']),
            "-in": checkMan(cdna, args["prepref/makeBlastdb"]['-in']),
            "-dbtype": checkMan('nucl',
                args["prepref/makeBlastdb"]['-dbtype']),
            "other": checkMan('', args["prepref/makeBlastdb"]['other']),
            "-out": checkMan("{}.cdna.all".format(basename),
                args["prepref/makeBlastdb"]['-out'])
            })
    #extractSpliceSites = """time -p extract_splice_sites.py {gtf} > 
    # splice_sites.txt""".format(**Context)
    pprint(makeBlastdb)
    pprint(args["prepref/extractSpliceSites"])
    extractSpliceSites = ("""time -p {extract_splice_sites} {other}"""+
        """ {gtf} > {out}""").format(
            **{
            "extract_splice_sites": checkMan("extract_splice_sites.py",
                args["prepref/extractSpliceSites"]['extract_splice_sites.py']),
            "other": checkMan('', args["prepref/extractSpliceSites"]['other']),
            "gtf": checkMan(gtf, args["prepref/extractSpliceSites"]['gtf']),
            "out": checkMan("splice_sites.txt", args["prepref/extractSpliceSites"]['out'])
            })
    #extractExons = """time -p extract_exons.py {gtf} > 
    # known_exons.txt""".format(**Context)
    extractExons = ("""time -p {extract_exons} {other} {gtf} >"""+
        """ {out}""").format(
            **{
            "extract_exons": checkMan("extract_exons.py",
                args["prepref/extractExons"]['extract_exons.py']),
            "other": checkMan('', args["prepref/extractExons"]['other']),
            "gtf": checkMan(gtf, args["prepref/extractExons"]['gtf']),
            "out": checkMan("known_exons.txt",
                args["prepref/extractExons"]['out'])
            })
    #hisatBuild = """time -p hisat2-build -p {cpu} --ss splice_sites.txt 
    # --exon known_exons.txt {genome} {basename}""".format(**Context)
    hisatBuild = ("""time -p {hisat2-build} -p {-p} --ss {--ss}"""+
        """ --exon {--exon} {other} {genome} {basename}""").format(
            **{
            "hisat2-build": checkMan("hisat2-build",
                args["prepref/hisatBuild"]['hisat2-build']),
            "-p": checkMan(cpulimit, args["prepref/hisatBuild"]['-p']),
            "--ss": checkMan("splice_sites.txt",
                args["prepref/hisatBuild"]['--ss']),
            "--exon": checkMan("known_exons.txt",
                args["prepref/hisatBuild"]['--exon']),
            "other": checkMan('', args["prepref/hisatBuild"]['other']),
            "genome": checkMan(genome, args["prepref/hisatBuild"]['genome']),
            "basename": checkMan(basename,
                args["prepref/hisatBuild"]['basename']),
            })
    #samtoolsFaidx = """time -p samtools faidx {genome}""".format(**Context)
    samtoolsFaidx = ("""time -p {samtools} faidx {other} {genome}""").format(
            **{
            "samtools": checkMan("samtools",
                args["prepref/samtoolsFaidx"]['samtools']),
            "other": checkMan('', args["prepref/samtoolsFaidx"]['other']),
            "genome": checkMan(genome,
                args["prepref/samtoolsFaidx"]['genome']),
            })
    os.chdir(referenceDir)
    print("[ {} ] Preprocessing Data...".format(pipeClasses.now()))
    with open(ppLog, 'w') as PPlog:
        if args['prepref/main']['makeBlastdb']:
            PPlog.write('\n{}\n{}'.format(makeBlastdb,'='*50))
            subprocess.run(makeBlastdb,
                shell=True,
                check=True,
                executable="/bin/bash",
                stdout=PPlog,
                stderr=subprocess.STDOUT)
        else:
            print('makeBlastdb skipped due to manifest\n')
            PPlog.write('makeBlastdb skipped due to manifest\n')
        if args['prepref/main']['extractSpliceSites']:
            PPlog.write('\n{}\n{}'.format(extractSpliceSites,'='*50))
            subprocess.run(extractSpliceSites,
                shell=True,
                check=True,
                executable="/bin/bash",
                stdout=PPlog,
                stderr=subprocess.STDOUT)
        else:
            print('extractSpliceSites skipped due to manifest\n')
            PPlog.write('extractSpliceSites skipped due to manifest\n')
        if args['prepref/main']['extractExons']:
            PPlog.write('\n{}\n{}'.format(extractExons,'='*50))
            subprocess.run(extractExons,
                shell=True,
                check=True,
                executable="/bin/bash",
                stdout=PPlog,
                stderr=subprocess.STDOUT)
        else:
            print('extractExons skipped due to manifest\n')
            PPlog.write('extractExons skipped due to manifest\n')
        if args['prepref/main']['hisatBuild']:
            PPlog.write('\n{}\n{}'.format(hisatBuild,'='*50))
            subprocess.run(hisatBuild,
                shell=True,
                check=True,
                executable="/bin/bash",
                stdout=PPlog,
                stderr=subprocess.STDOUT)
        else:
            print('hisatBuild skipped due to manifest\n')
            PPlog.write('hisatBuild skipped due to manifest\n')
        if args['prepref/main']['samtoolsFaidx']:
            PPlog.write('\n{}\n{}'.format(samtoolsFaidx,'='*50))
            subprocess.run(samtoolsFaidx,
                shell=True,
                check=True,
                executable="/bin/bash",
                stdout=PPlog,
                stderr=subprocess.STDOUT)
        else:
            print('samtoolsFaidx skipped due to manifest\n')
            PPlog.write('samtoolsFaidx skipped due to manifest\n')

def createKallistoIndex(referenceDir, cdna, basename, arguments):
    """ Arguments:
            referenceDir : location of a reference directory
            cdna : location of a CDNA file with a '.cdna.' in the name
            basename : basename of files; typically species name
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        Handles creating a kallisto index without a class structure
    """
    indexCheck = os.path.join(referenceDir, 'KaliIndexBuilt')
    if not os.path.exists(indexCheck):
        localArgs = arguments['prepref/createKallistoIndex']
        logFile = os.path.join(referenceDir, 'KallistoRuntime.log')
        # Making Command
        #{{ time -p kallisto index -i {basename}.kali.cdna.fa.idx
        # {cdna}; }} >> {log} 2>&1"
        command = ("""{{ time -p {kallisto} index -i {-i} {other} {cdna};"""+
            """ }} >> {log} 2>&1""")
        Context = {
            "kallisto": checkMan("kallisto", localArgs['kallisto']),
            "-i": checkMan("{}.kali.cdna.fa.idx".format(basename),
                localArgs['-i']),
            "other": checkMan('', localArgs['other']),
            "cdna": checkMan(cdna, localArgs['cdna']),
            "log": logFile,
            }
        goodCommand = command.format(**Context)
        # Executing
        print('[ {} ] Building kallisto index...'.format(pipeClasses.now()))
        os.chdir(referenceDir)
        subprocess.run(goodCommand,
            shell=True,
            check=True,
            executable="/bin/bash")
        with open(indexCheck,'w') as F:
                F.write('True')
    else:
        print('Error: Cannot build Kallisto index; already exists')

def createBowtie2Index(referenceDir, genome, basename, arguments):
    """ Arguments:
            referenceDir : location of a reference directory
            genome : location of a DNA file with a '.dna.' in the name
            basename : basename of files; typically species name
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        Handles creating a bowtie2 index without a class structure
    """
    indexCheck = os.path.join(referenceDir, 'B2IndexBuilt')
    if not os.path.exists(indexCheck):
        localArgs = arguments['prepref/createBowtie2Index']
        logFile = os.path.join(referenceDir, 'Bowtie2Runtime.log')
        # Making Command
        command = ("""{{ time -p {bowtie2-build} --threads {--threads}"""+
            """ {other} {genome} {basename}; }} >> {log} 2>&1""")
        Context = {
            "bowtie2-build": checkMan("bowtie2-build", localArgs['bowtie2-build']),
            "--threads": checkMan(str(os.cpu_count()), localArgs['--threads']),
            "other": checkMan('', localArgs['other']),
            "genome": checkMan(genome, localArgs['genome']),
            "basename": checkMan(basename, localArgs['basename']),
            "log": logFile,
            }
        goodCommand = command.format(**Context)
        # Executing
        print('[ {} ] Building Bowtie2 index...'.format(pipeClasses.now()))
        os.chdir(referenceDir)
        subprocess.run(goodCommand,
            shell=True,
            check=True,
            executable="/bin/bash")
        with open(indexCheck,'w') as F:
                F.write('True')
    else:
        print('Error: Cannot build Bowtie2 index; already exists')

def clean(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        Handles runPipe clean command
    """
    # Handling Cleaning Arguments
    possibleCleanArguments = ['All','Reference','Data','Postprocessing']
    if arguments['--clean']:
        assert arguments['--clean'] in possibleCleanArguments, 'Invalid Cleaning Argument: Run runPipe.py -h for available arguments'
        PROJ = pipeClasses.Experiment(expandPath(arguments['<input>']))
        if arguments['--clean'] != 'All':
            if arguments['--clean'] == 'Data':
                if not os.path.isdir(PROJ.Data):
                    raise SystemExit('{} does not exist'.format(PROJ.Data))
            if arguments['--clean'] == 'Reference':
                if not os.path.isdir(PROJ.Reference):
                    raise SystemExit('{} does not exist'.format(PROJ.Reference))
            if arguments['--clean'] == 'Postprocessing':
                if not os.path.isdir(PROJ.Postprocessing):
                    raise SystemExit('{} does not exist'.format(PROJ.Postprocessing))
        if NOCONFIRM:
            PROJ.clean(arguments['--clean'])
            raise SystemExit
        else:
            while True:
                answer = input('Are you sure you wish to clean {}?(y/n) '.format(arguments['--clean']))
                if answer == 'y':
                    PROJ.clean(arguments['--clean'])
                    raise SystemExit
                elif answer == 'n':
                    raise SystemExit
                else:
                    print('Please answer y or n')
    elif arguments['--sampleclean']:
        PROJ = pipeClasses.Experiment(expandPath(arguments['<input>']))
        if not os.path.isdir(str(PROJ.Data + '/' + arguments['--sampleclean'])):
            raise SystemExit('{} does not exist'.format(str(PROJ.Data + '/' +
                                                        arguments['--sampleclean'])))
        if NOCONFIRM:
            PROJ.clean('Sample',arguments['--sampleclean'])
            raise SystemExit
        else:
            while True:
                answer = input('Are you sure you wish to clean {}?(y/n) '.format(arguments['--sampleclean']))
                if answer == 'y':
                    PROJ.clean('Sample',arguments['--sampleclean'])
                    raise SystemExit
                elif answer == 'n':
                    raise SystemExit
                else:
                    print('Please answer y or n')
        raise SystemExit
    else:
        if NOCONFIRM:
            PROJ.clean('All')
            raise SystemExit
        else:
            while True:
                answer = input('Are you sure you wish to clean All?(y/n) ')
                if answer == 'y':
                    PROJ.clean('All')
                    raise SystemExit
                elif answer == 'n':
                    raise SystemExit
                else:
                    print('Please answer y or n')

def makeBatch(ExperimentClass, arguments):
    ''' Arguments:
            ExperimentClass = class; experiment to run analysis on
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        If --makebatch argument given, then make batch script to be
        used with slurm, and then exit
    '''
    # Making slurm batch files if necessary
    if arguments['--batchjson']:
        testFile(expandPath(arguments['--batchjson']))
        pipeClasses.checkJSON(expandPath(arguments['--batchjson']))
    if arguments['--makebatch']:
        preNodes,Nodes = arguments['--makebatch'].split(','),[]
        for node in preNodes:
            if not node.isdigit() or int(node) <= 0:
                raise SystemExit('Not a valid argument to --makebatch: {}'.format(
                                        arguments['--makebatch']))
            Nodes.append(int(node))
        if arguments['<command>'] == 'string':
            ExperimentClass.makeStringtieBatch(cluster=Nodes,
                    jsonFile=expandPath(arguments['--batchjson']))
        elif arguments['<command>'] == 'kall':
            ExperimentClass.makeKallistoBatch(cluster=Nodes,
                    jsonFile=expandPath(arguments['--batchjson']))
        else:
            ExperimentClass.makeBatch(cluster=Nodes,
                    jsonFile=expandPath(arguments['--batchjson']))
        raise SystemExit('Batch file successfully created:\n\t{}/pipeBatch'.format(os.getcwd()))

def checkMaxCPU(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            int or None; the max number of CPU to use, if None
                         then there is no limit
        Checks --maxcpu option from CLI, if option not given
        then default is to use all available CPU
    """
    # Returning a maximum CPU value if given
    if arguments['--maxcpu']:
        if arguments['--maxcpu'].isdigit():
            Max = int(arguments['--maxcpu'])
            if Max <= os.cpu_count() and Max > 0:
                return Max
            else:
                raise SystemExit('--maxcpu greater than available CPUs')
        else:
            raise SystemExit('Invalid value to --maxcpu: {}'.format(
                        arguments['--maxcpu']))
    else:
        return None

def setGlobalLog(ExperimentClass):
    """ Arguments:
            ExperimentClass : Experiment; instance of a class
        Returns:
            None

        Creates a global variable, RUNTIMELOG, that specifies
        location of execution log
    """
    # Inititiating a Runtime Log global location
    global RUNTIMELOG
    RUNTIMELOG = str(os.path.join(ExperimentClass.Project,'Runtime.log'))
    pipeClasses.RUNTIMELOG = RUNTIMELOG

def checkdashr(ExperimentClass, arguments):
    """ Arguments:
            ExperimentClass : Experiment; instance of a class
            arguments : dictionary; CLI arguments from docopt
        Returns:
            samples : list; list of samples to execute

        Checks --runsample argument from CLI
    """
    # Running a specific sample
    if arguments['--runsample']:
        samples = arguments['--runsample'].split(',')
        possibleSamples = [str(a+1) for a in range(ExperimentClass.Numsamples)]
        runsampleUsage = ('Invalid argument to --runsample: {}'.format(arguments['--runsample']) +
                            'Possible arguments: {}'.format(str(possibleSamples)))
        if len(set(samples)) != len(samples):
            raise SystemExit(runsampleUsage)
        for sample in samples:
            if sample not in possibleSamples:
                raise SystemExit(runsampleUsage)
        return samples

def checkdashe(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            executionStages : list; list of stages to execute

        Checks --execute argument from CLI
    """
    # Determining what stages to run of Pipeline
    if arguments['--execute'] == 'A':
        executionStages = ["1","2","3","4","5"]
    else:
        executionStages = arguments['--execute'].split(',')
    possibleStages = ["1","2","3","4","5","A"]
    executeUsage = ('Invalid argument to --execute: {}'.format(
        arguments['--execute']) + 'Possible arguments: {}'.format(str(possibleStages)))
    if len(set(executionStages)) != len(executionStages):
        raise SystemExit(executeUsage)
    for stage in executionStages:
        if stage not in possibleStages:
            raise SystemExit(executeUsage)
    return executionStages

def checkdashp(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            executionPhases : list; list of phases to execute for
                              Stringtie

        Checks --phase argument from CLI for runPipe string command
    """
    # Handling string --phase
    possiblePhases = ['a','b','c','ab','bc','abc']
    stringtieUsage = ('Invalid argument to --phase: {}'.format(arguments['--phase']) +
                        'Possible arguments: {}'.format(str(possiblePhases)))
    if arguments['--phase'] not in possiblePhases:
        raise SystemExit(stringtieUsage)
    executionPhases = arguments['--phase']
    return executionPhases

def stage1ReadyToExecute(ExperimentClass):
    """ Arguments:
            ExperimentClass : Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    testFile(ExperimentClass.inputPath)
    return True

def stage2ReadyToExecute(ExperimentClass):
    """ Arguments:
            ExperimentClass : Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    projectPath = ExperimentClass.Project
    dataPath = ExperimentClass.Data
    refPath = ExperimentClass.Reference
    origPath = ExperimentClass.Original
    ppPath = ExperimentClass.Postprocessing
    for directory in [projectPath, dataPath, refPath, origPath, ppPath]:
        testDir(directory)
    for sample in glob.glob(os.path.join(dataPath,'sample_*')):
        if len(glob.glob(os.path.join(sample,'*'))) < 2:
            raise SystemExit('Symbolic links to Original data missing')
    for ref in [os.path.join(ExperimentClass.Reference, f) for f
            in [ExperimentClass.Gtf, ExperimentClass.Cdna, ExperimentClass.Genome]]:
        testFile(ref)
    return True

def stage3FCReadyToExecute(FCountsClass):
    """ Arguments:
            FCountsClass : featureCounts Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    if FCountsClass.isReferencePrepared():
        return True
    return False

def stage3STReadyToExecute(STClass):
    """ Arguments:
            STClass : Stringtie Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
            None
    """
    if STClass.isReferencePrepared():
        return True
    return False

def stage3KAReadyToExecute(KAClass):
    """ Arguments:
            KAClass : Kallisto Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    if KAClass.isReferencePrepared() and not KAClass.needToBuildKaliIndex():
        return True
    return False

def stage3BTReadyToExecute(BTClass):
    """ Arguments:
            BTClass : Bowtie Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    #TODO update this
    return True
    if BTClass.isReferencePrepared():
        return True
    return False

def stage4ReadyToExecute(ExperimentClass):
    """ Arguments:
            ExperimentClass : Experiment; instance of a class
        Returns:
            None
    """
    return ExperimentClass.is3Finished()

def stage5FCReadyToExecute(FCountsClass):
    """ Arguments:
            FCountsClass : featureCounts Experiment; instance of a class
        Returns:
            None
    """
    if (not os.path.exists(os.path.join(FCountsClass.Postprocessing, 'makeEdge.r')) or
        not os.path.exists(os.path.join(FCountsClass.Postprocessing, 'makeReport.r'))):
        return False
    return True

def stage5STReadyToExecute(STClass):
    """ Arguments:
            STClass : Stringtie Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    if not os.path.exists(os.path.join(STClass.Postprocessing, 'runBallgown.r')):
        return False
    return True

def stage5KAReadyToExecute(KAClass):
    """ Arguments:
            KAClass : Kallisto Experiment; instance of a class
        Returns:
            boolean : if stage is ready to execute
    """
    if not os.path.exists(os.path.join(KAClass.Postprocessing, 'runSleuth.r')):
        return False
    return True

def readInputFile(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            config : dict; arguments from input manifest

        Reads input manifest and stores into a dictionary
    """
    try:
        inputFile = expandPath(arguments['<input>'])
    except KeyError:
        try:
            # Mode is prepref -i
            inputFile = expandPath(arguments['-i'])
        except TypeError:
            # Mode is prepref -r
            inputFile = expandPath(arguments['tmpDefaults'])
    testFile(inputFile)
    config = configparser.ConfigParser(interpolation=configparser.ExtendedInterpolation(),
            dict_type=OD)
    config.optionxform = str
    config.BOOLEAN_STATES = {'True': True,
            'False': False,
            'true': True,
            'false': False,
            'None': False,
            'none': False}
    config.read(inputFile)
    return config

def updateArgs(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            updatedArgs : dict; containing necessary adjustments from manifest

        Combines command line arguments and manifest arguments
        Note: command line arguments take precedence i.e. if command line argument
        specified, use command line argument, else default to manifest
    """
    # Generate a fallback defaults file
    tmpDefaults = '.tmprunPipeDefaults.ini'
    generateDefaultInputFile({'--filename': tmpDefaults,'--mode': arguments['<command>']})
    FALLBACK = readInputFile({'<input>': tmpDefaults})
    mode = arguments['<command>']
    updatedArgs = {}
    arguments.update({'tmpDefaults': tmpDefaults})
    Manifest = readInputFile(arguments)
    try:
        manifestArgs = Manifest[mode]
    except KeyError:
        manifestArgs = FALLBACK[mode]
    # Add mode options i.e. options that can be specified on command line
    for option in arguments:
        if arguments[option] == False:
            updatedArgs[option] = manifestArgs.getboolean(option, fallback=FALLBACK[mode].getboolean(option))
        elif arguments[option] == None:
            if manifestArgs.get(option, fallback=FALLBACK[mode].get(option)) == 'None':
                updatedArgs[option] = None
            else:
                updatedArgs[option] = manifestArgs.get(option, fallback=FALLBACK[mode].get(option))
        else:
            updatedArgs[option] = arguments[option]
    # Add all other manifest options
    for section in FALLBACK.sections():
        if section != mode:
            updatedArgs[section] = {}
            for option in FALLBACK[section]:
                try:
                    if Manifest[section].get(option, fallback=FALLBACK[section].get(option)) == 'None':
                        updatedArgs[section][option] = None
                    elif Manifest[section].get(option, fallback=FALLBACK[section].get(option)) == 'False':
                        updatedArgs[section][option] = False
                    elif Manifest[section].get(option, fallback=FALLBACK[section].get(option)) == 'True':
                        updatedArgs[section][option] = True
                    else:
                        updatedArgs[section][option] = Manifest[section].get(option, fallback=FALLBACK[section].get(option))
                except:
                    if FALLBACK[section].get(option) == 'None':
                        updatedArgs[section][option] = None
                    elif FALLBACK[section].get(option) == 'False':
                        updatedArgs[section][option] = False
                    elif FALLBACK[section].get(option) == 'True':
                        updatedArgs[section][option] = True
                    else:
                        updatedArgs[section][option] = FALLBACK[section].get(option)
    # Remove tmp fallback defaults file
    os.remove(tmpDefaults)
    return updatedArgs

def generatePreprefInput(arguments):
    """ Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None
    """
    ############################################################
    # Setup
    ############################################################
    RNASEQDIR = os.path.expandvars('$RNASEQDIR')
    config = configparser.ConfigParser(
            interpolation=configparser.ExtendedInterpolation(),
            dict_type=OD)
    config.optionxform = str
    config.BOOLEAN_STATES = {
        'True': True,
        'False': False,
        'true': True,
        'false': False,
        'None': False,
        'none': False}
    pwd = os.path.abspath(os.curdir)
    ############################################################
    # Locations
    ############################################################
    config['locations'] = OD((
            ('Reference', pwd),
            ))
    ############################################################
    # Mode
    ############################################################
    config['mode'] = OD((
        ('prepref', 'True'),
        ))
    ############################################################
    # Main
    ############################################################
    config['prepref'] = OD((
        ('--qualitycheck', 'False'),
        ('--preprocess', 'False'),
        ('--kallisto', 'False'),
        ('--onlykallisto', 'False'),
        ('--bowtie2', 'False'),
        ('--onlybowtie2', 'False'),
        ('--maxcpu', 'None'),
        ))
    ############################################################
    # Executables
    ############################################################
    config['EXECUTABLES'] = OD((
            ('rnaseqdir', RNASEQDIR),
            ('kallisto', '${rnaseqdir}/kallisto'),
            ('makeblastdb', '${rnaseqdir}/ncbi-blast/bin/makeblastdb'),
            ('extract_splice_sites.py', '${rnaseqdir}/hisat2/extract_splice_sites.py'),
            ('extract_exons.py', '${rnaseqdir}/hisat2/extract_exons.py'),
            ('hisat2-build', '${rnaseqdir}/hisat2/hisat2-build'),
            ('samtools', '${rnaseqdir}/samtools/bin/samtools'),
            ('bowtie2-build', '${rnaseqdir}/bowtie2'),
            ))
    ############################################################
    # PREPREF
    ############################################################
    config['prepref/main'] = OD((
            ('qcRef', 'True'),
            ('createKallistoIndex', 'True'),
            ('createBowtie2Index', 'True'),
            ('makeBlastdb', 'True'),
            ('extractSpliceSites', 'True'),
            ('extractExons', 'True'),
            ('hisatBuild', 'True'),
            ('samtoolsFaidx', 'True'),
            ))
    # prepref/main/createKallistoIndex
    # kallisto index -i {basename}.kali.cdna.fa.idx {other} {cdna}
    config['prepref/createKallistoIndex'] = OD((
        ('kallisto', '${EXECUTABLES:kallisto}'),
        ('-i', 'None'),
        ('other', 'None'),
        ('cdna', 'None'),
        ))
    # prepref/main/createBowtie2Index
    # bowtie2-build {other} {genome} {basename}
    config['prepref/createBowtie2Index'] = OD((
        ('bowtie2-build', '${EXECUTABLES:bowtie2-build}'),
        ('--threads', 'None'),
        ('other', 'None'),
        ('genome', 'None'),
        ('basename', 'None'),
        ))
    # prepref/main/makeBlastdb
    # makeblastdb -in {cdna} -dbtype nucl {other} -out {basename}.cdna.all
    config['prepref/makeBlastdb'] = OD((
        ('makeblastdb', '${EXECUTABLES:makeblastdb}'),
        ('-in', 'None'),
        ('-dbtype', 'None'),
        ('other', 'None'),
        ('-out', 'None'),
        ))
    # prepref/main/extractSpliceSites
    # extract_splice_sites.py {other} {gtf} > splice_sites.txt
    config['prepref/extractSpliceSites'] = OD((
        ('extract_splice_sites.py', '${EXECUTABLES:extract_splice_sites.py}'),
        ('other', 'None'),
        ('gtf', 'None'),
        ('out', 'None'),
        ))
    # prepref/main/extractExons
    # extract_exons.py {other} {gtf} > known_exons.txt
    config['prepref/extractExons'] = OD((
        ('extract_exons.py', '${EXECUTABLES:extract_exons.py}'),
        ('other', 'None'),
        ('gtf', 'None'),
        ('out', 'None'),
        ))
    # prepref/main/hisatBuild
    # hisat2-build -p {cpu} --ss splice_sites.txt
    # --exon known_exons.txt {other} {genome} {basename}
    config['prepref/hisatBuild'] = OD((
        ('hisat2-build', '${EXECUTABLES:hisat2-build}'),
        ('-p', 'None'),
        ('--ss', 'None'),
        ('--exon', 'None'),
        ('other', 'None'),
        ('genome', 'None'),
        ('basename', 'None'),
        ))
    # prepref/main/samtoolsFaidx
    # samtools faidx {genome} {other}
    config['prepref/samtoolsFaidx'] = OD((
        ('samtools', '${EXECUTABLES:samtools}'),
        ('genome', 'None'),
        ('other', 'None'),
        ))
    ############################################################
    with open(arguments['--filename'], 'w') as configfile:
        config.write(configfile)
    ############################################################

################################################################
# Usage Functions
################################################################

def featureCounts(arguments):
    '''Usage:
    runPipe fcounts [options] <input>

Options:
    -h, --help
        Show this screen and exit
    -e <stage>, --execute <stage>
        Comma-separated list of stages to be executed.
        Possible stages include:
            1: Creating Project Structure
            2: Preparing Reference Data
            3: Running actual Pipeline
            4: Preparing for R analysis
            5: Running R analysis
            A: (1,2,3,4,5); A=all i.e. runs entire pipeline
    -r <integer>, --runsample <integer>
        Runs Stage 3 of the pipeline on the sample specified
        by the integer
    -j <jsonFile>, --jsonfile <jsonFile>
        Ignores JSON Metadata file creation and uses specified
        path to JSON Metadata
    --maxcpu <CPUs>
        Limits number of CPUs used by Pipeline. Default is to
        use all available CPUs
    --makebatch <cluster>
        Makes batch file to be used with slurm. The argument
        it takes is a comma-separated list of CPUs on each
        node in your cluster
    --batchjson <pathtoJSON>
        Uses json file already created to make batch file
    --edger
        Runs edgeR analysis only. Default is to run both
    --deseq
        Runs DESeq2 analysis only. Default is to run both
    --noconfirm
        Ignore all user prompts except JSON file creation
    --use-blacklist <blacklist>
        Trimmomatic blacklist used for quality control
    --use-reference
        Use Reference data that has already been prepared.
        Put path to already prepared reference data in
        INPUT file
        Note: Need to run Stage 1 with this argument or add to
        "--makebatch" argument'''
    makeGlobalVars(arguments)
    cpuLimit = checkMaxCPU(arguments)
    testFile(expandPath(arguments['<input>']))
    testFile(expandPath(arguments['--use-blacklist']))
    FCClass = pipeClasses.FCountsExperiment(arguments)
    # Make batch file if necessary
    makeBatch(FCClass, arguments)
    setGlobalLog(FCClass)
    samplesToExecute = checkdashr(FCClass, arguments)
    stagesToExecute = checkdashe(arguments)
    # Run Stage 1 if necessary
    if '1' in stagesToExecute and stage1ReadyToExecute(FCClass):
        FCClass.runStage1()
    # Run Stage 2 if necessary
    if '2' in stagesToExecute and stage2ReadyToExecute(FCClass):
        FCClass.runStage2()
    # Run Stage 3 if necessary
    if '3' in stagesToExecute and stage3FCReadyToExecute(FCClass):
        if samplesToExecute == None:
            FCClass.runStage3()
        else:
            for sample in samplesToExecute:
                FCClass.executeSample(sample)
    # Run Stage 4 if necessary
    if '4' in stagesToExecute and stage4ReadyToExecute(FCClass):
        FCClass.runStage4()
    # Run Stage 5 if necessary
    if '5' in stagesToExecute and stage5FCReadyToExecute(FCClass):
        if arguments['--edger'] or arguments['--deseq']:
            if arguments['--edger']:
                FCClass.runEdgeR()
            if arguments['--deseq']:
                FCClass.runDESeq()
        else:
            FCClass.runStage5()

def stringtie(arguments):
    '''Usage:
    runPipe string [options] <input>

Options:
    -h, --help
        Show this screen and exit
    -e <stage>, --execute <stage>
        Comma-separated list of stages to be executed.
        Possible stages include:
            1: Creating Project Structure
            2: Preparing Reference Data
            3: Running actual Pipeline
            4: Preparing for R analysis
            5: Running R analysis
            A: (1,2,3,4,5); A=all i.e. runs entire pipeline
    -r <integer>, --runsample <integer>
        Runs Stage 3 of the pipeline on the sample specified
        by the integer
    -p <phase>, --phase <phase>
        Use stringtie tools to replace featureCounts. phase can
        be any of: "a","b","c","ab","bc","abc"
        Option also used to specify stringtie postprocessing
        options in which case use: "--execute 4 --stringtie abc"
        Note: If you will be running phase b, you cannot specify
        a sample to run with --runsample
    -j <jsonFile>, --jsonfile <jsonFile>
        Ignores JSON Metadata file creation and uses specified
        path to JSON Metadata
    --maxcpu <CPUs>
        Limits number of CPUs used by Pipeline. Default is to
        use all available CPUs
    --noconfirm
        Ignore all user prompts except JSON file creation
    --use-blacklist <blacklist>
        Trimmomatic blacklist used for quality control
    --use-reference
        Use Reference data that has already been prepared.
        Put path to already prepared reference data in
        INPUT file
        Note: Need to run Stage 1 with this argument or add to
        "--makebatch" argument
    --makebatch <cluster>
        Makes batch file to be used with slurm. The argument
        it takes is a comma-separated list of CPUs on each
        node in your cluster
    --batchjson <pathtoJSON>
        Uses json file already created to make batch file'''
    makeGlobalVars(arguments)
    cpuLimit = checkMaxCPU(arguments)
    testFile(expandPath(arguments['<input>']))
    testFile(expandPath(arguments['--use-blacklist']))
    StringtieClass = pipeClasses.StringtieExperiment(arguments)
    # Make batch file if necessary
    makeBatch(StringtieClass, arguments)
    setGlobalLog(StringtieClass)
    samplesToExecute = checkdashr(StringtieClass, arguments)
    stagesToExecute = checkdashe(arguments)
    phasesToExecute = checkdashp(arguments)
    # Run Stage 1 if necessary
    if '1' in stagesToExecute and stage1ReadyToExecute(StringtieClass):
        StringtieClass.runStage1()
    # Run Stage 2 if necessary
    if '2' in stagesToExecute and stage2ReadyToExecute(StringtieClass):
        StringtieClass.runStage2()
    # Run Stage 3 if necessary
    if '3' in stagesToExecute and stage3STReadyToExecute(StringtieClass):
        if samplesToExecute == None:
            StringtieClass.runStage3(phasesToExecute)
        else:
            for sample in samplesToExecute:
                StringtieClass.executeSample(sample, phasesToExecute)
    # Run Stage 4 if necessary
    if '4' in stagesToExecute and stage4ReadyToExecute(StringtieClass):
        StringtieClass.runStage4()
    # Run Stage 5 if necessary
    if '5' in stagesToExecute and stage5STReadyToExecute(StringtieClass):
        StringtieClass.runStage5()

def kallisto(arguments):
    '''Usage:
    runPipe kall [options] <input>

Options:
    -h, --help
        Show this screen and exit
    -e <stage>, --execute <stage>
        Comma-separated list of stages to be executed.
        Possible stages include:
            1: Creating Project Structure
            2: Preparing Reference Data
            3: Running actual Pipeline
            4: Preparing for R analysis
            5: Running R analysis
            A: (1,2,3,4,5); A=all i.e. runs entire pipeline
    -r <integer>, --runsample <integer>
        Runs Stage 3 of the pipeline on the sample specified
        by the integer
    -j <jsonFile>, --jsonfile <jsonFile>
        Ignores JSON Metadata file creation and uses specified
        path to JSON Metadata
    --maxcpu <CPUs>
        Limits number of CPUs used by Pipeline. Default is to
        use all available CPUs
    --noconfirm
        Ignore all user prompts except JSON file creation
    --use-blacklist <blacklist>
        Trimmomatic blacklist used for quality control
    --use-reference
        Use Reference data that has already been prepared.
        Put path to already prepared reference data in
        INPUT file
        Note: Need to run Stage 1 with this argument or add to
        "--makebatch" argument
    --makebatch <cluster>
        Makes batch file to be used with slurm. The argument
        it takes is a comma-separated list of CPUs on each
        node in your cluster
    --batchjson <pathtoJSON>
        Uses json file already created to make batch file'''
    makeGlobalVars(arguments)
    cpuLimit = checkMaxCPU(arguments)
    testFile(expandPath(arguments['<input>']))
    testFile(expandPath(arguments['--use-blacklist']))
    KallistoClass = pipeClasses.KallistoExperiment(arguments)
    # Make batch file if necessary
    makeBatch(KallistoClass, arguments)
    setGlobalLog(KallistoClass)
    samplesToExecute = checkdashr(KallistoClass, arguments)
    stagesToExecute = checkdashe(arguments)
    # Run Stage 1 if necessary
    if '1' in stagesToExecute and stage1ReadyToExecute(KallistoClass):
        KallistoClass.runStage1()
    # Run Stage 2 if necessary
    if '2' in stagesToExecute and stage2ReadyToExecute(KallistoClass):
        KallistoClass.runStage2()
    # Run Stage 3 if necessary
    if '3' in stagesToExecute and stage3KAReadyToExecute(KallistoClass):
        if samplesToExecute == None:
            KallistoClass.runStage3()
        else:
            for sample in samplesToExecute:
                KallistoClass.executeSample(sample)
    # Run Stage 4 if necessary
    if '4' in stagesToExecute and stage4ReadyToExecute(KallistoClass):
        KallistoClass.runStage4()
    # Run Stage 5 if necessary
    if '5' in stagesToExecute and stage5KAReadyToExecute(KallistoClass):
        KallistoClass.runStage5()

def bowtie2(arguments):
    '''Usage:
    runPipe bowtie2 [options] <input>

Options:
    -h, --help
        Show this screen and exit
    -e <stage>, --execute <stage>
        Comma-separated list of stages to be executed.
        Possible stages include:
            1: Creating Project Structure
            2: Preparing Reference Data
            3: Running actual Pipeline
            4: Post-processing
            A: (1,2,3,4); A=all i.e. runs entire pipeline
    -r <integer>, --runsample <integer>
        Runs Stage 3 of the pipeline on the sample specified
        by the integer
    -j <jsonFile>, --jsonfile <jsonFile>
        Ignores JSON Metadata file creation and uses specified
        path to JSON Metadata
    --maxcpu <CPUs>
        Limits number of CPUs used by Pipeline. Default is to
        use all available CPUs
    --noconfirm
        Ignore all user prompts except JSON file creation
    --use-blacklist <blacklist>
        Trimmomatic blacklist used for quality control
    --use-reference
        Use Reference data that has already been prepared.
        Put path to already prepared reference data in
        INPUT file
        Note: Need to run Stage 1 with this argument or add to
        "--makebatch" argument
    --makebatch <cluster>
        Makes batch file to be used with slurm. The argument
        it takes is a comma-separated list of CPUs on each
        node in your cluster
    --batchjson <pathtoJSON>
        Uses json file already created to make batch file'''
    makeGlobalVars(arguments)
    cpuLimit = checkMaxCPU(arguments)
    testFile(expandPath(arguments['<input>']))
    testFile(expandPath(arguments['--use-blacklist']))
    Bowtie2Class = pipeClasses.Bowtie2Experiment(arguments)
    makeBatch(Bowtie2Class, arguments)
    setGlobalLog(Bowtie2Class)
    samplesToExecute = checkdashr(Bowtie2Class, arguments)
    stagesToExecute = checkdashe(arguments)
    # Run Stage 1 if necessary
    if '1' in stagesToExecute and stage1ReadyToExecute(Bowtie2Class):
        Bowtie2Class.runStage1()
    # Run Stage 2 if necessary
    if '2' in stagesToExecute and stage2ReadyToExecute(Bowtie2Class):
        Bowtie2Class.runStage2()
    # Run Stage 3 if necessary
    if '3' in stagesToExecute and stage3BTReadyToExecute(Bowtie2Class):
        if samplesToExecute == None:
            Bowtie2Class.runStage3()
        else:
            for sample in samplesToExecute:
                Bowtie2Class.executeSample(sample)
    # Run Stage 4 if necessary
    if '4' in stagesToExecute and stage4ReadyToExecute(Bowtie2Class):
        Bowtie2Class.runStage4()

def cleanup(arguments):
    '''Usage:
    runPipe clean [options] <input>

Options:
    -h, --help
        Show this screen and exit
    -c <placeToClean>, --clean <placeToClean>
        Cleans <placeToClean>; Possible places include:
            Reference
            Data
            Postprocessing
            All
    --sampleclean <sampleName>
        Similar to --clean; but instead just cleans a
        single sample directory, <sampleName>'''
    makeGlobalVars(arguments)
    testFile(expandPath(arguments['<input>']))
    clean(arguments)

def referenceProcessing(arguments):
    '''Usage:
    runPipe prepref [options] (-r <referenceDir> | -i <input>)

Options:
    -h, --help
        Show this screen and exit
    -r <referenceDir>
        One of the mandatory arguments i.e. must specify either
        r OR i options.
        Option value is a path to directory that contains a GTF,
        cDNA, and reference genome
    -i <input>
        One of the mandatory arguments i.e. must specify either
        r OR i options
        Option value is a path to input file that must contain
        at least a path to reference directory
        Note: a default input file can be generated with:
            runPipe gendef --mode prepref
    -q, --qualitycheck
        Only run quality check on references. Default behavior
        is to run both quality control and preprocessing
    -p, --preprocess
        Only run preprocessing on references. Default behavior
        is to run both quality control and preprocessing
    -k, --kallisto
        Additionally build kallisto index
        Note: index required if kallisto pipeline to be used
    --onlykallisto
        Build only the kallisto index
    -b, --bowtie2
        Additionally build Bowtie2 index
        Note: index required if Bowtie2 pipeline to be used
    --onlybowtie2
        Build only the Bowtie2 index
    --maxcpu <CPUs>
        Limit the number of CPU that get used to preprocess
        reference data.
        Note: default is to use all available'''
    cpuLimit = checkMaxCPU(arguments)
    if arguments['-r']:
        referencePath = expandPath(arguments['-r'])
    else:
        referencePath = expandPath(arguments['locations']['Reference'])
    if not os.path.isdir(referencePath):
        raise SystemExit('Reference directory does not exist: {}'.format(referencePath))
    Init = os.path.join(referencePath,'.init')
    if not os.path.exists(Init):
        Gtf,Cdna,Genome = pipeClasses.getReferenceVariables(referencePath)
        with open(Init,'w') as f:
            f.write('\n'.join([Gtf,Cdna,Genome]))
    else:
        with open(Init,'r') as f:
            Stuff = f.readlines()
        Gtf = Stuff[0].rstrip('\n')
        Cdna = Stuff[1].rstrip('\n')
        Genome = Stuff[2].rstrip('\n')
    Basename = str(Genome.split(".")[0])
    if arguments['--onlykallisto']:
        createKallistoIndex(referencePath, Cdna, Basename, arguments)
        print('[ {} ] Completed Kallisto index; exiting...'.format(pipeClasses.now()))
        return None
    if arguments['--onlybowtie2']:
        createBowtie2Index(referencePath, Genome, Basename, arguments)
        print('[ {} ] Completed Bowtie2 index; exiting...'.format(pipeClasses.now()))
        return None
    if arguments['--qualitycheck'] and not arguments['--preprocess']: # only q
        if arguments['prepref/main']['qcRef']:
            qcRef(referencePath,Genome)
        else:
            print('qcRef skipped due to manifest\n')
    elif not arguments['--qualitycheck'] and arguments['--preprocess']: # only p
        ppRef(referencePath, Cdna, Basename, Gtf, Genome, cpuLimit, arguments)
    else: #both
        if arguments['prepref/main']['qcRef']:
            qcRef(referencePath,Genome)
        else:
            print('qcRef skipped due to manifest\n')
        ppRef(referencePath, Cdna, Basename, Gtf, Genome, cpuLimit, arguments)
    if arguments['--kallisto']:
        createKallistoIndex(referencePath, Cdna, Basename, arguments)
    if arguments['--bowtie2']:
        createBowtie2Index(referencePath, Genome, Basename, arguments)

def generateDefaultInputFile(arguments):
    '''Usage:
    runPipe gendef [options]

Options:
    -h, --help
        Show this screen and exit
    -f <filename>, --filename <filename>
        Name of input file to create
        [default: default_input.ini]
    -m <mode>, --mode <mode>
        Type of execution mode, can be:
            fcounts
            string
            kall
            bowtie2
            prepref
        [default: fcounts]

Note: Any options given on command-line will override those in
input file'''
    ############################################################
    # If mode is gendef; create different config file
    ############################################################
    if arguments['--mode'] == 'prepref':
        generatePreprefInput(arguments)
        return None
    ############################################################
    # Set-Up Config
    ############################################################
    config = configparser.ConfigParser(
            interpolation=configparser.ExtendedInterpolation(),
            dict_type=OD)
    config.optionxform = str
    config.BOOLEAN_STATES = {'True': True,
            'False': False,
            'true': True,
            'false': False,
            'None': False,
            'none': False}
    # LOCATIONS
    pwd = os.path.abspath(os.curdir)
    config['locations'] = OD((
            ('Project', pwd),
            ('Reference', pwd),
            ('Original', pwd),
            ))
    # MODE
    if arguments['--mode'] not in ['fcounts', 'string', 'kall', 'bowtie2']:
        raise SystemExit('--mode argument is not valid: {}'.format(arguments['--mode']))
    config['mode'] = OD((
            ('fcounts', 'True' if arguments['--mode'] == 'fcounts' else 'False'),
            ('kall', 'True' if arguments['--mode'] == 'kall' else 'False'),
            ('string', 'True' if arguments['--mode'] == 'string' else 'False'),
            ('bowtie2', 'True' if arguments['--mode'] == 'bowtie2' else 'False'),
            ))
    RNASEQDIR = os.path.expandvars('$RNASEQDIR')

    ############################################################
    # CLI-mutable args
    ############################################################
    if arguments['--mode'] == 'fcounts':
        config['fcounts'] = OD((
                ('--execute', 'A'),
                ('--runsample', 'None'),
                ('--jsonfile', 'None'),
                ('--maxcpu', 'None'),
                ('--noconfirm', 'False'),
                ('--makebatch', 'None'),
                ('--batchjson', 'None'),
                ('--edger', 'False'),
                ('--deseq', 'False'),
                ('--use-blacklist', RNASEQDIR+'/Trimmomatic/adapters/TruSeq3-PE.fa'),
                ('--use-reference', 'False'),
                ))
    elif arguments['--mode'] == 'string':
        config['string'] = OD((
                ('--execute', 'A'),
                ('--runsample', 'None'),
                ('--phase', 'abc'),
                ('--jsonfile', 'None'),
                ('--maxcpu', 'None'),
                ('--noconfirm', 'False'),
                ('--use-blacklist', RNASEQDIR+'/Trimmomatic/adapters/TruSeq3-PE.fa'),
                ('--use-reference', 'False'),
                ('--makebatch', 'None'),
                ('--batchjson', 'None'),
                ))
    elif arguments['--mode'] == 'kall':
        config['kall'] = OD((
                ('--execute', 'A'),
                ('--runsample', 'None'),
                ('--jsonfile', 'None'),
                ('--maxcpu', 'None'),
                ('--noconfirm', 'False'),
                ('--use-blacklist', RNASEQDIR+'/Trimmomatic/adapters/TruSeq3-PE.fa'),
                ('--use-reference', 'False'),
                ('--makebatch', 'None'),
                ('--batchjson', 'None'),
                ))
    elif arguments['--mode'] == 'bowtie2':
        config['bowtie2'] = OD((
                ('--execute', 'A'),
                ('--runsample', 'None'),
                ('--jsonfile', 'None'),
                ('--maxcpu', 'None'),
                ('--noconfirm', 'False'),
                ('--makebatch', 'None'),
                ('--batchjson', 'None'),
                ('--use-blacklist', RNASEQDIR+'/Trimmomatic/adapters/TruSeq3-PE.fa'),
                ('--use-reference', 'False'),
                ))

    ############################################################
    # Executables
    ############################################################
    config['EXECUTABLES'] = OD((
            ('Rscript', '/usr/local/bin/Rscript'),
            ('java', '/usr/bin/java'),
            ('rnaseqdir', RNASEQDIR),
            ('fastqc', '${rnaseqdir}/fastqc'),
            ('extract_exons.py', '${rnaseqdir}/hisat2/extract_exons.py'),
            ('extract_splice_sites.py', '${rnaseqdir}/hisat2/extract_splice_sites.py'),
            ('hisat2', '${rnaseqdir}/hisat2/hisat2'),
            ('hisat2-build', '${rnaseqdir}/hisat2/hisat2-build'),
            ('samtools', '${rnaseqdir}/samtools/bin/samtools'),
            ('makeblastdb', '${rnaseqdir}/ncbi-blast/bin/makeblastdb'),
            ('blastn', '${rnaseqdir}/ncbi-blast/bin/blastn'),
            ('seqtk', '${rnaseqdir}/seqtk'),
            ('gffcompare', '${rnaseqdir}/gffcompare'),
            ('stranded_classifier.py', '${rnaseqdir}/stranded_classifier.py'),
            ('featureCounts', '${rnaseqdir}/subread/bin/featureCounts'),
            ('stringtie', '${rnaseqdir}/stringtie'),
            ('kallisto', '${rnaseqdir}/kallisto'),
            ('bowtie2', '${rnaseqdir}/bowtie2'),
            ('bowtie2-build', '${rnaseqdir}/bowtie2-build'),
            ))

    ############################################################
    # FCOUNTS
    ############################################################
    if arguments['--mode'] == 'fcounts':
        config['fcounts/main'] = OD((
                ('runQCheck', 'True'),
                ('runTrimmomatic', 'True'),
                ('runSeqtk', 'True'),
                ('runBlastn', 'True'),
                ('runHisat', 'True'),
                ('runCompression', 'True'),
                ('runFeatureCounts', 'True'),
                ('getNiceColumns', 'True'),
                ('getAlignedColumn', 'True'),
                ))
        # fcounts/main/runHisat
        # hisat2 -k 5 -p {numProcs}{FRoRF} --dta --phred{phred} {other}\
        #       --known-splicesite-infile {ref}/splice_sites.txt -x {ref}/{basename} \
        #       -1 read1.P.trim.{fastq}.gz -2 read2.P.trim.{fastq}.gz -S aligned.{sample}.sam
        config['fcounts/runHisat'] = OD((
                ('hisat2', '${EXECUTABLES:hisat2}'),
                ('-k', 'None'),
                ('-p', 'None'),
                ('--rna-strandedness', 'None'),
                ('--dta', 'None'),
                ('--phred', 'None'),
                ('--known-splicesite-infile', 'None'),
                ('-x', 'None'),
                ('-1', 'None'),
                ('-2', 'None'),
                ('-S', 'None'),
                ('other', 'None'),
                ))
        # fcounts/main/runCompression
        # samtools view -bT {ref}/{genome} -@{procs} {other} aligned.{sample}.sam -o aligned.{sample}.bam
        config['fcounts/runCompression'] = OD((
                ('samtools', '${EXECUTABLES:samtools}'),
                ('-b', 'None'),
                ('-T', 'None'),
                ('-@', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))
        # fcounts/main/runFeatureCounts
        # featureCounts -T {procs} -s {stranded} -p -C --primary --ignoreDup --largestOverlap -t exon -g gene_id \
        #       -a {ref}/{gtf} -o aligned.{sample}.counts {other} aligned.{sample}.bam
        config['fcounts/runFeatureCounts'] = OD((
                ('featureCounts', '${EXECUTABLES:featureCounts}'),
                ('-T', 'None'),
                ('-s', 'None'),
                ('-p', 'None'),
                ('-C', 'None'),
                ('--primary', 'None'),
                ('--ignoreDup', 'None'),
                ('--largestOverlap', 'None'),
                ('-t', 'None'),
                ('-g', 'None'),
                ('-a', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))

    ############################################################
    # STRING
    ############################################################
    elif arguments['--mode'] == 'string':
        config['string/main'] = OD((
                ('runQCheck', 'True'),
                ('runTrimmomatic', 'True'),
                ('runSeqtk', 'True'),
                ('runBlastn', 'True'),
                ('runHisat', 'True'),
                ('runAltCompression', 'True'),
                ('assembleTranscripts', 'True'),
                ('stringtieMerge', 'True'),
                ('compareTranscripts', 'True'),
                ('estimateTranscriptAbundances', 'True'),
                ))
        # string/main/runHisat
        # hisat2 -k 5 -p {numProcs}{FRoRF} --dta --phred{phred} {other}\
        #       --known-splicesite-infile {ref}/splice_sites.txt -x {ref}/{basename} \
        #       -1 read1.P.trim.{fastq}.gz -2 read2.P.trim.{fastq}.gz -S aligned.{sample}.sam
        config['string/runHisat'] = OD((
                ('hisat2', '${EXECUTABLES:hisat2}'),
                ('-k', 'None'),
                ('-p', 'None'),
                ('--rna-strandedness', 'None'),
                ('--dta', 'None'),
                ('--phred', 'None'),
                ('--known-splicesite-infile', 'None'),
                ('-x', 'None'),
                ('-1', 'None'),
                ('-2', 'None'),
                ('-S', 'None'),
                ('other', 'None'),
                ))
        # string/main/runAltCompression
        # samtools sort -@ {procs} -o aligned.{sample}.bam {other} aligned.{sample}.sam
        config['string/runAltCompression'] = OD((
                ('samtools', '${EXECUTABLES:samtools}'),
                ('-@', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))
        # string/main/assembleTranscripts
        # stringtie -p {procs} -o {sample}.st.gtf -l {sample} {other} aligned.{sample}.bam
        config['string/assembleTranscripts'] = OD((
                ('stringtie', '${EXECUTABLES:stringtie}'),
                ('-p', 'None'),
                ('-o', 'None'),
                ('-l', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))
        # string/main/stringtieMerge
        # stringtie --merge -p {procs} -o {mergedir}/{projectname}.stmerged.gtf {other} {mergelist}
        config['string/stringtieMerge'] = OD((
                ('stringtie', '${EXECUTABLES:stringtie}'),
                ('-p', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))
        # string/main/compareTranscripts
        # gffcompare -r {ref}/{gtf} -G -o {projectname}.merged {other} {stmerged}
        config['string/compareTranscripts'] = OD((
                ('gffcompare', '${EXECUTABLES:gffcompare}'),
                ('-r', 'None'),
                ('-G', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))
        # string/main/estimateTranscriptAbundances
        # stringtie -e -B -p {procs} -G {stmerged} -o {sample}.good.st.gtf {other} aligned.{sample}.bam
        config['string/estimateTranscriptAbundances'] = OD((
                ('stringtie', '${EXECUTABLES:stringtie}'),
                ('-e', 'None'),
                ('-B', 'None'),
                ('-p', 'None'),
                ('-G', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))

    ############################################################
    # KALL
    ############################################################
    elif arguments['--mode'] == 'kall':
        config['kall/main'] = OD((
                ('runQCheck', 'True'),
                ('runTrimmomatic', 'True'),
                ('runSeqtk', 'True'),
                ('runBlastn', 'True'),
                ('runKallisto', 'True'),
                ))
        # kall/main/runKallisto
        # kallisto quant -i {transcriptindex} -o {outputdir} --threads {procs}{FRoRF} -b 100 \
        #       <( zcat read1.P.trim.{fastq}.gz ) <( zcat read2.P.trim.{fastq}.gz )
        config['kall/runKallisto'] = OD((
                ('kallisto', '${EXECUTABLES:kallisto}'),
                ('-i', 'None'),
                ('-o', 'None'),
                ('--threads', 'None'),
                ('stranded', 'None'),
                ('-b', 'None'),
                ('read1', 'None'),
                ('read2', 'None'),
                ('other', 'None'),
                ))

    ############################################################
    # Bowtie2
    ############################################################
    elif arguments['--mode'] == 'bowtie2':
        config['bowtie2/main'] = OD((
                ('runQCheck', 'True'),
                ('runTrimmomatic', 'True'),
                ('runSeqtk', 'True'),
                ('runBlastn', 'True'),
                ('runBowtie2', 'True'),
                ('runCompression', 'True'),
                ))
        # bowtie2/main/runBowtie2
        # bowtie2 [options]
        config['bowtie2/runBowtie2'] = OD((
                ('bowtie2', '${EXECUTABLES:bowtie2}'),
                ("--very-sensitive-local", 'None'),
                ("-k", '5'),
                ("-p", 'None'),
                ("--rna-strandedness", 'None'),
                ("--phred", 'None'),
                ("other", 'None'),
                ("-x", 'None'),
                ("-1", 'None'),
                ("-2", 'None'), 
                ("-S", 'None'), 
                ))
        # bowtie2/main/runCompression
        # samtools view -bT {ref}/{genome} -@{procs} {other} aligned.{sample}.sam -o aligned.{sample}.bam
        config['bowtie2/runCompression'] = OD((
                ('samtools', '${EXECUTABLES:samtools}'),
                ('-b', 'None'),
                ('-T', 'None'),
                ('-@', 'None'),
                ('-o', 'None'),
                ('in', 'None'),
                ('other', 'None'),
                ))

    ############################################################
    # General Utilities
    ############################################################
    # runQCheck
    # fastqc -t {procs} -o {fastqfolder} {other} {read1} {read2}
    config['runQCheck'] = OD((
            ('fastqc', '${EXECUTABLES:fastqc}'),
            ('-t', 'None'),
            ('-o', 'None'),
            ('read1', 'None'),
            ('read2', 'None'),
            ('other', 'None'),
            ))
    # runTrimmomatic
    # java -jar $RNASEQDIR/Trimmomatic/trimmomatic-0.36.jar PE -threads {procs} -phred{phred} {other}\
    #       {Read1} {Read2} \
    #       read1.P.trim.{fastq}.gz read1.U.trim.{fastq}.gz \
    #       read2.P.trim.{fastq}.gz read2.U.trim.{fastq}.gz \
    #       ILLUMINACLIP:{blacklist}:2:30:10 LEADING:5 TRAILING:5 SLIDINGWINDOW:4:5 MINLEN:35
    config['runTrimmomatic'] = OD((
            ('java', '${EXECUTABLES:java}'),
            ('-jar', 'None'),
            ('-threads', 'None'),
            ('-phred', 'None'),
            ('read1', 'None'),
            ('read2', 'None'),
            ('read1pout', 'None'),
            ('read2pout', 'None'),
            ('read1uout', 'None'),
            ('read2uout', 'None'),
            ('blacklist', 'None'),
            ('ILLUMINACLIP', 'None'),
            ('LEADING', 'None'),
            ('TRAILING', 'None'),
            ('SLIDINGWINDOW', 'None'),
            ('MINLEN', 'None'),
            ('other', 'None'),
            ))
    # runSeqtk
    # seqtk sample -s100 read1.P.trim.{0}.gz 10000 | seqtk seq -A {other} - > sampled.read1.fa
    # seqtk sample -s100 read2.P.trim.{0}.gz 10000 | seqtk seq -A {other} - > sampled.read2.fa
    config['runSeqtk'] = OD((
            ('seqtk', '${EXECUTABLES:seqtk}'),
            ('-s', 'None'),
            ('read1', 'None'),
            ('read2', 'None'),
            ('read1out', 'None'),
            ('read2out', 'None'),
            ('samples', 'None'),
            ('-A', 'None'),
            ('other', 'None'),
            ))
    # runBlastn
    # blastn -query sampled.read1.fa -db {0} -out sampled.read1_vscdna.out -task blastn-short \
    #       -outfmt "6 std sstrand" -max_target_seqs 1 -num_threads {1} {other}
    # blastn -query sampled.read2.fa -db {0} -out sampled.read2_vscdna.out -task blastn-short \
    #       -outfmt "6 std sstrand" -max_target_seqs 1 -num_threads {1} {other}
    config['runBlastn'] = OD((
            ('blastn', '${EXECUTABLES:blastn}'),
            ('read1', 'None'),
            ('read2', 'None'),
            ('out1', 'None'),
            ('out2', 'None'),
            ('-db', 'None'),
            ('-task', 'None'),
            ('-outfmt', 'None'),
            ('-max_target_seqs', 'None'),
            ('-num_threads', 'None'),
            ('other', 'None'),
            ))

    ############################################################
    with open(arguments['--filename'], 'w') as configfile:
        config.write(configfile)
    ############################################################

def otherStuff(arguments):
    ''' Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        Handles what happens when a sub-command is given that
        isn't real
    '''
    if any(arguments.values()):
        raise SystemExit(__doc__)
    else:
        raise SystemExit(__doc__)

def moreHelp(arguments):
    ''' Arguments:
            arguments : dictionary; CLI arguments from docopt
        Returns:
            None

        Handles the help subcommand
    '''
    try:
        helpCommand = arguments['<args>'][0]
    except IndexError:
        raise SystemExit(__doc__)
    if helpCommand == 'fcounts':
        print(featureCounts.__doc__)
        print(
"""\n################################################################
                    fcounts Information
################################################################

The fcounts API consists of the FCountsExperiment and
FCountsSample classes located in pipeClasses.py. There are also
methods and attributes that are inherited from the Experiment
and Sample Class. Execution of an experiment consists of
executing the 5 runStage methods of an FCountsExperiment. These
stages are:
            1: Creating Project Structure
            2: Preparing Reference Data
            3: Running actual Pipeline
            4: Preparing for R analysis
            5: Running R analysis

Within the runStage1() method, there are two functions:
            1: makeStructure()
            2: makeSyms()

Function 1: Experiment.makeStructure():
    Action: Calls the makeStructure.sh shell script which takes
    as its arguments the path to the project and the number of
    samples
    Result: After execution, all the main directories of the
    project should be included -> Project, Data, Original,
    Postprocessing, Reference, and each of the sample
    directories

Function 2: Experiment.makeSyms():
    Action: Calls the makeSyms.sh shell script which takes as
    its arguments the path to the project, the path to the
    original data, and the path to the reference data
    Result: The original data files will have symbolic links in
    their respective sample directories; if there is a metadata
    file specified by the '--jsonfile' option, it will be linked
    in the Postprocessing directory; if the reference data has
    been prepared and specified by the '--use-reference' option,
    the entire reference directory will be linked in the
    Reference directoy, otherwise, just the 3 necessary
    reference files will be linked -> Gtf, Cdna, and Genome

Within the runStage2() method, there are two functions:
            1: qcRef()
            2: ppRef()

Function 1: Experiment.qcRef()
    Action: Calls the QCofRef.sh shell script which takes as its
    arguments the path to the reference data and the name of the
    genome.
    Result: Certain characteristics of the reference data will
    be checked such as: the names of the chromosomes in the gtf
    and genome file, the number of chromosomes in the gtf and
    genome file, the names of the genes in the cdna and gtf
    file, the total number of unique genes in the cdna and gtf,
    and the number of unique gene names in the cdna AND not in
    the gtf

Function 2: Experiment.ppRef()
    Action: Prepares the reference data by using various tools
    such as blast, extract_spice_sites.py, extract_exons.py,
    hisat2, and samtools
    Result: A blast database, a file with exon and splice site
    locations, a hisat2 database, and a genome index will be
    created in reference directory

Within the runStage3() method, there is one function:
            1: GO()

Function 1: FCountsExperiment.GO()
    Action: Creates sample classes and executes their runParts
    method
    Result: Experiment infrastructures acts as a wrapper around
    the samples, and executes them individually such that they
    are independent

Further Stage 3 information:

In Stage 3, the GO() method will create execution spaces for
each sample specified on the command line, or all possible by
default. After creating each sample, each sample's runSample()
method will be executed.

For the FCountsSample types, the runSample() method executes the
following commands:
        Part 1:
            1: runQCheck()
            2: runTrimmomatic()
            3: runQCheck()
        Part 2:
            1: runSeqtk()
            2: runBlastn()
            3: runHisat()
            4: runCompression()
            5: runFeatureCounts()
            6: getNiceColumns()
            7: getAlignedColumn()

Part 1: Consists of quality control with fastQC and trimmomatic

Function 1: Sample.runQCheck()
    Action: Runs fastQC on reads and then scrapes the
    overrepresented sequences from fastQC logs
    Result: There will be a fastQC folder in each sample
    directory that contains quality control information
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting runQCheck to
    False. Can also control the execution options under the
    [runQCheck] header:
        {fastqc} -t {-t} -o {-o} {other} {read1} {read2}
        fastqc: fastQC executable (by default will use
        executable defined under [EXECUTABLES] header)
        -t: processors to use (by default will use allocated
        sample space)
        -o: output directory (by default will use folder named
        fastqc{run-number}.{sample-name}) (CAUTION: highly
        discouraged from changing)
        other: used to specify any other options not already
        defined
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)

Function 2: Sample.runTrimmomatic()
    Action: Executes trimmomatic on reads
    Result: Reads will be trimmed
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting runTrimmomatic to
    False. Can also control the execution options under the
    [runTrimmomatic] header:
        {java} -jar {-jar} PE -threads {-threads} -phred{-phred}
        {other} {read1} {read2} {read1pout} {read1uout}
        {read2pout} {read2uout}
        ILLUMINACLIP:{blacklist}:{ILLUMINACLIP}
        LEADING:{LEADING} TRAILING:{TRAILING}
        SLIDINGWINDOW:{SLIDINGWINDOW} MINLEN:{MINLEN}
        java: java executable (by default will use executable
        defined under [EXECUTABLES] header)
        -jar: trimmomatic jar file (by default will use
        $RNASEQDIR/Trimmomatic/trimmomatic-0.36.jar)
        -threads: processors to use (by default will use
        allocated sample space)
        -phred: phred version (by default will scrape version
        from fastQC logs). Can set to 33, 64, or None (for
        default)
        other: used to specify any other options not already
        defined
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        read1pout: output read 1 (CAUTION: highly discouraged from
        changing)
        read2pout: output read 2 (CAUTION: highly discouraged from
        changing)
        read1uout: output read 1 (CAUTION: highly discouraged from
        changing)
        read2uout: output read 2 (CAUTION: highly discouraged from
        changing)
        blacklist: blacklist file (Can also specify on
        command-line with --use-blacklist)
        ILLUMINACLIP: trim options (by default: "2:30:10")
        LEADING: trim options (by default: "5")
        TRAILING: trim options (by default: "5")
        SLIDINGWINDOW: trim options (by default: "4:5")
        MINLEN: trim options (by default: "35")

Function 3: Sample.runQCheck()
    Action: Runs fastQC on reads and then scrapes the
    overrepresented sequences from fastQC logs
    Result: Does the same thing as the previous runQCheck except
    this run is post-trimmomatic to get a perspective on the
    changes that trimmomatic made
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting runQCheck to
    False or runTrimmomatic to False. Control execution options
    exactly the same as in Function 1.

Part 2: Consists of execution of feature counts method

Function 1: Sample.runSeqtk()
    Action: Execute seqtk on reads to get a representative
    sample of reads
    Result: Obtains a representative sample of reads in order to
    more quickly check strandedness of reads
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting runSeqtk to
    False. Can also control the execution options under the
    [runSeqtk] header:
        {seqtk} sample -s{-s} {read1} {samples} | seqtk seq {-A}
            {other} - > {read1out}
        {seqtk} sample -s{-s} {read2} {samples} | seqtk seq {-A}
            {other} - > {read2out}
        seqtk: seqtk executable (by default will use executable
        defined under [EXECUTABLES] header)
        -s: random seed (by default: "100")
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        read1out: output read 1 (CAUTION: highly discouraged from
        changing)
        read2out: output read 2 (CAUTION: highly discouraged from
        changing)
        samples: number of samples to take (by default: "10000")
        -A: boolean option to force FASTA output (by default is
        on). Can turn off by setting to False
        other: used to specify any other options not already
        defined

Function 2: Sample.runBlastn()
    Action: Execute blastn on seqtk output
    Result: Used to gather strandedness information of reads
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting runBlastn to
    False. Can also control the execution options under the
    [runBlastn] header:
        {blastn} -query {read1} -db {-db} -out {out1} -task
            {-task} -outfmt {-outfmt} -max_target_seqs
            {-max_target_seqs} -num_threads {-num_threads}
            {other}
        {blastn} -query {read2} -db {-db} -out {out2} -task
            {-task} -outfmt {-outfmt} -max_target_seqs
            {-max_target_seqs} -num_threads {-num_threads}
            {other}
        blastn: blastn executable (by default will use executable
        defined under [EXECUTABLES] header)
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        out1: output read 1 (CAUTION: highly discouraged from
        changing)
        out2: output read 2 (CAUTION: highly discouraged from
        changing)
        -db: path to blast database (by default:
        Reference/{basename}.cdna.all)
        -task: task to executed (by default "blastn-short")
        -outfmt: output format (by default '"6 std sstrand"';
        notice the double quotes necessary to contain the
        spaces)
        -max_target_seqs: max target sequences (by default "1")
        -num_threads: processors to use (by default will use
        allocated sample space)
        other: used to specify any other options not already
        defined

Function 3: FCountsSample.runHisat()
    Action: Executes hisat2 for alignment of reads to reference
    genome
    Result: A SAM file with identified reads
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting runHisat to
    False. Can also control the execution options under the
    [fcounts/runHisat] header:
        {hisat2} -k {-k} -p {-p} {--rna-strandedness} {--dta}
        --phred{phred} {other} --known-slicesite-infile
        {--known-splicesite-infile} -x {-x} -1 {-1} -2 {-2}
        -S {-S}
        hisat2: hisat2 executable (by default will use executable
        defined under [EXECUTABLES] header)
        -k: alternates per read (by default "5")
        -p: processors to use (by default will use allocated
        sample space)
        --rna-strandedness: strandedness of reads (by default
        will determine from blastn and seqtk) Can set to FR, RF,
        False, or None. False specifies unstrandedness while
        None defaults to pipeline findStranded()
        --dta: boolean option to report alignments tailored for
        transcript assemblers (by default on). Can turn off by
        setting to False
        --phred: phred version (by default will determine from
        fastQC logs). Can set to 33 or 64
        --known-splicesite-infile: path to splice sites (by
        default will use Reference/splice_sites.txt)
        -x: path to hisat2 index (by default will use
        Reference/{basename})
        read1: path to read 1 (CAUTION: highly discouraged from
        changing)
        read2: path to read 2 (CAUTION: highly discouraged from
        changing)
        -S: outpus SAM file (CAUTION: highly discouraged from
        changing)
        other: used to specify any other options not already
        defined

Function 4: FCountsSample.runCompression()
    Action: Use samtools to compress hisat2 output
    Result: A compressed BAM files with aligned read information
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting runCompression to
    False. Can also control the execution options under the
    [fcounts/runCompression] header:
        {samtools} view {-b} -T {-T} -@{-@} {other} {in} -o {-o}
        samtools: samtools executable (by default will use executable
        defined under [EXECUTABLES] header)
        -b: boolean option to output BAM file (by default on).
        Can turn off by setting to False
        -T: path to reference sequence FASTA file (by default
        will use Reference/{genome_file})
        -@: processors to use (by default will use allocated
        sample space)
        -o: output file name (CAUTION: highly discouraged from
        changing)
        in: input SAM file (CAUTION: highly discouraged from
        changing)
        other: used to specify any other options not already
        defined

Function 5: FCountsSample.runFeatureCounts()
    Action: Use featureCounts to count aligned reads
    Result: A file with count data
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting runFeatureCounts
    to False. Can also control the execution options under the
    [fcounts/runFeatureCounts] header:
        {featureCounts} -T {-T} -s
        {-s}{-p}{-C}{--primary}{--ignoreDup}{--largestOverlap}
        -t {-t} -g {-g} -a {-a} {other} -o {-o} {in}
        featureCounts: featureCounts executable (by default will
        use executable defined under [EXECUTABLES] header)
        -T: processors to use (by default will use allocated
        sample space)
        -s:  strandedness of reads (by default will determine
        from blastn and seqtk). Can set to 0 (unstranded), 1
        (stranded), 2 (reversely stranded), or None (default)
        -p: boolean option that allows for fragments to be
        counted instead of reads, normally for paired-end reads
        (by default on). Can turn off by setting to False.
        -C: boolean option that sets: "Do not count read pairs
        that have their two ends mapping to different
        chromosomes or mapping to same chromosome but on
        different strands." (By default on). Can turn off by
        setting to False.
        --primary: boolean option to count primary alignments
        only (by default on). Can turn off by setting to False.
        --ignoreDup: boolean option to ignore duplicate reads
        when read counting. (By default on). Can turn off by
        setting to False.
        --largestOverlap: boolean option to count gene with
        largest overlap on read (By default on). Can turn off
        by setting to False.
        -t: feature type in GTF annotation (by default "exon")
        -g: attribute type in GTF annotation (by default
        "gene_id")
        -a: path to annotation file (gtf) (by default
        Reference/{Gtf})
        -o: ouput counts file (CAUTION: highly discouraged from
        changing)
        in: input BAM file (CAUTION: highly discouraged from
        changing)
        other: used to specify any other options not already
        defined

Function 6: FCountsSample.getNiceColumns()
    Action: Scrapes featureCounts output for gene id, length of
    gene, and counts
    Result: A table with only gene name, length, and count
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting getNiceColumns
    to False.

Function 7: FCountsSample.getAlignedColumn()
    Action: Scrapes featureCounts to get only count column
    Result: A file with one column that contains count
    information
    Manifest Information: Able to be controlled from manifest
    under the [fcounts/main] header by setting getAlignedColumn
    to False.
""")
        raise SystemExit()
    elif helpCommand == 'string':
        print('''This is stringtie information #TODO''')
        raise SystemExit(stringtie.__doc__)
    elif helpCommand == 'kall':
        print('''This is kallisto information #TODO''')
        raise SystemExit(kallisto.__doc__)
    elif helpCommand == 'bowtie':
        print('''This is bowtie information #TODO''')
        raise SystemExit(bowtie.__doc__)
    elif helpCommand == 'mj':
        print('''This is makeJSON information #TODO''')
        import makeJSON
        raise SystemExit(makeJSON.__doc__)
    elif helpCommand == 'mb':
        print('''This is makeTrimBlacklist''')
        import makeTrimBlacklist
        raise SystemExit(makeTrimBlacklist.__doc__)
    elif helpCommand == 'clean':
        print('''This is cleanup information #TODO''')
        raise SystemExit(cleanup.__doc__)
    elif helpCommand == 'fo':
        print('''This is optPath information #TODO''')
        import optPath
        raise SystemExit(optPath.__doc__)
    elif helpCommand == 'prepref':
        print('''This is reference preprocessing information #TODO''')
        raise SystemExit(referenceProcessing.__doc__)
    elif helpCommand == 'help':
        print('''Help command provides help #TODO''')
    else:
        raise SystemExit(__doc__)

################################################################
# Reading Command-Line Arguments
################################################################

if __name__ == '__main__':
    beginTime = timer()

    args = docopt(__doc__, version=VERSION, options_first=True)
    argv = [args['<command>']] + args['<args>']
    if args['<command>'] == 'fcounts':
        args.update(docopt(featureCounts.__doc__, argv=argv))
        updatedArgs = updateArgs(args)
        featureCounts(updatedArgs)
    elif args['<command>'] == 'string':
        args.update(docopt(stringtie.__doc__, argv=argv))
        updatedArgs = updateArgs(args)
        stringtie(updatedArgs)
    elif args['<command>'] == 'kall':
        args.update(docopt(kallisto.__doc__, argv=argv))
        updatedArgs = updateArgs(args)
        kallisto(updatedArgs)
    elif args['<command>'] == 'bowtie2':
        args.update(docopt(bowtie2.__doc__, argv=argv))
        updatedArgs = updateArgs(args)
        bowtie2(updatedArgs)
    elif args['<command>'] == 'mj':
        import makeJSON
        args.update(docopt(makeJSON.__doc__, argv=argv))
        makeJSON.writeJSON(args['--jsonfile'])
    elif args['<command>'] == 'mb':
        import makeTrimBlacklist
        args.update(docopt(makeTrimBlacklist.__doc__, argv=argv))
        makeTrimBlacklist.blacklist(args['--tofile'])
    elif args['<command>'] == 'clean':
        args.update(docopt(cleanup.__doc__, argv=argv))
        cleanup(args)
    elif args['<command>'] == 'fo':
        import optPath
        args.update(docopt(optPath.__doc__, argv=argv))
        optPath.main(args)
    elif args['<command>'] == 'prepref':
        args.update(docopt(referenceProcessing.__doc__, argv=argv))
        updatedArgs = updateArgs(args)
        referenceProcessing(updatedArgs)
    elif args['<command>'] == 'gendef':
        args.update(docopt(generateDefaultInputFile.__doc__, argv=argv))
        generateDefaultInputFile(args)
    elif args['<command>'] == 'help':
        moreHelp(args)
    elif args['<command>'] == None:
        otherStuff(args)
    else:
        raise SystemExit("{} is not a runPipe command. See runPipe help".format(args['<command>']))

    timeused = str(time.strftime('%H:%M:%S', time.gmtime(timer() - beginTime)))
    print('[ {} ] Total time elapsed: {}'.format(pipeClasses.now(), timeused))
